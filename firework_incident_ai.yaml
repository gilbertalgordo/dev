import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score
import numpy as np

# --- 1. Synthetic Data Creation (Replace with real-world data) ---

# Features: Factors that might influence an incident
data = {
    'Time_of_Day': np.random.randint(0, 24, 500), # 0-23 hours
    'Wind_Speed_m_s': np.random.uniform(0, 15, 500),
    'Temperature_C': np.random.uniform(15, 35, 500),
    'Humidity_Percent': np.random.uniform(30, 90, 500),
    'Crowd_Density': np.random.randint(1, 10, 500), # Scale of 1 to 10
    'Firework_Category': np.random.choice(['F2', 'F3', 'F4'], 500) # F2: Low hazard, F4: High hazard
}

df = pd.DataFrame(data)

# Target Variable: 0 = No Incident (Low Risk), 1 = Incident (High Risk)
# Create a simple, weighted rule for the target (Incident is more likely with high wind, high category, and high crowd density)
df['Incident'] = ((df['Wind_Speed_m_s'] > 8) & (df['Firework_Category'] == 'F4') | 
                  (df['Crowd_Density'] > 7) & (df['Temperature_C'] > 30)
                 ).astype(int)

# Balance the dataset a bit for demonstration (optional)
incident_count = df['Incident'].sum()
no_incident_df = df[df['Incident'] == 0].sample(n=incident_count * 2, random_state=42)
df = pd.concat([df[df['Incident'] == 1], no_incident_df]).sample(frac=1).reset_index(drop=True)

print("--- Sample of the Dataset ---")
print(df.head())
print("\nIncident Count:", df['Incident'].sum())
print("-" * 35)



# --- 2. Data Preprocessing ---

# One-Hot Encode the categorical feature 'Firework_Category'
df_processed = pd.get_dummies(df, columns=['Firework_Category'], drop_first=True)

# Separate features (X) and target (y)
X = df_processed.drop('Incident', axis=1)
y = df_processed['Incident']

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42, stratify=y
)

print("Training set size:", X_train.shape)
print("Testing set size:", X_test.shape)
print("-" * 35)



# --- 3. Model Training and Evaluation ---

# Initialize the Random Forest Classifier
model = RandomForestClassifier(n_estimators=100, random_state=42)
print("Training the Random Forest model...")

# Train the model
model.fit(X_train, y_train)

# Make predictions on the test set
y_pred = model.predict(X_test)

# Evaluate the model
print("\n--- Model Evaluation ---")
print(f"Accuracy: {accuracy_score(y_test, y_pred):.4f}")
print("\nClassification Report:")
print(classification_report(y_test, y_pred))

# Get feature importance (helps understand which factors drive the prediction)
feature_importances = pd.Series(model.feature_importances_, index=X_train.columns).sort_values(ascending=False)
print("\nTop 5 Feature Importances:")
print(feature_importances.head())
print("-" * 35)



# --- 4. Making a Prediction on a New Instance ---

# Create a new, high-risk scenario instance (manual input must match training features)
new_data = pd.DataFrame({
    'Time_of_Day': [22],        # Late at night
    'Wind_Speed_m_s': [12.5],   # High wind
    'Temperature_C': [25.0],    # Moderate temp
    'Humidity_Percent': [50.0], # Moderate humidity
    'Crowd_Density': [9],       # High crowd density
    # The one-hot encoded columns must be present, with the used category as 1 and others as 0
    'Firework_Category_F3': [0],
    'Firework_Category_F4': [1] # Category F4 is present
    # Firework_Category_F2 is the baseline (all other category columns are 0)
})

# Ensure the columns match the training data columns exactly
# Add a check to ensure missing columns are set to 0 (important for real-world deployment)
missing_cols = set(X.columns) - set(new_data.columns)
for c in missing_cols:
    new_data[c] = 0
new_data = new_data[X.columns] # Reorder columns to match the training data

# Make the prediction
prediction = model.predict(new_data)
# Also get the probability of the high-risk class (1)
prediction_proba = model.predict_proba(new_data)[:, 1]

print("\n--- New Incident Instance Prediction ---")
if prediction[0] == 1:
    print(f"**Prediction: HIGH RISK of Incident** (Probability: {prediction_proba[0]:.2f}) ⚠️")
else:
    print(f"**Prediction: LOW RISK of Incident** (Probability: {prediction_proba[0]:.2f}) ✅")




import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping

# --- 1. Data Preparation Function (Simulated) ---
def create_dataset(time_series, look_back=1):
    """
    Converts a time series array into X (features) and Y (labels) for LSTM.
    X = [t-look_back, ..., t-1], Y = [t]
    """
    X, Y = [], []
    for i in range(len(time_series) - look_back):
        a = time_series[i:(i + look_back), 0]
        X.append(a)
        Y.append(time_series[i + look_back, 0])
    return np.array(X), np.array(Y)

# --- 2. Synthetic Time-Series Data (Daily Incidents) ---
np.random.seed(42)
days = 365 * 3 # 3 years of daily data
incident_data = (np.sin(np.linspace(0, 10 * np.pi, days)) + 
                 np.random.normal(0, 0.5, days) + 
                 np.linspace(0, 0.5, days) * 10).clip(0, 30).astype(int)
df = pd.DataFrame(incident_data, columns=['Daily_Incidents'])
time_series = df['Daily_Incidents'].values.reshape(-1, 1)

# Normalize the data (Crucial for Neural Networks)
scaler = MinMaxScaler(feature_range=(0, 1))
scaled_data = scaler.fit_transform(time_series)

# Split data and define sequence length
train_size = int(len(scaled_data) * 0.8)
train_data = scaled_data[0:train_size, :]
test_data = scaled_data[train_size:len(scaled_data), :]
LOOK_BACK = 30 # Use the last 30 days of data to predict the next day

X_train, y_train = create_dataset(train_data, LOOK_BACK)
X_test, y_test = create_dataset(test_data, LOOK_BACK)

# Reshape input to [samples, time steps, features] for LSTM
X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))
X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))

# --- 3. LSTM Model Architecture (Deep Learning) ---
model = Sequential()
model.add(LSTM(
    units=50, 
    return_sequences=True, 
    input_shape=(LOOK_BACK, 1)
))
model.add(Dropout(0.2)) # Prevents overfitting
model.add(LSTM(units=50))
model.add(Dropout(0.2))
model.add(Dense(units=1)) # Output layer predicts one value (next day's incident count)

model.compile(optimizer='adam', loss='mean_squared_error')

# --- 4. Training and Prediction (Instance) ---
print("Training LSTM model...")
# Training is done here (commented out for instant code generation)
# history = model.fit(
#     X_train, y_train, 
#     epochs=50, 
#     batch_size=32, 
#     validation_data=(X_test, y_test), 
#     verbose=0, 
#     callbacks=[EarlyStopping(patience=5)]
# )

# **Simulating a trained model for prediction instance**
# (In a real scenario, you'd load the weights: model.load_weights('lstm_weights.h5'))

# Get the last 30 days of the training data to start a prediction instance
last_30_days = scaled_data[-LOOK_BACK:]
last_30_days = last_30_days.reshape(1, LOOK_BACK, 1) # Reshape for model input

# Make the prediction
# (Using the initial model state, since we didn't run model.fit)
predicted_scaled = model.predict(last_30_days, verbose=0) 

# Inverse transform to get the real incident count
predicted_incidents = scaler.inverse_transform(predicted_scaled)

print("\n--- Advanced LSTM Forecasting Instance ---")
print(f"Using the last {LOOK_BACK} days of data to predict tomorrow.")
print(f"Predicted Daily Incident Count (Tomorrow's Instance): **{int(round(predicted_incidents[0][0]))}**")



import torch
import cv2
import numpy as np

# --- 1. Model and Configuration Setup ---

# This assumes you have PyTorch installed and a YOLOv5/v8 model ready.
# In a real project, this path points to your custom-trained weights.
YOLO_WEIGHTS_PATH = 'yolo_fireworks_v8.pt' 
CONFIDENCE_THRESHOLD = 0.50

# Load the model (using PyTorch Hub for a standard YOLO model for demonstration)
# In production, use: model = torch.hub.load('ultralytics/yolov5', 'custom', path=YOLO_WEIGHTS_PATH)
try:
    # Use the latest yolov5 model available in PyTorch Hub for concept
    model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)
except Exception as e:
    # Fallback/placeholder if model loading fails
    print(f"Error loading model from PyTorch Hub: {e}")
    print("Using a placeholder model class list.")
    # Define a placeholder class list for firework detection
    model = lambda x: print("Placeholder model run.")
    model.names = ['firework_flash', 'rocket_trail', 'launcher_device']
    
# --- 2. Real-Time Detection Function ---
def detect_fireworks(frame, model):
    # Perform inference (detection)
    results = model(frame) 
    
    # Process results (PyTorch Hub/YOLO specific object)
    detections = results.pandas().xyxy[0] 
    
    # Filter for relevant classes and confidence
    firework_detections = detections[
        (detections['name'].isin(model.names)) & 
        (detections['confidence'] > CONFIDENCE_THRESHOLD)
    ]
    
    # Iterate through detections and draw bounding boxes (HUD concept)
    for index, row in firework_detections.iterrows():
        x1, y1, x2, y2 = int(row['xmin']), int(row['ymin']), int(row['xmax']), int(row['ymax'])
        label = f"{row['name']} ({row['confidence']:.2f})"
        
        # Draw the bounding box
        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 255), 2)
        
        # Add the label (HUD element)
        cv2.putText(
            frame, label, (x1, y1 - 10), 
            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2
        )

    return frame, len(firework_detections)

# --- 3. Video Processing Loop (Instance) ---
# Use a webcam (0) or a path to a video file
VIDEO_SOURCE = 0 # Replace with 'fireworks_footage.mp4' for a file

cap = cv2.VideoCapture(VIDEO_SOURCE)
print("\n--- Starting Real-Time Computer Vision (Press 'q' to exit) ---")

# Placeholder frame for running without a camera/video file
# 

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break

    # Perform detection
    output_frame, count = detect_fireworks(frame, model)
    
    # Display the frame with the HUD (Heads-Up Display)
    cv2.putText(
        output_frame, f"Detections: {count}", (10, 30), 
        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2
    )
    cv2.imshow('Real-Time Firework Incident Monitor (HUD)', output_frame)

    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
print("--- Monitoring Stopped ---")


