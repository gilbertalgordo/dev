import subprocess
import os
import psutil
import logging
import platform
from datetime import datetime

# --- Configuration ---
LOG_FILE = "assistant_log.log"
RESEARCH_API_KEY = "YOUR_RESEARCH_API_KEY" # Placeholder for a real API key (e.g., Google Search API)

# Set up logging
logging.basicConfig(filename=LOG_FILE, level=logging.INFO,
                    format='%(asctime)s - %(levelname)s - %(message)s')

class AppManager:
    def __init__(self):
        self.os_platform = platform.system()
        logging.info(f"Initialized AppManager on {self.os_platform}")

    def list_installed_apps(self):
        """
        Lists installed applications. This is highly OS-dependent.
        Simplified example for demonstration.
        """
        app_list = []
        if self.os_platform == "Windows":
            # This is a very basic way to get some installed apps on Windows
            # A more robust solution would involve WMI or registry scanning.
            try:
                result = subprocess.run(['powershell', 'Get-ItemProperty HKLM:\\Software\\Wow6432Node\\Microsoft\\Windows\\CurrentVersion\\Uninstall\\*', '| Select-Object DisplayName, DisplayVersion, Publisher'], capture_output=True, text=True, check=True)
                for line in result.stdout.splitlines():
                    if "DisplayName" in line:
                        app_list.append(line.strip())
            except Exception as e:
                logging.error(f"Error listing Windows apps: {e}")
        elif self.os_platform == "Darwin": # macOS
            # On macOS, apps are typically in /Applications or ~/Applications
            app_dirs = ["/Applications", os.path.expanduser("~/Applications")]
            for app_dir in app_dirs:
                if os.path.exists(app_dir):
                    for item in os.listdir(app_dir):
                        if item.endswith(".app"):
                            app_list.append(item)
        elif self.os_platform == "Linux":
            # Linux app management is complex (apt, snap, flatpak, etc.)
            # This is a very crude way to find some executables in common paths
            common_bin_paths = ["/usr/bin", "/bin", "/usr/local/bin"]
            for path in common_bin_paths:
                if os.path.exists(path):
                    for item in os.listdir(path):
                        if os.path.isfile(os.path.join(path, item)) and os.access(os.path.join(path, item), os.X_OK):
                            app_list.append(item)
        logging.info(f"Listed {len(app_list)} applications.")
        return app_list

    def launch_app(self, app_name_or_path):
        """
        Launches an application.
        """
        try:
            if self.os_platform == "Windows" and app_name_or_path.endswith(".exe"):
                subprocess.Popen([app_name_or_path], shell=True)
            elif self.os_platform == "Darwin" and app_name_or_path.endswith(".app"):
                subprocess.Popen(["open", os.path.join("/Applications", app_name_or_path)]) # Assumes in /Applications for simplicity
            elif self.os_platform == "Linux":
                subprocess.Popen([app_name_or_path]) # Assumes it's in PATH or full path given
            else:
                logging.warning(f"Could not determine how to launch {app_name_or_path} on {self.os_platform}.")
                return False
            logging.info(f"Launched application: {app_name_or_path}")
            return True
        except Exception as e:
            logging.error(f"Error launching {app_name_or_path}: {e}")
            return False

    def close_app(self, app_name_or_pid):
        """
        Attempts to close an application by name or PID.
        Requires psutil for robust process management.
        """
        for proc in psutil.process_iter(['pid', 'name']):
            try:
                if app_name_or_pid.isdigit() and proc.info['pid'] == int(app_name_or_pid):
                    proc.terminate()
                    logging.info(f"Terminated process with PID: {app_name_or_pid}")
                    return True
                elif app_name_or_pid.lower() in proc.info['name'].lower():
                    proc.terminate()
                    logging.info(f"Terminated process by name: {proc.info['name']} (PID: {proc.info['pid']})")
                    return True
            except (psutil.NoSuchProcess, psutil.AccessDenied, psutil.ZombieProcess):
                continue
        logging.warning(f"Could not find or terminate application: {app_name_or_pid}")
        return False

    def get_app_read_write_stats(self, app_name_or_pid):
        """
        Gets basic read/write stats for a running application process.
        This provides process-level I/O, not file-level.
        """
        stats = {"read_bytes": 0, "write_bytes": 0}
        for proc in psutil.process_iter(['pid', 'name', 'io_counters']):
            try:
                if app_name_or_pid.isdigit() and proc.info['pid'] == int(app_name_or_pid):
                    io_counters = proc.io_counters()
                    stats["read_bytes"] = io_counters.read_bytes
                    stats["write_bytes"] = io_counters.write_bytes
                    logging.info(f"Retrieved I/O stats for PID {app_name_or_pid}: {stats}")
                    return stats
                elif app_name_or_pid.lower() in proc.info['name'].lower():
                    io_counters = proc.io_counters()
                    stats["read_bytes"] = io_counters.read_bytes
                    stats["write_bytes"] = io_counters.write_bytes
                    logging.info(f"Retrieved I/O stats for '{proc.info['name']}' (PID: {proc.info['pid']}): {stats}")
                    return stats
            except (psutil.NoSuchProcess, psutil.AccessDenied, psutil.ZombieProcess):
                continue
        logging.warning(f"Could not find process to get I/O stats: {app_name_or_pid}")
        return None

    # This is extremely difficult to implement generally without kernel modules or specialized tools.
    # It's more of a concept here.
    def monitor_file_access(self, file_path):
        """
        (Highly conceptual) Monitors read/write attributes for a specific file.
        True real-time file access monitoring typically requires OS-specific APIs
        (e.g., Windows API hooks, Linux fanotify/inotify, macOS FSEvents).
        Python's watchdog library can detect file system *events* but not *who* accessed them.
        """
        logging.warning(f"Real-time, process-specific file access monitoring for {file_path} is complex and not fully implemented here.")
        # Placeholder: You might log a file's existence and modification time.
        if os.path.exists(file_path):
            return {
                "exists": True,
                "last_modified": datetime.fromtimestamp(os.path.getmtime(file_path)).isoformat(),
                "last_accessed": datetime.fromtimestamp(os.path.getatime(file_path)).isoformat(),
                "size_bytes": os.path.getsize(file_path)
            }
        return {"exists": False}


class ErrorScanner:
    def __init__(self):
        logging.info("Initialized ErrorScanner.")

    def scan_system_logs(self, keywords=["error", "fail", "critical"]):
        """
        Scans system logs for specified keywords.
        Highly OS-dependent and requires appropriate permissions.
        """
        errors_found = []
        if platform.system() == "Windows":
            try:
                # Basic example: Check Windows Event Logs (Application, System)
                # Requires 'python-wmi' or 'pywin32' for robust access
                logging.warning("Windows Event Log scanning is complex and not fully implemented. Consider pywin32.")
                # Example using powershell (less efficient for large logs)
                result = subprocess.run(['powershell', 'Get-WinEvent -LogName Application,System -ErrorAction SilentlyContinue | Where-Object {$_.Message -match "error" -or $_.Message -match "fail"} | Select-Object -First 20 Message'], capture_output=True, text=True, check=True)
                errors_found.extend(result.stdout.splitlines())
            except Exception as e:
                logging.error(f"Error scanning Windows Event Logs: {e}")
        elif platform.system() == "Linux":
            # Example: Reading syslog or journalctl output
            try:
                result = subprocess.run(['journalctl', '-p', 'err', '-n', '50'], capture_output=True, text=True, check=True) # Last 50 errors
                errors_found.extend(result.stdout.splitlines())
            except Exception as e:
                logging.error(f"Error scanning Linux journalctl: {e}")
        elif platform.system() == "Darwin": # macOS
            # macOS uses 'log show'
            try:
                result = subprocess.run(['log', 'show', '--last', '1h', '--predicate', 'eventType = error OR eventType = fault'], capture_output=True, text=True, check=True)
                errors_found.extend(result.stdout.splitlines())
            except Exception as e:
                logging.error(f"Error scanning macOS logs: {e}")
        logging.info(f"Scanned system logs. Found {len(errors_found)} potential errors.")
        return errors_found

    def check_application_health(self, app_name_or_pid):
        """
        Checks if an application process is running and its basic health (CPU/memory).
        """
        for proc in psutil.process_iter(['pid', 'name', 'cpu_percent', 'memory_percent']):
            try:
                if app_name_or_pid.isdigit() and proc.info['pid'] == int(app_name_or_pid):
                    return {
                        "running": True,
                        "cpu_percent": proc.cpu_percent(interval=0.1),
                        "memory_percent": proc.memory_percent(),
                        "status": proc.status()
                    }
                elif app_name_or_pid.lower() in proc.info['name'].lower():
                    return {
                        "running": True,
                        "cpu_percent": proc.cpu_percent(interval=0.1),
                        "memory_percent": proc.memory_percent(),
                        "status": proc.status()
                    }
            except (psutil.NoSuchProcess, psutil.AccessDenied, psutil.ZombieProcess):
                continue
        return {"running": False}

class Researcher:
    def __init__(self, api_key=RESEARCH_API_KEY):
        self.api_key = api_key
        logging.info("Initialized Researcher.")

    def perform_web_search(self, query):
        """
        Simulates a web search. In a real scenario, this would use a search API
        (e.g., Google Custom Search API, SerpApi, or integrate with a web scraping library).
        """
        logging.info(f"Performing simulated web search for: '{query}'")
        # Placeholder for actual API call
        if not self.api_key:
            logging.warning("Research API key not provided. Web search will be a placeholder.")
            return [f"Simulated search result 1 for '{query}'",
                    f"Simulated search result 2 for '{query}'"]
        else:
            # Example using a placeholder for an actual web search API call
            # import requests
            # url = f"https://api.example.com/search?q={query}&key={self.api_key}"
            # try:
            #     response = requests.get(url)
            #     response.raise_for_status() # Raise an exception for HTTP errors
            #     data = response.json()
            #     return [result['snippet'] for result in data.get('results', [])]
            # except requests.exceptions.RequestException as e:
            #     logging.error(f"Error during web search for '{query}': {e}")
            #     return [f"Error retrieving search results for '{query}'"]
            return [f"Placeholder: Real web search for '{query}' would go here."]

    def summarize_text(self, text):
        """
        (Conceptual) Uses an AI model to summarize text.
        Requires a library like `transformers` and a pre-trained model.
        """
        try:
            # from transformers import pipeline
            # summarizer = pipeline("summarization")
            # summary = summarizer(text, max_length=130, min_length=30, do_sample=False)
            # return summary[0]['summary_text']
            logging.warning("Text summarization requires a powerful NLP model (e.g., from Hugging Face Transformers).")
            return f"Summary of: {text[:100]}..." # Truncated for demo
        except ImportError:
            logging.error("Hugging Face Transformers library not found. Cannot perform summarization.")
            return "Summarization function unavailable (install transformers library)."


class AIAssistant:
    def __init__(self):
        self.app_manager = AppManager()
        self.error_scanner = ErrorScanner()
        self.researcher = Researcher()
        logging.info("AI Assistant initialized.")

    def execute_command(self, command_text):
        """
        Parses user commands and dispatches to appropriate modules.
        This is where the 'AI' (NLP/intent recognition) would be more robust.
        For now, it's a simple keyword-based command parser.
        """
        command_text = command_text.lower().strip()
        logging.info(f"Received command: '{command_text}'")

        if "list apps" in command_text:
            apps = self.app_manager.list_installed_apps()
            return "Installed applications:\n" + "\n".join(apps[:20]) + ("..." if len(apps) > 20 else "")
        elif "launch app" in command_text:
            parts = command_text.split("launch app ", 1)
            if len(parts) > 1:
                app_name = parts[1].strip()
                if self.app_manager.launch_app(app_name):
                    return f"Attempting to launch {app_name}."
                else:
                    return f"Failed to launch {app_name}. Check application name/path or permissions."
            return "Please specify an application to launch (e.g., 'launch app notepad.exe')."
        elif "close app" in command_text:
            parts = command_text.split("close app ", 1)
            if len(parts) > 1:
                app_name_or_pid = parts[1].strip()
                if self.app_manager.close_app(app_name_or_pid):
                    return f"Attempting to close {app_name_or_pid}."
                else:
                    return f"Failed to close {app_name_or_pid}. App not found or permission denied."
            return "Please specify an application name or PID to close (e.g., 'close app notepad' or 'close app 1234')."
        elif "app stats" in command_text:
            parts = command_text.split("app stats ", 1)
            if len(parts) > 1:
                app_name_or_pid = parts[1].strip()
                stats = self.app_manager.get_app_read_write_stats(app_name_or_pid)
                if stats:
                    return (f"I/O Stats for {app_name_or_pid}:\n"
                            f"  Read Bytes: {stats['read_bytes']}\n"
                            f"  Write Bytes: {stats['write_bytes']}")
                else:
                    return f"Could not get stats for {app_name_or_pid}. App not found or not running."
            return "Please specify an application name or PID for stats (e.g., 'app stats chrome' or 'app stats 5678')."
        elif "scan errors" in command_text or "check logs" in command_text:
            errors = self.error_scanner.scan_system_logs()
            if errors:
                return "Found potential errors in system logs:\n" + "\n".join(errors[:10]) + ("..." if len(errors) > 10 else "")
            return "No significant errors found in system logs."
        elif "research" in command_text:
            parts = command_text.split("research ", 1)
            if len(parts) > 1:
                query = parts[1].strip()
                results = self.researcher.perform_web_search(query)
                return "Research results:\n" + "\n".join(results)
            return "Please provide a research query (e.g., 'research python performance tuning')."
        elif "summarize" in command_text:
            parts = command_text.split("summarize ", 1)
            if len(parts) > 1:
                text_to_summarize = parts[1].strip()
                summary = self.researcher.summarize_text(text_to_summarize)
                return f"Summary: {summary}"
            return "Please provide text to summarize (e.g., 'summarize This is a long piece of text...')."
        elif "check health" in command_text:
            parts = command_text.split("check health ", 1)
            if len(parts) > 1:
                app_name_or_pid = parts[1].strip()
                health = self.error_scanner.check_application_health(app_name_or_pid)
                if health["running"]:
                    return (f"{app_name_or_pid} is running. CPU: {health['cpu_percent']:.2f}%, Memory: {health['memory_percent']:.2f}%, Status: {health['status']}")
                else:
                    return f"{app_name_or_pid} is not running."
            return "Please specify an application name or PID to check health (e.g., 'check health firefox')."
        elif "exit" in command_text or "quit" in command_text:
            return "Exiting assistant. Goodbye!"
        else:
            return "I don't understand that command. Try 'list apps', 'launch app <name>', 'close app <name>', 'app stats <name>', 'scan errors', 'research <query>', 'summarize <text>', or 'check health <name>'."

# --- Main Interaction Loop ---
if __name__ == "__main__":
    assistant = AIAssistant()
    print("Advanced AI Assistant started. Type 'exit' to quit.")

    while True:
        user_input = input("You: ").strip()
        if user_input.lower() in ["exit", "quit"]:
            print(assistant.execute_command(user_input))
            break
        response = assistant.execute_command(user_input)
        print("Assistant:", response)



{
  "name": "node-ai-assistant",
  "version": "1.0.0",
  "description": "An advanced AI assistant in Node.js",
  "main": "index.js",
  "type": "module",
  "scripts": {
    "start": "node index.js"
  },
  "keywords": [],
  "author": "Your Name",
  "license": "MIT",
  "dependencies": {
    "axios": "^1.6.8",
    "chalk": "^5.3.0",
    "get-installed-apps": "^2.0.0",
    "node-nlp": "^4.27.0",
    "openai": "^4.47.0",
    "systeminformation": "^5.22.4"
  }
}



npm install axios chalk get-installed-apps node-nlp openai systeminformation



import { exec, spawn } from 'child_process';
import os from 'os';
import fs from 'fs/promises';
import { getInstalledApps, getWinInstalledApps, getMacInstalledApps } from 'get-installed-apps';
import si from 'systeminformation';
import { NlpManager } from 'node-nlp';
import { OpenAI } from 'openai'; // From 'openai' npm package
import chalk from 'chalk'; // For colorful console output

// --- Configuration ---
const LOG_FILE = 'assistant_log.log';
const OPENAI_API_KEY = process.env.OPENAI_API_KEY || 'YOUR_OPENAI_API_KEY'; // Use environment variable for production!

// Set up simple logging to file
async function logToFile(level, message) {
    const timestamp = new Date().toISOString();
    const logMessage = `${timestamp} - ${level.toUpperCase()} - ${message}\n`;
    try {
        await fs.appendFile(LOG_FILE, logMessage);
    } catch (error) {
        console.error(chalk.red(`Failed to write to log file: ${error.message}`));
    }
}

class AppManager {
    constructor() {
        this.platform = os.platform();
        logToFile('info', `Initialized AppManager on ${this.platform}`);
    }

    async listInstalledApps() {
        try {
            let apps = [];
            if (this.platform === 'win32') {
                // `get-installed-apps` is good for Windows
                apps = await getWinInstalledApps();
            } else if (this.platform === 'darwin') {
                // `get-installed-apps` works for macOS .app bundles
                apps = await getMacInstalledApps();
            } else { // Linux
                // Linux is more complex; this is a very basic attempt
                // You'd typically parse dpkg, rpm, snap, flatpak lists
                const { stdout } = await this.executeCommand('dpkg -l | grep ^ii | awk \'{print $2}\'');
                apps = stdout.split('\n').filter(Boolean); // filter(Boolean) removes empty strings
            }
            logToFile('info', `Listed ${apps.length} applications.`);
            return apps.map(app => (typeof app === 'string' ? app : app.displayName || app.name)).slice(0, 20); // Limit for display
        } catch (error) {
            logToFile('error', `Error listing apps: ${error.message}`);
            return [];
        }
    }

    async launchApp(appPathOrName) {
        try {
            let command = '';
            let args = [];

            if (this.platform === 'win32') {
                command = 'start';
                args.push(`""`); // Empty title to handle paths with spaces
                args.push(`"${appPathOrName}"`);
            } else if (this.platform === 'darwin') {
                command = 'open';
                args.push(`-a`);
                args.push(appPathOrName); // Expects app name like "Google Chrome" or path like "/Applications/Safari.app"
            } else { // Linux
                command = appPathOrName; // Assumes it's in PATH or full path
            }

            // Using spawn for non-blocking execution, especially for GUI apps
            const child = spawn(command, args, { detached: true, stdio: 'ignore', shell: true });
            child.unref(); // Allow parent process to exit independently
            logToFile('info', `Attempted to launch: ${appPathOrName}`);
            return true;
        } catch (error) {
            logToFile('error', `Error launching ${appPathOrName}: ${error.message}`);
            return false;
        }
    }

    async closeApp(appNameOrPid) {
        try {
            const processes = await si.processes();
            let targetProcess = null;

            if (!isNaN(appNameOrPid)) { // It's a PID
                targetProcess = processes.list.find(p => p.pid === parseInt(appNameOrPid));
            } else { // It's a name
                targetProcess = processes.list.find(p => p.name.toLowerCase().includes(appNameOrPid.toLowerCase()));
            }

            if (targetProcess) {
                process.kill(targetProcess.pid, 'SIGTERM'); // Send termination signal
                logToFile('info', `Terminated process: ${targetProcess.name} (PID: ${targetProcess.pid})`);
                return true;
            } else {
                logToFile('warn', `Process not found: ${appNameOrPid}`);
                return false;
            }
        } catch (error) {
            logToFile('error', `Error closing ${appNameOrPid}: ${error.message}`);
            return false;
        }
    }

    async getAppReadWriteStats(appNameOrPid) {
        try {
            const processes = await si.processes();
            let targetProcess = null;

            if (!isNaN(appNameOrPid)) {
                targetProcess = processes.list.find(p => p.pid === parseInt(appNameOrPid));
            } else {
                targetProcess = processes.list.find(p => p.name.toLowerCase().includes(appNameOrPid.toLowerCase()));
            }

            if (targetProcess) {
                // systeminformation provides aggregated I/O for the process
                logToFile('info', `Retrieved I/O stats for '${targetProcess.name}' (PID: ${targetProcess.pid}): Read: ${targetProcess.rIO} bytes, Write: ${targetProcess.wIO} bytes`);
                return {
                    pid: targetProcess.pid,
                    name: targetProcess.name,
                    readBytes: targetProcess.rIO, // Read bytes
                    writeBytes: targetProcess.wIO  // Written bytes
                };
            }
            logToFile('warn', `Could not find process to get I/O stats: ${appNameOrPid}`);
            return null;
        } catch (error) {
            logToFile('error', `Error getting I/O stats for ${appNameOrPid}: ${error.message}`);
            return null;
        }
    }

    // Helper to execute shell commands
    async executeCommand(command) {
        return new Promise((resolve, reject) => {
            exec(command, (error, stdout, stderr) => {
                if (error) {
                    reject(new Error(`Command failed: ${command}\n${stderr}`));
                } else {
                    resolve({ stdout, stderr });
                }
            });
        });
    }
}

class ErrorScanner {
    constructor() {
        logToFile('info', 'Initialized ErrorScanner.');
    }

    async scanSystemLogs(keywords = ['error', 'fail', 'critical']) {
        let errorsFound = [];
        let command = '';
        let args = [];

        if (os.platform() === 'win32') {
            // PowerShell command to get event logs with keywords
            command = 'powershell.exe';
            args = [
                '-Command',
                `Get-WinEvent -LogName Application,System -ErrorAction SilentlyContinue | Where-Object {($_.Message -match '${keywords.join('|')}') -or ($_.LevelDisplayName -match 'Error' -or $_.LevelDisplayName -match 'Critical')} | Select-Object -First 20 Message | Format-List`
            ];
        } else if (os.platform() === 'darwin') {
            // macOS log command
            command = 'log';
            args = [
                'show', '--last', '1h', '--predicate',
                `eventType == error OR eventType == fault OR (message CONTAINS "${keywords.join('" OR message CONTAINS "')}")`
            ];
        } else { // Linux
            // journalctl command
            command = 'journalctl';
            args = ['-p', 'err', '-n', '50', '--no-pager']; // Last 50 errors
        }

        try {
            const { stdout } = await new Promise((resolve, reject) => {
                exec(`${command} ${args.join(' ')}`, (error, stdout, stderr) => {
                    if (error) {
                        logToFile('error', `Error scanning system logs: ${stderr}`);
                        reject(error);
                    } else {
                        resolve({ stdout, stderr });
                    }
                });
            });
            errorsFound = stdout.split('\n').filter(line => line.trim() !== '');
            logToFile('info', `Scanned system logs. Found ${errorsFound.length} potential errors.`);
            return errorsFound.slice(0, 10); // Limit for display
        } catch (error) {
            logToFile('error', `Failed to scan system logs: ${error.message}`);
            return [`Could not scan system logs: ${error.message}`];
        }
    }

    async checkApplicationHealth(appNameOrPid) {
        try {
            const processes = await si.processes();
            let targetProcess = null;

            if (!isNaN(appNameOrPid)) {
                targetProcess = processes.list.find(p => p.pid === parseInt(appNameOrPid));
            } else {
                targetProcess = processes.list.find(p => p.name.toLowerCase().includes(appNameOrPid.toLowerCase()));
            }

            if (targetProcess) {
                logToFile('info', `Health check for '${targetProcess.name}' (PID: ${targetProcess.pid}): CPU: ${targetProcess.cpu.toFixed(2)}%, Memory: ${targetProcess.mem.toFixed(2)}%, Status: ${targetProcess.status}`);
                return {
                    running: true,
                    pid: targetProcess.pid,
                    name: targetProcess.name,
                    cpuPercent: targetProcess.cpu,
                    memoryPercent: targetProcess.mem, // Memory usage in percentage of total
                    status: targetProcess.status
                };
            }
            logToFile('warn', `Application not found for health check: ${appNameOrPid}`);
            return { running: false };
        } catch (error) {
            logToFile('error', `Error checking health for ${appNameOrPid}: ${error.message}`);
            return { running: false };
        }
    }
}

class Researcher {
    constructor(apiKey) {
        this.openai = new OpenAI({ apiKey: apiKey });
        this.hasOpenAI = !!apiKey;
        logToFile('info', `Initialized Researcher. OpenAI enabled: ${this.hasOpenAI}`);
    }

    async performWebSearch(query) {
        logToFile('info', `Performing simulated web search for: '${query}'`);
        // In a real scenario, integrate with a search API (e.g., Google Custom Search, Brave Search API)
        if (!this.hasOpenAI) {
            logToFile('warn', 'OpenAI API key not provided. Web search will be a placeholder.');
            return [
                `Simulated search result 1 for '${query}'`,
                `Simulated search result 2 for '${query}'`
            ];
        }

        try {
            // Use OpenAI's search capability (if available for your model) or a separate search API.
            // For now, let's use a simple OpenAI chat completion to "simulate" research.
            const completion = await this.openai.chat.completions.create({
                model: "gpt-4o", // or "gpt-3.5-turbo"
                messages: [
                    { role: "system", content: "You are a helpful assistant that provides concise research results." },
                    { role: "user", content: `Provide a concise summary of research on: ${query}` }
                ],
                max_tokens: 300,
            });
            const result = completion.choices[0]?.message?.content || "No research results found.";
            return [`AI-generated research result: ${result}`];
        } catch (error) {
            logToFile('error', `Error during OpenAI web search simulation for '${query}': ${error.message}`);
            return [`Error retrieving AI-generated research results for '${query}'.`];
        }
    }

    async summarizeText(text) {
        if (!this.hasOpenAI) {
            logToFile('warn', 'OpenAI API key not provided. Summarization will be a placeholder.');
            return `Summary of: ${text.substring(0, 100)}... (OpenAI not configured)`;
        }

        try {
            const completion = await this.openai.chat.completions.create({
                model: "gpt-4o", // or "gpt-3.5-turbo"
                messages: [
                    { role: "system", content: "You are a helpful assistant that summarizes text concisely." },
                    { role: "user", content: `Summarize the following text:\n\n${text}` }
                ],
                max_tokens: 200,
            });
            return completion.choices[0]?.message?.content || "Could not generate summary.";
        } catch (error) {
            logToFile('error', `Error during text summarization: ${error.message}`);
            return `Failed to summarize text: ${error.message}`;
        }
    }
}

class AIAssistant {
    constructor() {
        this.appManager = new AppManager();
        this.errorScanner = new ErrorScanner();
        this.researcher = new Researcher(OPENAI_API_KEY);

        this.nlpManager = new NlpManager({ languages: ['en'], forceNER: true });
        this.setupNlpManager();

        logToFile('info', 'AI Assistant initialized.');
    }

    async setupNlpManager() {
        // Train NLP manager for intent recognition
        this.nlpManager.addDocument('en', 'list installed apps', 'app.list');
        this.nlpManager.addDocument('en', 'show me my applications', 'app.list');

        this.nlpManager.addDocument('en', 'launch app %appName%', 'app.launch');
        this.nlpManager.addDocument('en', 'open %appName%', 'app.launch');

        this.nlpManager.addDocument('en', 'close app %appNameOrPid%', 'app.close');
        this.nlpManager.addDocument('en', 'terminate %appNameOrPid%', 'app.close');

        this.nlpManager.addDocument('en', 'get app stats for %appNameOrPid%', 'app.stats');
        this.nlpManager.addDocument('en', 'show io for %appNameOrPid%', 'app.stats');

        this.nlpManager.addDocument('en', 'scan system errors', 'system.scan_errors');
        this.nlpManager.addDocument('en', 'check logs for errors', 'system.scan_errors');

        this.nlpManager.addDocument('en', 'research %query%', 'research.web');
        this.nlpManager.addDocument('en', 'find information on %query%', 'research.web');

        this.nlpManager.addDocument('en', 'summarize %text%', 'research.summarize');

        this.nlpManager.addDocument('en', 'check health of %appNameOrPid%', 'app.health');
        this.nlpManager.addDocument('en', 'is %appNameOrPid% running', 'app.health');

        this.nlpManager.addAnswer('en', 'app.list', 'Listing installed applications...');
        this.nlpManager.addAnswer('en', 'app.launch', 'Attempting to launch the application...');
        this.nlpManager.addAnswer('en', 'app.close', 'Attempting to close the application...');
        this.nlpManager.addAnswer('en', 'app.stats', 'Retrieving application statistics...');
        this.nlpManager.addAnswer('en', 'system.scan_errors', 'Scanning system logs for errors...');
        this.nlpManager.addAnswer('en', 'research.web', 'Performing web research...');
        this.nlpManager.addAnswer('en', 'research.summarize', 'Summarizing the provided text...');
        this.nlpManager.addAnswer('en', 'app.health', 'Checking application health...');

        await this.nlpManager.train();
        logToFile('info', 'NLP Manager trained.');
    }

    async executeCommand(commandText) {
        logToFile('info', `Received command: '${commandText}'`);
        const result = await this.nlpManager.process('en', commandText);
        const intent = result.intent;
        const entities = result.entities;
        const score = result.score;

        if (score < 0.7) { // Confidence threshold
            return chalk.yellow("I don't fully understand that command. Please try rephrasing.");
        }

        switch (intent) {
            case 'app.list':
                const apps = await this.appManager.listInstalledApps();
                return chalk.green("Installed applications:\n") + apps.join('\n');
            case 'app.launch':
                const appName = entities.find(e => e.entity === 'appName')?.utteranceText;
                if (appName) {
                    const success = await this.appManager.launchApp(appName);
                    return success ? chalk.green(`Attempting to launch ${appName}.`) : chalk.red(`Failed to launch ${appName}. Check name/path or permissions.`);
                }
                return chalk.red("Please specify an application to launch (e.g., 'launch app Notepad.exe').");
            case 'app.close':
                const appNameOrPidClose = entities.find(e => e.entity === 'appNameOrPid')?.utteranceText;
                if (appNameOrPidClose) {
                    const success = await this.appManager.closeApp(appNameOrPidClose);
                    return success ? chalk.green(`Attempting to close ${appNameOrPidClose}.`) : chalk.red(`Failed to close ${appNameOrPidClose}. App not found or permission denied.`);
                }
                return chalk.red("Please specify an application name or PID to close (e.g., 'close app Chrome' or 'close app 1234').");
            case 'app.stats':
                const appNameOrPidStats = entities.find(e => e.entity === 'appNameOrPid')?.utteranceText;
                if (appNameOrPidStats) {
                    const stats = await this.appManager.getAppReadWriteStats(appNameOrPidStats);
                    if (stats) {
                        return chalk.cyan(`I/O Stats for ${stats.name} (PID: ${stats.pid}):\n`) +
                               chalk.cyan(`  Read Bytes: ${stats.readBytes}\n`) +
                               chalk.cyan(`  Write Bytes: ${stats.writeBytes}`);
                    }
                    return chalk.red(`Could not get stats for ${appNameOrPidStats}. App not found or not running.`);
                }
                return chalk.red("Please specify an application name or PID for stats (e.g., 'app stats firefox' or 'app stats 5678').");
            case 'system.scan_errors':
                const errors = await this.errorScanner.scanSystemLogs();
                if (errors.length > 0) {
                    return chalk.yellow("Found potential errors in system logs:\n") + errors.join('\n');
                }
                return chalk.green("No significant errors found in system logs.");
            case 'research.web':
                const query = entities.find(e => e.entity === 'query')?.utteranceText;
                if (query) {
                    const results = await this.researcher.performWebSearch(query);
                    return chalk.blue("Research results:\n") + results.join('\n');
                }
                return chalk.red("Please provide a research query (e.g., 'research Node.js security best practices').");
            case 'research.summarize':
                const textToSummarize = entities.find(e => e.entity === 'text')?.utteranceText;
                if (textToSummarize) {
                    const summary = await this.researcher.summarizeText(textToSummarize);
                    return chalk.magenta(`Summary: ${summary}`);
                }
                return chalk.red("Please provide text to summarize (e.g., 'summarize The quick brown fox...').");
            case 'app.health':
                const appNameOrPidHealth = entities.find(e => e.entity === 'appNameOrPid')?.utteranceText;
                if (appNameOrPidHealth) {
                    const health = await this.errorScanner.checkApplicationHealth(appNameOrPidHealth);
                    if (health.running) {
                        return chalk.green(`${health.name} (PID: ${health.pid}) is running. CPU: ${health.cpuPercent.toFixed(2)}%, Memory: ${health.memoryPercent.toFixed(2)}%, Status: ${health.status}`);
                    }
                    return chalk.red(`${appNameOrPidHealth} is not running.`);
                }
                return chalk.red("Please specify an application name or PID to check health (e.g., 'check health Safari').");
            default:
                return chalk.grey("I'm not sure how to handle that. Try commands like 'list apps', 'launch app <name>', 'close app <name>', 'app stats <name>', 'scan errors', 'research <query>', 'summarize <text>', or 'check health <name>'.");
        }
    }
}

// --- Main Interaction Loop ---
async function main() {
    const assistant = new AIAssistant();
    console.log(chalk.bold.green("Advanced AI Assistant started. Type 'exit' to quit."));

    process.stdin.setEncoding('utf8');
    process.stdin.on('data', async (data) => {
        const userInput = data.toString().trim();
        if (userInput.toLowerCase() === 'exit' || userInput.toLowerCase() === 'quit') {
            console.log(chalk.bold.grey("Exiting assistant. Goodbye!"));
            process.exit(0);
        }
        const response = await assistant.executeCommand(userInput);
        console.log(chalk.bold.yellow("Assistant:"), response);
        process.stdout.write("You: "); // Prompt for next input
    });

    // Initial prompt
    process.stdout.write("You: ");
}

main().catch(error => {
    console.error(chalk.bgRed.white("An unhandled error occurred:"), error);
    logToFile('critical', `Unhandled error: ${error.message}\n${error.stack}`);
    process.exit(1);
});



Building an advanced AI assistant in Node.js that handles all installed apps, monitors read/write attributes, scans errors, and performs research is a highly ambitious project, similar in complexity to the Python example. Node.js excels at asynchronous I/O and server-side operations, making it suitable for parts of this, but directly interacting with the operating system at a low level (like monitoring file I/O of other processes) remains challenging and platform-dependent, often requiring native modules or external system tools.
Here's a conceptual outline and some foundational Node.js code snippets to illustrate how you might approach various components.
Core Concepts and Challenges (Node.js Perspective):
 * Operating System Interaction: Node.js has built-in modules like child_process (for running shell commands), os (for OS information), and fs (for file system operations). For deeper OS interaction (e.g., listing all installed apps, reading system-wide logs), you'll often rely on platform-specific command-line tools that Node.js can execute.
 * Permissions and Security: Just like with Python, interacting with system-level resources requires elevated privileges. This introduces significant security risks and needs to be handled with extreme caution.
 * Read/Write Monitoring: Similar to Python, direct, granular, real-time file I/O monitoring of other applications from user-space Node.js is very difficult. fs.watch() can monitor file/directory changes, but not which process caused them. You'll likely rely on system-level tools or aggregated process I/O statistics.
 * Error Scanning: This involves reading system logs (Event Viewer on Windows, journalctl on Linux, log show on macOS) and parsing their output.
 * Research Capability: Node.js has a rich ecosystem for web scraping (axios, cheerio), interacting with APIs (node-fetch, axios), and integrating with AI models (e.g., OpenAI's API, Hugging Face transformers.js).
 * User Interface: This example will focus on a command-line interface. For a GUI, you'd use frameworks like Electron.
Node.js Modules to Consider:
 * OS Interaction/System Monitoring:
   * child_process: To execute shell commands (e.g., powershell, wmic, open, ps, journalctl, log).
   * os: For basic OS information (platform, CPU, memory).
   * fs/promises (or fs with callbacks): For file system operations (reading logs, managing files).
   * get-installed-apps (npm package): For cross-platform listing of installed applications (Windows & macOS, limited for Linux).
   * systeminformation (npm package): For more comprehensive system information, including process details (though detailed I/O per process is still tricky).
   * winston or pino (npm packages): For robust logging within your assistant.
 * NLP/AI for Research:
   * node-nlp (npm package): For natural language processing, intent recognition, and entity extraction.
   * openai (npm package): Official OpenAI Node.js client library for interacting with GPT models (for summarization, Q&A).
   * axios or node-fetch (npm packages): For making HTTP requests to external APIs (search engines, LLMs).
   * cheerio (npm package): For parsing HTML from web research (if you're doing web scraping).
 * Utility:
   * commander or yargs (npm packages): For building command-line interfaces.
Conceptual Node.js Code Structure (Highly Simplified)
1. package.json (Required)
{
  "name": "node-ai-assistant",
  "version": "1.0.0",
  "description": "An advanced AI assistant in Node.js",
  "main": "index.js",
  "type": "module",
  "scripts": {
    "start": "node index.js"
  },
  "keywords": [],
  "author": "Your Name",
  "license": "MIT",
  "dependencies": {
    "axios": "^1.6.8",
    "chalk": "^5.3.0",
    "get-installed-apps": "^2.0.0",
    "node-nlp": "^4.27.0",
    "openai": "^4.47.0",
    "systeminformation": "^5.22.4"
  }
}

Install dependencies:
npm install axios chalk get-installed-apps node-nlp openai systeminformation

2. index.js (Main Assistant Logic)
import { exec, spawn } from 'child_process';
import os from 'os';
import fs from 'fs/promises';
import { getInstalledApps, getWinInstalledApps, getMacInstalledApps } from 'get-installed-apps';
import si from 'systeminformation';
import { NlpManager } from 'node-nlp';
import { OpenAI } from 'openai'; // From 'openai' npm package
import chalk from 'chalk'; // For colorful console output

// --- Configuration ---
const LOG_FILE = 'assistant_log.log';
const OPENAI_API_KEY = process.env.OPENAI_API_KEY || 'YOUR_OPENAI_API_KEY'; // Use environment variable for production!

// Set up simple logging to file
async function logToFile(level, message) {
    const timestamp = new Date().toISOString();
    const logMessage = `${timestamp} - ${level.toUpperCase()} - ${message}\n`;
    try {
        await fs.appendFile(LOG_FILE, logMessage);
    } catch (error) {
        console.error(chalk.red(`Failed to write to log file: ${error.message}`));
    }
}

class AppManager {
    constructor() {
        this.platform = os.platform();
        logToFile('info', `Initialized AppManager on ${this.platform}`);
    }

    async listInstalledApps() {
        try {
            let apps = [];
            if (this.platform === 'win32') {
                // `get-installed-apps` is good for Windows
                apps = await getWinInstalledApps();
            } else if (this.platform === 'darwin') {
                // `get-installed-apps` works for macOS .app bundles
                apps = await getMacInstalledApps();
            } else { // Linux
                // Linux is more complex; this is a very basic attempt
                // You'd typically parse dpkg, rpm, snap, flatpak lists
                const { stdout } = await this.executeCommand('dpkg -l | grep ^ii | awk \'{print $2}\'');
                apps = stdout.split('\n').filter(Boolean); // filter(Boolean) removes empty strings
            }
            logToFile('info', `Listed ${apps.length} applications.`);
            return apps.map(app => (typeof app === 'string' ? app : app.displayName || app.name)).slice(0, 20); // Limit for display
        } catch (error) {
            logToFile('error', `Error listing apps: ${error.message}`);
            return [];
        }
    }

    async launchApp(appPathOrName) {
        try {
            let command = '';
            let args = [];

            if (this.platform === 'win32') {
                command = 'start';
                args.push(`""`); // Empty title to handle paths with spaces
                args.push(`"${appPathOrName}"`);
            } else if (this.platform === 'darwin') {
                command = 'open';
                args.push(`-a`);
                args.push(appPathOrName); // Expects app name like "Google Chrome" or path like "/Applications/Safari.app"
            } else { // Linux
                command = appPathOrName; // Assumes it's in PATH or full path
            }

            // Using spawn for non-blocking execution, especially for GUI apps
            const child = spawn(command, args, { detached: true, stdio: 'ignore', shell: true });
            child.unref(); // Allow parent process to exit independently
            logToFile('info', `Attempted to launch: ${appPathOrName}`);
            return true;
        } catch (error) {
            logToFile('error', `Error launching ${appPathOrName}: ${error.message}`);
            return false;
        }
    }

    async closeApp(appNameOrPid) {
        try {
            const processes = await si.processes();
            let targetProcess = null;

            if (!isNaN(appNameOrPid)) { // It's a PID
                targetProcess = processes.list.find(p => p.pid === parseInt(appNameOrPid));
            } else { // It's a name
                targetProcess = processes.list.find(p => p.name.toLowerCase().includes(appNameOrPid.toLowerCase()));
            }

            if (targetProcess) {
                process.kill(targetProcess.pid, 'SIGTERM'); // Send termination signal
                logToFile('info', `Terminated process: ${targetProcess.name} (PID: ${targetProcess.pid})`);
                return true;
            } else {
                logToFile('warn', `Process not found: ${appNameOrPid}`);
                return false;
            }
        } catch (error) {
            logToFile('error', `Error closing ${appNameOrPid}: ${error.message}`);
            return false;
        }
    }

    async getAppReadWriteStats(appNameOrPid) {
        try {
            const processes = await si.processes();
            let targetProcess = null;

            if (!isNaN(appNameOrPid)) {
                targetProcess = processes.list.find(p => p.pid === parseInt(appNameOrPid));
            } else {
                targetProcess = processes.list.find(p => p.name.toLowerCase().includes(appNameOrPid.toLowerCase()));
            }

            if (targetProcess) {
                // systeminformation provides aggregated I/O for the process
                logToFile('info', `Retrieved I/O stats for '${targetProcess.name}' (PID: ${targetProcess.pid}): Read: ${targetProcess.rIO} bytes, Write: ${targetProcess.wIO} bytes`);
                return {
                    pid: targetProcess.pid,
                    name: targetProcess.name,
                    readBytes: targetProcess.rIO, // Read bytes
                    writeBytes: targetProcess.wIO  // Written bytes
                };
            }
            logToFile('warn', `Could not find process to get I/O stats: ${appNameOrPid}`);
            return null;
        } catch (error) {
            logToFile('error', `Error getting I/O stats for ${appNameOrPid}: ${error.message}`);
            return null;
        }
    }

    // Helper to execute shell commands
    async executeCommand(command) {
        return new Promise((resolve, reject) => {
            exec(command, (error, stdout, stderr) => {
                if (error) {
                    reject(new Error(`Command failed: ${command}\n${stderr}`));
                } else {
                    resolve({ stdout, stderr });
                }
            });
        });
    }
}

class ErrorScanner {
    constructor() {
        logToFile('info', 'Initialized ErrorScanner.');
    }

    async scanSystemLogs(keywords = ['error', 'fail', 'critical']) {
        let errorsFound = [];
        let command = '';
        let args = [];

        if (os.platform() === 'win32') {
            // PowerShell command to get event logs with keywords
            command = 'powershell.exe';
            args = [
                '-Command',
                `Get-WinEvent -LogName Application,System -ErrorAction SilentlyContinue | Where-Object {($_.Message -match '${keywords.join('|')}') -or ($_.LevelDisplayName -match 'Error' -or $_.LevelDisplayName -match 'Critical')} | Select-Object -First 20 Message | Format-List`
            ];
        } else if (os.platform() === 'darwin') {
            // macOS log command
            command = 'log';
            args = [
                'show', '--last', '1h', '--predicate',
                `eventType == error OR eventType == fault OR (message CONTAINS "${keywords.join('" OR message CONTAINS "')}")`
            ];
        } else { // Linux
            // journalctl command
            command = 'journalctl';
            args = ['-p', 'err', '-n', '50', '--no-pager']; // Last 50 errors
        }

        try {
            const { stdout } = await new Promise((resolve, reject) => {
                exec(`${command} ${args.join(' ')}`, (error, stdout, stderr) => {
                    if (error) {
                        logToFile('error', `Error scanning system logs: ${stderr}`);
                        reject(error);
                    } else {
                        resolve({ stdout, stderr });
                    }
                });
            });
            errorsFound = stdout.split('\n').filter(line => line.trim() !== '');
            logToFile('info', `Scanned system logs. Found ${errorsFound.length} potential errors.`);
            return errorsFound.slice(0, 10); // Limit for display
        } catch (error) {
            logToFile('error', `Failed to scan system logs: ${error.message}`);
            return [`Could not scan system logs: ${error.message}`];
        }
    }

    async checkApplicationHealth(appNameOrPid) {
        try {
            const processes = await si.processes();
            let targetProcess = null;

            if (!isNaN(appNameOrPid)) {
                targetProcess = processes.list.find(p => p.pid === parseInt(appNameOrPid));
            } else {
                targetProcess = processes.list.find(p => p.name.toLowerCase().includes(appNameOrPid.toLowerCase()));
            }

            if (targetProcess) {
                logToFile('info', `Health check for '${targetProcess.name}' (PID: ${targetProcess.pid}): CPU: ${targetProcess.cpu.toFixed(2)}%, Memory: ${targetProcess.mem.toFixed(2)}%, Status: ${targetProcess.status}`);
                return {
                    running: true,
                    pid: targetProcess.pid,
                    name: targetProcess.name,
                    cpuPercent: targetProcess.cpu,
                    memoryPercent: targetProcess.mem, // Memory usage in percentage of total
                    status: targetProcess.status
                };
            }
            logToFile('warn', `Application not found for health check: ${appNameOrPid}`);
            return { running: false };
        } catch (error) {
            logToFile('error', `Error checking health for ${appNameOrPid}: ${error.message}`);
            return { running: false };
        }
    }
}

class Researcher {
    constructor(apiKey) {
        this.openai = new OpenAI({ apiKey: apiKey });
        this.hasOpenAI = !!apiKey;
        logToFile('info', `Initialized Researcher. OpenAI enabled: ${this.hasOpenAI}`);
    }

    async performWebSearch(query) {
        logToFile('info', `Performing simulated web search for: '${query}'`);
        // In a real scenario, integrate with a search API (e.g., Google Custom Search, Brave Search API)
        if (!this.hasOpenAI) {
            logToFile('warn', 'OpenAI API key not provided. Web search will be a placeholder.');
            return [
                `Simulated search result 1 for '${query}'`,
                `Simulated search result 2 for '${query}'`
            ];
        }

        try {
            // Use OpenAI's search capability (if available for your model) or a separate search API.
            // For now, let's use a simple OpenAI chat completion to "simulate" research.
            const completion = await this.openai.chat.completions.create({
                model: "gpt-4o", // or "gpt-3.5-turbo"
                messages: [
                    { role: "system", content: "You are a helpful assistant that provides concise research results." },
                    { role: "user", content: `Provide a concise summary of research on: ${query}` }
                ],
                max_tokens: 300,
            });
            const result = completion.choices[0]?.message?.content || "No research results found.";
            return [`AI-generated research result: ${result}`];
        } catch (error) {
            logToFile('error', `Error during OpenAI web search simulation for '${query}': ${error.message}`);
            return [`Error retrieving AI-generated research results for '${query}'.`];
        }
    }

    async summarizeText(text) {
        if (!this.hasOpenAI) {
            logToFile('warn', 'OpenAI API key not provided. Summarization will be a placeholder.');
            return `Summary of: ${text.substring(0, 100)}... (OpenAI not configured)`;
        }

        try {
            const completion = await this.openai.chat.completions.create({
                model: "gpt-4o", // or "gpt-3.5-turbo"
                messages: [
                    { role: "system", content: "You are a helpful assistant that summarizes text concisely." },
                    { role: "user", content: `Summarize the following text:\n\n${text}` }
                ],
                max_tokens: 200,
            });
            return completion.choices[0]?.message?.content || "Could not generate summary.";
        } catch (error) {
            logToFile('error', `Error during text summarization: ${error.message}`);
            return `Failed to summarize text: ${error.message}`;
        }
    }
}

class AIAssistant {
    constructor() {
        this.appManager = new AppManager();
        this.errorScanner = new ErrorScanner();
        this.researcher = new Researcher(OPENAI_API_KEY);

        this.nlpManager = new NlpManager({ languages: ['en'], forceNER: true });
        this.setupNlpManager();

        logToFile('info', 'AI Assistant initialized.');
    }

    async setupNlpManager() {
        // Train NLP manager for intent recognition
        this.nlpManager.addDocument('en', 'list installed apps', 'app.list');
        this.nlpManager.addDocument('en', 'show me my applications', 'app.list');

        this.nlpManager.addDocument('en', 'launch app %appName%', 'app.launch');
        this.nlpManager.addDocument('en', 'open %appName%', 'app.launch');

        this.nlpManager.addDocument('en', 'close app %appNameOrPid%', 'app.close');
        this.nlpManager.addDocument('en', 'terminate %appNameOrPid%', 'app.close');

        this.nlpManager.addDocument('en', 'get app stats for %appNameOrPid%', 'app.stats');
        this.nlpManager.addDocument('en', 'show io for %appNameOrPid%', 'app.stats');

        this.nlpManager.addDocument('en', 'scan system errors', 'system.scan_errors');
        this.nlpManager.addDocument('en', 'check logs for errors', 'system.scan_errors');

        this.nlpManager.addDocument('en', 'research %query%', 'research.web');
        this.nlpManager.addDocument('en', 'find information on %query%', 'research.web');

        this.nlpManager.addDocument('en', 'summarize %text%', 'research.summarize');

        this.nlpManager.addDocument('en', 'check health of %appNameOrPid%', 'app.health');
        this.nlpManager.addDocument('en', 'is %appNameOrPid% running', 'app.health');

        this.nlpManager.addAnswer('en', 'app.list', 'Listing installed applications...');
        this.nlpManager.addAnswer('en', 'app.launch', 'Attempting to launch the application...');
        this.nlpManager.addAnswer('en', 'app.close', 'Attempting to close the application...');
        this.nlpManager.addAnswer('en', 'app.stats', 'Retrieving application statistics...');
        this.nlpManager.addAnswer('en', 'system.scan_errors', 'Scanning system logs for errors...');
        this.nlpManager.addAnswer('en', 'research.web', 'Performing web research...');
        this.nlpManager.addAnswer('en', 'research.summarize', 'Summarizing the provided text...');
        this.nlpManager.addAnswer('en', 'app.health', 'Checking application health...');

        await this.nlpManager.train();
        logToFile('info', 'NLP Manager trained.');
    }

    async executeCommand(commandText) {
        logToFile('info', `Received command: '${commandText}'`);
        const result = await this.nlpManager.process('en', commandText);
        const intent = result.intent;
        const entities = result.entities;
        const score = result.score;

        if (score < 0.7) { // Confidence threshold
            return chalk.yellow("I don't fully understand that command. Please try rephrasing.");
        }

        switch (intent) {
            case 'app.list':
                const apps = await this.appManager.listInstalledApps();
                return chalk.green("Installed applications:\n") + apps.join('\n');
            case 'app.launch':
                const appName = entities.find(e => e.entity === 'appName')?.utteranceText;
                if (appName) {
                    const success = await this.appManager.launchApp(appName);
                    return success ? chalk.green(`Attempting to launch ${appName}.`) : chalk.red(`Failed to launch ${appName}. Check name/path or permissions.`);
                }
                return chalk.red("Please specify an application to launch (e.g., 'launch app Notepad.exe').");
            case 'app.close':
                const appNameOrPidClose = entities.find(e => e.entity === 'appNameOrPid')?.utteranceText;
                if (appNameOrPidClose) {
                    const success = await this.appManager.closeApp(appNameOrPidClose);
                    return success ? chalk.green(`Attempting to close ${appNameOrPidClose}.`) : chalk.red(`Failed to close ${appNameOrPidClose}. App not found or permission denied.`);
                }
                return chalk.red("Please specify an application name or PID to close (e.g., 'close app Chrome' or 'close app 1234').");
            case 'app.stats':
                const appNameOrPidStats = entities.find(e => e.entity === 'appNameOrPid')?.utteranceText;
                if (appNameOrPidStats) {
                    const stats = await this.appManager.getAppReadWriteStats(appNameOrPidStats);
                    if (stats) {
                        return chalk.cyan(`I/O Stats for ${stats.name} (PID: ${stats.pid}):\n`) +
                               chalk.cyan(`  Read Bytes: ${stats.readBytes}\n`) +
                               chalk.cyan(`  Write Bytes: ${stats.writeBytes}`);
                    }
                    return chalk.red(`Could not get stats for ${appNameOrPidStats}. App not found or not running.`);
                }
                return chalk.red("Please specify an application name or PID for stats (e.g., 'app stats firefox' or 'app stats 5678').");
            case 'system.scan_errors':
                const errors = await this.errorScanner.scanSystemLogs();
                if (errors.length > 0) {
                    return chalk.yellow("Found potential errors in system logs:\n") + errors.join('\n');
                }
                return chalk.green("No significant errors found in system logs.");
            case 'research.web':
                const query = entities.find(e => e.entity === 'query')?.utteranceText;
                if (query) {
                    const results = await this.researcher.performWebSearch(query);
                    return chalk.blue("Research results:\n") + results.join('\n');
                }
                return chalk.red("Please provide a research query (e.g., 'research Node.js security best practices').");
            case 'research.summarize':
                const textToSummarize = entities.find(e => e.entity === 'text')?.utteranceText;
                if (textToSummarize) {
                    const summary = await this.researcher.summarizeText(textToSummarize);
                    return chalk.magenta(`Summary: ${summary}`);
                }
                return chalk.red("Please provide text to summarize (e.g., 'summarize The quick brown fox...').");
            case 'app.health':
                const appNameOrPidHealth = entities.find(e => e.entity === 'appNameOrPid')?.utteranceText;
                if (appNameOrPidHealth) {
                    const health = await this.errorScanner.checkApplicationHealth(appNameOrPidHealth);
                    if (health.running) {
                        return chalk.green(`${health.name} (PID: ${health.pid}) is running. CPU: ${health.cpuPercent.toFixed(2)}%, Memory: ${health.memoryPercent.toFixed(2)}%, Status: ${health.status}`);
                    }
                    return chalk.red(`${appNameOrPidHealth} is not running.`);
                }
                return chalk.red("Please specify an application name or PID to check health (e.g., 'check health Safari').");
            default:
                return chalk.grey("I'm not sure how to handle that. Try commands like 'list apps', 'launch app <name>', 'close app <name>', 'app stats <name>', 'scan errors', 'research <query>', 'summarize <text>', or 'check health <name>'.");
        }
    }
}

// --- Main Interaction Loop ---
async function main() {
    const assistant = new AIAssistant();
    console.log(chalk.bold.green("Advanced AI Assistant started. Type 'exit' to quit."));

    process.stdin.setEncoding('utf8');
    process.stdin.on('data', async (data) => {
        const userInput = data.toString().trim();
        if (userInput.toLowerCase() === 'exit' || userInput.toLowerCase() === 'quit') {
            console.log(chalk.bold.grey("Exiting assistant. Goodbye!"));
            process.exit(0);
        }
        const response = await assistant.executeCommand(userInput);
        console.log(chalk.bold.yellow("Assistant:"), response);
        process.stdout.write("You: "); // Prompt for next input
    });

    // Initial prompt
    process.stdout.write("You: ");
}

main().catch(error => {
    console.error(chalk.bgRed.white("An unhandled error occurred:"), error);
    logToFile('critical', `Unhandled error: ${error.message}\n${error.stack}`);
    process.exit(1);
});

3. Environment Variable (.env file or direct export)
To avoid hardcoding your OpenAI API key, create a .env file in the same directory as index.js:
OPENAI_API_KEY=sk-YOUR_ACTUAL_OPENAI_API_KEY

Then, you'll need to run your Node.js application using a tool like dotenv (though for this example, process.env will work if you set it before running, e.g., OPENAI_API_KEY=sk-xxxx node index.js). For simple testing, you can directly set OPENAI_API_KEY in index.js, but never commit it to version control.
To run the assistant:
 * Save the package.json and index.js files.
 * Open your terminal in the project directory.
 * Run npm install.
 * Set your OpenAI API key (e.g., export OPENAI_API_KEY='your_key_here' on Linux/macOS or set OPENAI_API_KEY=your_key_here on Windows, then run npm start).
 * Or, directly edit index.js to set OPENAI_API_KEY (for testing only, not recommended for production).
 * Run npm start.
Explanation and Key Considerations for a Real Node.js Assistant:
 * OS Interaction (AppManager):
   * Listing Apps:
     * get-installed-apps: This npm package simplifies cross-platform app listing for Windows and macOS by leveraging system APIs/commands. It's much better than raw exec for this purpose.
     * Linux: Still the trickiest. The dpkg -l command is a very basic example for Debian-based systems. A robust solution would involve parsing outputs from apt, snap, flatpak, dnf, yum, etc., or querying their databases.
   * Launching/Closing Apps: Uses child_process.spawn with detached: true and unref() to allow the launched app to run independently of the assistant process. start on Windows and open on macOS are the standard ways to launch GUI apps.
   * Read/Write Attributes (Per-App File Access):
     * systeminformation: This powerful npm package provides comprehensive system and process information, including rIO (read bytes) and wIO (written bytes) for processes. This gives you aggregated I/O statistics for a process, which is the most practical approach from user-space Node.js.
     * Granular File Monitoring: Node.js fs.watch() can detect file changes but cannot tell you which specific process performed the read/write. Truly granular, process-specific file I/O monitoring generally requires kernel-level drivers or OS-specific APIs (like Windows Filtering Platform, Linux fanotify), which are outside the scope of direct Node.js capabilities and would involve writing native C++ add-ons (using node-gyp) or integrating with external tools that provide this functionality. This remains the most significant technical hurdle for a "deep" monitoring solution.
 * Error Scanning (ErrorScanner):
   * Relies on child_process.exec to run platform-specific commands: powershell.exe for Windows Event Logs, log for macOS, and journalctl for Linux.
   * Parsing Output: The raw stdout needs to be parsed effectively. For Windows Event Logs, PowerShell output can be complex. You might consider using a dedicated npm package (if available) or more sophisticated parsing logic.
   * Robustness: Error handling for exec calls is crucial, as these commands might fail due to permissions or missing tools.
   * Application-Specific Logs: To scan errors within specific applications, you'd need to know where those applications store their logs and read/parse them directly using fs/promises.
 * Research (Researcher):
   * OpenAI Integration: Uses the @openai/api npm package for interacting with OpenAI's LLMs (like GPT-4o). This allows for summarization, Q&A, and simulating "research" by having the LLM generate concise answers based on its training data.
   * Real Web Search: For actual up-to-date web research, you would integrate with a dedicated search API (e.g., Google Custom Search API, SerpApi, Brave Search API) using axios or node-fetch. The current code uses OpenAI to simulate research based on its knowledge, which is different from live web scraping or API calls to search engines.
   * Context: For advanced research, the assistant would need to maintain conversation history and context for the LLM.
 * User Interface (AIAssistant and main):
   * node-nlp: This library is used for basic Natural Language Understanding (NLU), specifically for intent recognition (app.list, app.launch, etc.) and entity extraction (appName, query). This provides a more flexible command parsing than simple keyword matching.
   * Confidence Threshold: The result.score from node-nlp helps determine how confident the assistant is in its understanding of the command.
   * chalk: Used for colorful and more readable console output.
   * Command Line Interface: The process.stdin.on('data') sets up a basic interactive command-line loop.
Security Considerations (Crucial):
 * Elevated Privileges: Running this assistant with administrative privileges is almost certainly required for many of its functions (launching/closing arbitrary apps, reading system logs). This is a major security risk. Any vulnerability in your Node.js code could be exploited to gain full control of the system.
 * Input Validation: Never directly inject user input into shell commands. Always validate and sanitize inputs. The current child_process.exec and spawn calls attempt to use arguments safely (e.g., by quoting paths), but this needs meticulous attention.
 * API Keys: Use environment variables (like OPENAI_API_KEY) for sensitive information. Do NOT hardcode them or commit them to version control.
 * Error Handling: Robust error handling is essential to prevent crashes and provide meaningful feedback.
 * Least Privilege: Design the assistant so that it runs with the minimum necessary permissions. Consider specific capabilities rather than full admin rights if possible.
 * Sandboxing: Explore sandboxing mechanisms for executing potentially risky operations (e.g., launching downloaded files), though this is complex at the OS level.
Further Enhancements:
 * GUI: Implement a user-friendly graphical interface using Electron.
 * Voice Interface: Integrate with speech-to-text (STT) and text-to-speech (TTS) libraries/APIs.
 * Persistent Storage: Save configuration, learned preferences, or historical data.
 * Task Automation: Beyond just launching/closing, integrate with automation tools (e.g., Puppeteer for browser automation, or more advanced OS scripting).
 * Monitoring in Background: Implement background processes or services that continually monitor system logs or app behavior.
 * Proactive Suggestions: Use AI to proactively suggest actions based on detected errors or system state.
 * Extensibility: Design a plugin system to easily add new capabilities or integrate with more specific applications.
This Node.js structure provides a strong foundation, but remember that the "advanced" aspects, especially low-level OS interaction and deep AI integration, will require significant effort and careful handling of security.



# 1. Create a new Electron React project using Vite template
npm init electron-app@latest my-ai-assistant -- --template=vite-react-ts

# 2. Navigate into your project directory
cd my-ai-assistant

# 3. Install additional dependencies for system interaction and AI
npm install systeminformation get-installed-apps node-nlp openai axios chalk
# For `node-nlp` you might also need to install `fs-extra` if you face issues
# npm install fs-extra

# 4. For system command execution, you might also need to explicitly ensure `child_process`
# (It's usually available in Electron's main process, but good to be explicit for clarity)



You're aiming to build a sophisticated AI assistant with a user interface (UI) using React, but with the ability to interact deeply with the operating system. This implies building a desktop application, as web browsers (where standard React apps run) have severe security restrictions on accessing local files, running system commands, or monitoring other applications.
The ideal framework for this is Electron, which allows you to build cross-platform desktop applications using web technologies (HTML, CSS, and JavaScript/React). Electron embeds a Chromium browser (for rendering your React UI) and a Node.js runtime (for all the system-level interactions).
Here's a conceptual breakdown of the architecture and example React/Electron code:
Architecture Overview:
 * Electron Main Process (Node.js Environment):
   * This is the "backend" of your desktop app. It has full Node.js capabilities and can access system APIs, run shell commands, interact with the file system, and communicate with your AI models (or their APIs).
   * It will house the AppManager, ErrorScanner, and Researcher logic (similar to the Node.js example).
   * It uses ipcMain to communicate with the React frontend.
 * Electron Renderer Process (React UI):
   * This is the "frontend" where your React components live. It's essentially a web page running within Electron.
   * It handles all UI rendering, user input, and displays results.
   * It uses ipcRenderer to send requests to the main process and receive data back.
 * Preload Script:
   * A secure bridge between the renderer process (React) and the main process (Node.js).
   * It selectively exposes Node.js modules or functions to the renderer process, preventing direct access to the Node.js environment from the untrusted web content.
Project Setup (using Electron Forge for simplicity):
First, create an Electron-React project.
# 1. Create a new Electron React project using Vite template
npm init electron-app@latest my-ai-assistant -- --template=vite-react-ts

# 2. Navigate into your project directory
cd my-ai-assistant

# 3. Install additional dependencies for system interaction and AI
npm install systeminformation get-installed-apps node-nlp openai axios chalk
# For `node-nlp` you might also need to install `fs-extra` if you face issues
# npm install fs-extra

# 4. For system command execution, you might also need to explicitly ensure `child_process`
# (It's usually available in Electron's main process, but good to be explicit for clarity)

File Structure (simplified):
my-ai-assistant/
├── .gitignore
├── package.json
├── electron.vite.config.ts  # Electron Forge config
├── src/
│   ├── main/
│   │   ├── index.ts              # Electron Main Process code (Node.js logic)
│   │   └── api.ts                # System interaction logic (AppManager, ErrorScanner, Researcher)
│   ├── preload/
│   │   └── index.ts              # Preload script for secure communication
│   └── renderer/
│       ├── index.html
│       ├── src/                  # React app
│       │   ├── App.tsx
│       │   ├── main.tsx
│       │   ├── components/
│       │   │   └── AssistantChat.tsx
│       │   └── hooks/
│       │       └── useAssistantApi.ts
│       └── vite-env.d.ts
├── tsconfig.json
└── tsconfig.node.json

Code Generation:
1. src/main/api.ts (Electron Main Process - Backend Logic)
This file will contain the core system interaction logic. It's largely similar to the Node.js code from the previous response, adapted for TypeScript and Electron's IPC.
import { exec, spawn } from 'child_process';
import os from 'os';
import fs from 'fs/promises';
import { getInstalledApps, getWinInstalledApps, getMacInstalledApps } from 'get-installed-apps';
import si from 'systeminformation';
import { NlpManager } from 'node-nlp';
import { OpenAI } from 'openai';
import path from 'path'; // Node.js path module
import { app } from 'electron'; // Electron's app module for paths

// --- Configuration ---
const LOG_FILE = path.join(app.getPath('userData'), 'assistant_log.log');
const OPENAI_API_KEY = process.env.OPENAI_API_KEY || 'YOUR_OPENAI_API_KEY'; // Use environment variable!

// Set up simple logging to file
async function logToFile(level: string, message: string) {
    const timestamp = new Date().toISOString();
    const logMessage = `${timestamp} - ${level.toUpperCase()} - ${message}\n`;
    try {
        await fs.appendFile(LOG_FILE, logMessage);
    } catch (error: any) {
        console.error(`Failed to write to log file: ${error.message}`);
    }
}

interface AppInfo {
    id?: string;
    name: string;
    version?: string;
    publisher?: string;
    path?: string;
}

interface ProcessStats {
    pid: number;
    name: string;
    readBytes: number;
    writeBytes: number;
}

interface AppHealth {
    running: boolean;
    pid?: number;
    name?: string;
    cpuPercent?: number;
    memoryPercent?: number;
    status?: string;
}

class AppManager {
    private platform: NodeJS.Platform;

    constructor() {
        this.platform = os.platform();
        logToFile('info', `Initialized AppManager on ${this.platform}`);
    }

    async listInstalledApps(): Promise<AppInfo[]> {
        try {
            let apps: AppInfo[] = [];
            if (this.platform === 'win32') {
                const winApps = await getWinInstalledApps();
                apps = winApps.map(app => ({
                    name: app.displayName || 'Unknown',
                    version: app.displayVersion,
                    publisher: app.publisher,
                    id: app.installLocation || app.systemComponent // Use a more reliable ID if possible
                }));
            } else if (this.platform === 'darwin') {
                const macApps = await getMacInstalledApps();
                apps = macApps.map(app => ({
                    name: app.name,
                    path: app.path,
                    id: app.path // Use path as ID for macOS
                }));
            } else { // Linux
                // This is a very basic attempt for Linux. A real solution needs to parse package managers.
                try {
                    const { stdout } = await this.executeCommand('dpkg -l | grep "^ii" | awk \'{print $2}\'');
                    apps = stdout.split('\n').filter(Boolean).map(name => ({ name, id: name }));
                } catch (dpkgError) {
                    logToFile('warn', `dpkg command failed. Trying snap list...`);
                    try {
                         const { stdout } = await this.executeCommand('snap list | tail -n +2 | awk \'{print $1}\'');
                         apps = apps.concat(stdout.split('\n').filter(Boolean).map(name => ({ name: `Snap: ${name}`, id: `snap-${name}` })));
                    } catch (snapError) {
                        logToFile('error', `Failed to list Linux apps: ${dpkgError} and ${snapError}`);
                    }
                }
            }
            logToFile('info', `Listed ${apps.length} applications.`);
            return apps;
        } catch (error: any) {
            logToFile('error', `Error listing apps: ${error.message}`);
            return [];
        }
    }

    async launchApp(appPathOrName: string): Promise<boolean> {
        try {
            let command = '';
            let args: string[] = [];

            if (this.platform === 'win32') {
                command = 'start';
                args.push(`""`); // Empty title to handle paths with spaces
                args.push(`"${appPathOrName}"`);
            } else if (this.platform === 'darwin') {
                command = 'open';
                args.push(`-a`);
                args.push(appPathOrName);
            } else { // Linux
                command = appPathOrName; // Assumes it's in PATH or full path
            }

            const child = spawn(command, args, { detached: true, stdio: 'ignore', shell: true });
            child.unref();
            logToFile('info', `Attempted to launch: ${appPathOrName}`);
            return true;
        } catch (error: any) {
            logToFile('error', `Error launching ${appPathOrName}: ${error.message}`);
            return false;
        }
    }

    async closeApp(appNameOrPid: string): Promise<boolean> {
        try {
            const processes = await si.processes();
            let targetProcess = null;

            if (!isNaN(parseInt(appNameOrPid))) {
                targetProcess = processes.list.find(p => p.pid === parseInt(appNameOrPid));
            } else {
                targetProcess = processes.list.find(p => p.name.toLowerCase().includes(appNameOrPid.toLowerCase()));
            }

            if (targetProcess) {
                process.kill(targetProcess.pid, 'SIGTERM');
                logToFile('info', `Terminated process: ${targetProcess.name} (PID: ${targetProcess.pid})`);
                return true;
            } else {
                logToFile('warn', `Process not found: ${appNameOrPid}`);
                return false;
            }
        } catch (error: any) {
            logToFile('error', `Error closing ${appNameOrPid}: ${error.message}`);
            return false;
        }
    }

    async getAppReadWriteStats(appNameOrPid: string): Promise<ProcessStats | null> {
        try {
            const processes = await si.processes();
            let targetProcess = null;

            if (!isNaN(parseInt(appNameOrPid))) {
                targetProcess = processes.list.find(p => p.pid === parseInt(appNameOrPid));
            } else {
                targetProcess = processes.list.find(p => p.name.toLowerCase().includes(appNameOrPid.toLowerCase()));
            }

            if (targetProcess) {
                logToFile('info', `Retrieved I/O stats for '${targetProcess.name}' (PID: ${targetProcess.pid}): Read: ${targetProcess.rIO} bytes, Write: ${targetProcess.wIO} bytes`);
                return {
                    pid: targetProcess.pid,
                    name: targetProcess.name,
                    readBytes: targetProcess.rIO,
                    writeBytes: targetProcess.wIO
                };
            }
            logToFile('warn', `Could not find process to get I/O stats: ${appNameOrPid}`);
            return null;
        } catch (error: any) {
            logToFile('error', `Error getting I/O stats for ${appNameOrPid}: ${error.message}`);
            return null;
        }
    }

    private executeCommand(command: string): Promise<{ stdout: string; stderr: string }> {
        return new Promise((resolve, reject) => {
            exec(command, (error, stdout, stderr) => {
                if (error) {
                    reject(new Error(`Command failed: ${command}\n${stderr}`));
                } else {
                    resolve({ stdout, stderr });
                }
            });
        });
    }
}

class ErrorScanner {
    constructor() {
        logToFile('info', 'Initialized ErrorScanner.');
    }

    async scanSystemLogs(keywords: string[] = ['error', 'fail', 'critical']): Promise<string[]> {
        let errorsFound: string[] = [];
        let command = '';
        let args: string[] = [];

        if (os.platform() === 'win32') {
            command = 'powershell.exe';
            args = [
                '-Command',
                `Get-WinEvent -LogName Application,System -ErrorAction SilentlyContinue | Where-Object {($_.Message -match '${keywords.join('|')}') -or ($_.LevelDisplayName -match 'Error' -or $_.LevelDisplayName -match 'Critical')} | Select-Object -First 20 Message | Format-List`
            ];
        } else if (os.platform() === 'darwin') {
            command = 'log';
            args = [
                'show', '--last', '1h', '--predicate',
                `eventType == error OR eventType == fault OR (message CONTAINS "${keywords.join('" OR message CONTAINS "')}")`
            ];
        } else { // Linux
            command = 'journalctl';
            args = ['-p', 'err', '-n', '50', '--no-pager'];
        }

        try {
            const { stdout } = await new Promise<{ stdout: string; stderr: string }>((resolve, reject) => {
                exec(`${command} ${args.join(' ')}`, (error, stdout, stderr) => {
                    if (error) {
                        logToFile('error', `Error scanning system logs: ${stderr}`);
                        reject(error);
                    } else {
                        resolve({ stdout, stderr });
                    }
                });
            });
            errorsFound = stdout.split('\n').filter(line => line.trim() !== '');
            logToFile('info', `Scanned system logs. Found ${errorsFound.length} potential errors.`);
            return errorsFound.slice(0, 10);
        } catch (error: any) {
            logToFile('error', `Failed to scan system logs: ${error.message}`);
            return [`Could not scan system logs: ${error.message}`];
        }
    }

    async checkApplicationHealth(appNameOrPid: string): Promise<AppHealth> {
        try {
            const processes = await si.processes();
            let targetProcess = null;

            if (!isNaN(parseInt(appNameOrPid))) {
                targetProcess = processes.list.find(p => p.pid === parseInt(appNameOrPid));
            } else {
                targetProcess = processes.list.find(p => p.name.toLowerCase().includes(appNameOrPid.toLowerCase()));
            }

            if (targetProcess) {
                logToFile('info', `Health check for '${targetProcess.name}' (PID: ${targetProcess.pid}): CPU: ${targetProcess.cpu.toFixed(2)}%, Memory: ${targetProcess.mem.toFixed(2)}%, Status: ${targetProcess.status}`);
                return {
                    running: true,
                    pid: targetProcess.pid,
                    name: targetProcess.name,
                    cpuPercent: targetProcess.cpu,
                    memoryPercent: targetProcess.mem,
                    status: targetProcess.status
                };
            }
            logToFile('warn', `Application not found for health check: ${appNameOrPid}`);
            return { running: false };
        } catch (error: any) {
            logToFile('error', `Error checking health for ${appNameOrPid}: ${error.message}`);
            return { running: false };
        }
    }
}

class Researcher {
    private openai: OpenAI;
    private hasOpenAI: boolean;

    constructor(apiKey: string) {
        this.openai = new OpenAI({ apiKey: apiKey });
        this.hasOpenAI = !!apiKey;
        logToFile('info', `Initialized Researcher. OpenAI enabled: ${this.hasOpenAI}`);
    }

    async performWebSearch(query: string): Promise<string[]> {
        logToFile('info', `Performing simulated web search for: '${query}'`);
        if (!this.hasOpenAI) {
            logToFile('warn', 'OpenAI API key not provided. Web search will be a placeholder.');
            return [`Simulated search result 1 for '${query}'`, `Simulated search result 2 for '${query}'`];
        }

        try {
            const completion = await this.openai.chat.completions.create({
                model: "gpt-4o",
                messages: [
                    { role: "system", content: "You are a helpful assistant that provides concise research results." },
                    { role: "user", content: `Provide a concise summary of research on: ${query}` }
                ],
                max_tokens: 300,
            });
            const result = completion.choices[0]?.message?.content || "No research results found.";
            return [`AI-generated research result: ${result}`];
        } catch (error: any) {
            logToFile('error', `Error during OpenAI web search simulation for '${query}': ${error.message}`);
            return [`Error retrieving AI-generated research results for '${query}'.`];
        }
    }

    async summarizeText(text: string): Promise<string> {
        if (!this.hasOpenAI) {
            logToFile('warn', 'OpenAI API key not provided. Summarization will be a placeholder.');
            return `Summary of: ${text.substring(0, 100)}... (OpenAI not configured)`;
        }

        try {
            const completion = await this.openai.chat.completions.create({
                model: "gpt-4o",
                messages: [
                    { role: "system", content: "You are a helpful assistant that summarizes text concisely." },
                    { role: "user", content: `Summarize the following text:\n\n${text}` }
                ],
                max_tokens: 200,
            });
            return completion.choices[0]?.message?.content || "Could not generate summary.";
        } catch (error: any) {
            logToFile('error', `Error during text summarization: ${error.message}`);
            return `Failed to summarize text: ${error.message}`;
        }
    }
}

export class AIAssistantCore {
    private appManager: AppManager;
    private errorScanner: ErrorScanner;
    private researcher: Researcher;
    private nlpManager: NlpManager;

    constructor() {
        this.appManager = new AppManager();
        this.errorScanner = new ErrorScanner();
        this.researcher = new Researcher(OPENAI_API_KEY);
        this.nlpManager = new NlpManager({ languages: ['en'], forceNER: true });
        this.setupNlpManager(); // Call setup as part of construction

        logToFile('info', 'AI Assistant Core initialized.');
    }

    private async setupNlpManager() {
        this.nlpManager.addDocument('en', 'list installed apps', 'app.list');
        this.nlpManager.addDocument('en', 'show me my applications', 'app.list');

        this.nlpManager.addDocument('en', 'launch app %appName%', 'app.launch');
        this.nlpManager.addDocument('en', 'open %appName%', 'app.launch');

        this.nlpManager.addDocument('en', 'close app %appNameOrPid%', 'app.close');
        this.nlpManager.addDocument('en', 'terminate %appNameOrPid%', 'app.close');

        this.nlpManager.addDocument('en', 'get app stats for %appNameOrPid%', 'app.stats');
        this.nlpManager.addDocument('en', 'show io for %appNameOrPid%', 'app.stats');

        this.nlpManager.addDocument('en', 'scan system errors', 'system.scan_errors');
        this.nlpManager.addDocument('en', 'check logs for errors', 'system.scan_errors');

        this.nlpManager.addDocument('en', 'research %query%', 'research.web');
        this.nlpManager.addDocument('en', 'find information on %query%', 'research.web');

        this.nlpManager.addDocument('en', 'summarize %text%', 'research.summarize');

        this.nlpManager.addDocument('en', 'check health of %appNameOrPid%', 'app.health');
        this.nlpManager.addDocument('en', 'is %appNameOrPid% running', 'app.health');

        this.nlpManager.addAnswer('en', 'app.list', 'Listing installed applications...');
        this.nlpManager.addAnswer('en', 'app.launch', 'Attempting to launch the application...');
        this.nlpManager.addAnswer('en', 'app.close', 'Attempting to close the application...');
        this.nlpManager.addAnswer('en', 'app.stats', 'Retrieving application statistics...');
        this.nlpManager.addAnswer('en', 'system.scan_errors', 'Scanning system logs for errors...');
        this.nlpManager.addAnswer('en', 'research.web', 'Performing web research...');
        this.nlpManager.addAnswer('en', 'research.summarize', 'Summarizing the provided text...');
        this.nlpManager.addAnswer('en', 'app.health', 'Checking application health...');

        await this.nlpManager.train();
        logToFile('info', 'NLP Manager trained.');
    }

    async processCommand(commandText: string): Promise<string> {
        logToFile('info', `Processing command: '${commandText}'`);
        const result = await this.nlpManager.process('en', commandText);
        const intent = result.intent;
        const entities = result.entities;
        const score = result.score;

        if (score < 0.7) {
            return "I don't fully understand that command. Please try rephrasing.";
        }

        const getEntity = (entityName: string) => entities.find(e => e.entity === entityName)?.utteranceText;

        switch (intent) {
            case 'app.list':
                const apps = await this.appManager.listInstalledApps();
                return "Installed applications:\n" + apps.map(app => app.name).join('\n');
            case 'app.launch':
                const appName = getEntity('appName');
                if (appName) {
                    const success = await this.appManager.launchApp(appName);
                    return success ? `Attempting to launch ${appName}.` : `Failed to launch ${appName}. Check name/path or permissions.`;
                }
                return "Please specify an application to launch (e.g., 'launch app Notepad.exe').";
            case 'app.close':
                const appNameOrPidClose = getEntity('appNameOrPid');
                if (appNameOrPidClose) {
                    const success = await this.appManager.closeApp(appNameOrPidClose);
                    return success ? `Attempting to close ${appNameOrPidClose}.` : `Failed to close ${appNameOrPidClose}. App not found or permission denied.`;
                }
                return "Please specify an application name or PID to close (e.g., 'close app Chrome' or 'close app 1234').";
            case 'app.stats':
                const appNameOrPidStats = getEntity('appNameOrPid');
                if (appNameOrPidStats) {
                    const stats = await this.appManager.getAppReadWriteStats(appNameOrPidStats);
                    if (stats) {
                        return (
                            `I/O Stats for ${stats.name} (PID: ${stats.pid}):\n` +
                            `  Read Bytes: ${stats.readBytes}\n` +
                            `  Write Bytes: ${stats.writeBytes}`
                        );
                    }
                    return `Could not get stats for ${appNameOrPidStats}. App not found or not running.`;
                }
                return "Please specify an application name or PID for stats (e.g., 'app stats firefox' or 'app stats 5678').";
            case 'system.scan_errors':
                const errors = await this.errorScanner.scanSystemLogs();
                if (errors.length > 0) {
                    return "Found potential errors in system logs:\n" + errors.join('\n');
                }
                return "No significant errors found in system logs.";
            case 'research.web':
                const query = getEntity('query');
                if (query) {
                    const results = await this.researcher.performWebSearch(query);
                    return "Research results:\n" + results.join('\n');
                }
                return "Please provide a research query (e.g., 'research Node.js security best practices').";
            case 'research.summarize':
                const textToSummarize = getEntity('text');
                if (textToSummarize) {
                    const summary = await this.researcher.summarizeText(textToSummarize);
                    return `Summary: ${summary}`;
                }
                return "Please provide text to summarize (e.g., 'summarize The quick brown fox...').";
            case 'app.health':
                const appNameOrPidHealth = getEntity('appNameOrPid');
                if (appNameOrPidHealth) {
                    const health = await this.errorScanner.checkApplicationHealth(appNameOrPidHealth);
                    if (health.running) {
                        return `${health.name} (PID: ${health.pid}) is running. CPU: ${health.cpuPercent?.toFixed(2)}%, Memory: ${health.memoryPercent?.toFixed(2)}%, Status: ${health.status}`;
                    }
                    return `${appNameOrPidHealth} is not running.`;
                }
                return "Please specify an application name or PID to check health (e.g., 'check health Safari').";
            default:
                return "I'm not sure how to handle that. Try commands like 'list apps', 'launch app <name>', 'close app <name>', 'app stats <name>', 'scan errors', 'research <query>', 'summarize <text>', or 'check health <name>'.";
        }
    }
}

2. src/main/index.ts (Electron Main Process - Entry Point)
This file sets up the Electron window and the IPC communication.
import { app, BrowserWindow, ipcMain } from 'electron';
import path from 'path';
import { AIAssistantCore } from './api';

// Handle creating/removing shortcuts on Windows when installing/uninstalling.
if (require('electron-squirrel-startup')) {
  app.quit();
}

const createWindow = () => {
  // Create the browser window.
  const mainWindow = new BrowserWindow({
    width: 900,
    height: 700,
    minWidth: 700,
    minHeight: 500,
    webPreferences: {
      preload: path.join(__dirname, '../preload/index.js'),
      // IMPORTANT: Context Isolation should be true for security!
      // NodeIntegration should be false. Preload script is the safe way.
      contextIsolation: true,
      nodeIntegration: false,
      sandbox: false // Set to false if you need access to more Node.js APIs in preload directly, but use with caution.
                    // For this example, keep it false as systeminformation might need broader access.
    },
  });

  // Load the React app.
  if (MAIN_WINDOW_VITE_DEV_SERVER_URL) {
    mainWindow.loadURL(MAIN_WINDOW_VITE_DEV_SERVER_URL);
  } else {
    mainWindow.loadFile(path.join(__dirname, '../renderer/index.html'));
  }

  // Open the DevTools.
  // mainWindow.webContents.openDevTools();
};

// This method will be called when Electron has finished
// initialization and is ready to create browser windows.
// Some APIs can only be used after this event occurs.
app.on('ready', () => {
    createWindow();

    // Initialize the AI Assistant Core
    const assistantCore = new AIAssistantCore();

    // IPC Handler for commands from React renderer
    ipcMain.handle('assistant-command', async (event, commandText: string) => {
        return await assistantCore.processCommand(commandText);
    });
});

// Quit when all windows are closed, except on macOS. There, it's common
// for applications and their menu bar to stay active until the user quits
// explicitly with Cmd + Q.
app.on('window-all-closed', () => {
  if (process.platform !== 'darwin') {
    app.quit();
  }
});

app.on('activate', () => {
  // On OS X it's common to re-create a window in the app when the
  // dock icon is clicked and there are no other windows open.
  if (BrowserWindow.getAllWindows().length === 0) {
    createWindow();
  }
});

// In this file you can include the rest of your app's specific main process
// code. You can also put them in separate files and import them here.

3. src/preload/index.ts (Preload Script - Secure Bridge)
This script runs before the renderer process's web content is loaded. It's crucial for security as it exposes only specific functions from the Node.js context to the React frontend.
import { contextBridge, ipcRenderer } from 'electron';

// Expose a safe, limited API to the renderer process
contextBridge.exposeInMainWorld('electronAPI', {
    // Function to send a command to the main process and get a response
    sendAssistantCommand: (commandText: string) => ipcRenderer.invoke('assistant-command', commandText),
    // You could add other specific functions here if needed, e.g., to request logging or app lists
});

4. src/renderer/vite-env.d.ts (Type Declaration for Preload API)
Add this to ensure TypeScript knows about the electronAPI you're exposing.
/// <reference types="vite/client" />

interface Window {
  electronAPI: {
    sendAssistantCommand: (commandText: string) => Promise<string>;
  };
}

5. src/renderer/src/App.tsx (React Component - UI)
import React, { useState, FormEvent, useEffect, useRef } from 'react';
import './App.css'; // Add some basic CSS later

interface Message {
  type: 'user' | 'assistant';
  text: string;
}

function App() {
  const [input, setInput] = useState<string>('');
  const [messages, setMessages] = useState<Message[]>([]);
  const [isLoading, setIsLoading] = useState<boolean>(false);
  const messagesEndRef = useRef<HTMLDivElement>(null);

  const scrollToBottom = () => {
    messagesEndRef.current?.scrollIntoView({ behavior: 'smooth' });
  };

  useEffect(() => {
    scrollToBottom();
  }, [messages]);

  const handleSendMessage = async (e: FormEvent) => {
    e.preventDefault();
    if (input.trim() === '') return;

    const userMessage: Message = { type: 'user', text: input };
    setMessages((prev) => [...prev, userMessage]);
    setInput('');
    setIsLoading(true);

    try {
      // Send command to Electron main process
      const response = await window.electronAPI.sendAssistantCommand(input);
      const assistantMessage: Message = { type: 'assistant', text: response };
      setMessages((prev) => [...prev, assistantMessage]);
    } catch (error: any) {
      console.error("Error sending command to main process:", error);
      const errorMessage: Message = { type: 'assistant', text: `Error: ${error.message || "Failed to get response."}` };
      setMessages((prev) => [...prev, errorMessage]);
    } finally {
      setIsLoading(false);
    }
  };

  return (
    <div className="app-container">
      <header className="app-header">
        <h1>Advanced AI Assistant</h1>
      </header>
      <div className="chat-window">
        {messages.map((msg, index) => (
          <div key={index} className={`message ${msg.type}`}>
            <span className="sender">{msg.type === 'user' ? 'You:' : 'Assistant:'}</span> {msg.text}
          </div>
        ))}
        {isLoading && (
          <div className="message assistant loading">
            <span className="sender">Assistant:</span> Thinking...
          </div>
        )}
        <div ref={messagesEndRef} />
      </div>
      <form onSubmit={handleSendMessage} className="input-form">
        <input
          type="text"
          value={input}
          onChange={(e) => setInput(e.target.value)}
          placeholder="Type your command..."
          disabled={isLoading}
        />
        <button type="submit" disabled={isLoading}>Send</button>
      </form>
    </div>
  );
}

export default App;

6. src/renderer/src/App.css (Basic Styling)
body {
  font-family: Arial, sans-serif;
  margin: 0;
  padding: 0;
  background-color: #f4f4f4;
  display: flex;
  justify-content: center;
  align-items: center;
  min-height: 100vh;
}

#root {
  width: 100%;
  height: 100vh;
  display: flex;
  justify-content: center;
  align-items: center;
}

.app-container {
  background-color: #fff;
  border-radius: 8px;
  box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
  width: 90%;
  max-width: 800px;
  height: 90vh;
  display: flex;
  flex-direction: column;
  overflow: hidden;
}

.app-header {
  background-color: #333;
  color: white;
  padding: 15px;
  text-align: center;
  border-top-left-radius: 8px;
  border-top-right-radius: 8px;
}

.chat-window {
  flex-grow: 1;
  padding: 20px;
  overflow-y: auto;
  display: flex;
  flex-direction: column;
  gap: 10px;
  background-color: #e9eff2;
}

.message {
  padding: 10px 15px;
  border-radius: 15px;
  max-width: 80%;
  word-wrap: break-word;
}

.message.user {
  background-color: #007bff;
  color: white;
  align-self: flex-end;
  border-bottom-right-radius: 2px;
}

.message.assistant {
  background-color: #f0f0f0;
  color: #333;
  align-self: flex-start;
  border-bottom-left-radius: 2px;
}

.message .sender {
  font-weight: bold;
  margin-right: 5px;
}

.input-form {
  display: flex;
  padding: 15px;
  border-top: 1px solid #eee;
  background-color: #fff;
}

.input-form input {
  flex-grow: 1;
  padding: 10px 15px;
  border: 1px solid #ddd;
  border-radius: 20px;
  margin-right: 10px;
  font-size: 16px;
}

.input-form button {
  background-color: #28a745;
  color: white;
  border: none;
  padding: 10px 20px;
  border-radius: 20px;
  cursor: pointer;
  font-size: 16px;
  transition: background-color 0.2s ease;
}

.input-form button:hover:not(:disabled) {
  background-color: #218838;
}

.input-form button:disabled {
  background-color: #cccccc;
  cursor: not-allowed;
}

.message.assistant.loading {
    font-style: italic;
    color: #666;
    animation: pulse 1.5s infinite;
}

@keyframes pulse {
    0% { opacity: 0.7; }
    50% { opacity: 1; }
    100% { opacity: 0.7; }
}

How to Run:
 * Install dependencies:
   npm install

 * Set your OpenAI API Key:
   Create a .env file in your project root (my-ai-assistant/) and add:
   OPENAI_API_KEY=sk-YOUR_ACTUAL_OPENAI_API_KEY

   Alternatively, set it directly in your environment before running Electron (e.g., export OPENAI_API_KEY='...' on Linux/macOS, or set OPENAI_API_KEY='...' on Windows).
   Important: For electron.vite.config.ts, you might need to use a plugin like vite-plugin-env-compatible or manually expose the environment variable to the main process for process.env.OPENAI_API_KEY to be picked up. A simpler way for a quick test is to hardcode it in src/main/api.ts (but remove it for any real deployment!).
 * Start the development server:
   npm run dev

   This will start both the React development server and the Electron application.
Key Points and Further Development:
 * IPC (Inter-Process Communication): The core of Electron development is understanding ipcMain (main process listens, sends replies) and ipcRenderer (renderer process sends messages, listens for replies). This separation is vital for security and prevents your UI code from directly accessing Node.js APIs.
 * Security (Preload Script & Context Isolation): The preload/index.ts script is crucial. It uses contextBridge.exposeInMainWorld to create a safe API that your React app can use to interact with the Electron main process. This means your React code cannot directly use require('fs') or child_process, preventing potential vulnerabilities if malicious code were to be injected into your renderer.
 * Error Handling: The current code has basic try...catch blocks. For a production app, you'd want more robust error logging, user-friendly error messages, and perhaps a way to report issues.
 * UI/UX: The React UI is very basic. You'd want to enhance it with:
   * Better styling (using Tailwind CSS, Material UI, Chakra UI, etc.).
   * Clearer visual feedback for loading states, errors, and successful operations.
   * More structured display of results (e.g., tables for app lists, formatted logs, expandable research results).
   * Input validation and suggestions.
 * Loading States: The isLoading state is implemented to disable input while waiting for a response.
 * System Interaction Depth:
   * File I/O Monitoring: As mentioned in previous responses, truly granular, per-process file read/write monitoring is extremely difficult from user-space (even with Electron/Node.js) and typically requires low-level OS APIs or kernel modules. systeminformation gives you aggregated I/O.
   * Advanced App Control: For things like "modifying app attributes" (which could mean configuration files), you'd use fs/promises in the main process to read/write specific configuration files for known applications. This requires knowing the app's configuration file locations and formats.
 * AI Integration: The Researcher class uses OpenAI's API. You could integrate other LLMs, local models (if powerful enough), or a chain of tools (e.g., a web search API combined with an LLM for summarization).
 * Scalability: For more complex NLP or AI logic, consider running a separate local Python/Flask backend and having your Electron app communicate with it (via HTTP or gRPC), allowing you to leverage Python's rich AI ecosystem while keeping your Electron app lean.
This React/Electron setup provides a strong foundation for building a powerful desktop AI assistant.



import { exec, spawn } from 'child_process';
import os from 'os';
import fs from 'fs/promises';
import { getInstalledApps, getWinInstalledApps, getMacInstalledApps } from 'get-installed-apps';
import si from 'systeminformation';
import { NlpManager } from 'node-nlp';
import { OpenAI } from 'openai';
import path from 'path'; // Node.js path module
import { app } from 'electron'; // Electron's app module for paths

// --- Configuration ---
const LOG_FILE = path.join(app.getPath('userData'), 'assistant_log.log');
const OPENAI_API_KEY = process.env.OPENAI_API_KEY || 'YOUR_OPENAI_API_KEY'; // Use environment variable!

// Set up simple logging to file
async function logToFile(level: string, message: string) {
    const timestamp = new Date().toISOString();
    const logMessage = `${timestamp} - ${level.toUpperCase()} - ${message}\n`;
    try {
        await fs.appendFile(LOG_FILE, logMessage);
    } catch (error: any) {
        console.error(`Failed to write to log file: ${error.message}`);
    }
}

interface AppInfo {
    id?: string;
    name: string;
    version?: string;
    publisher?: string;
    path?: string;
}

interface ProcessStats {
    pid: number;
    name: string;
    readBytes: number;
    writeBytes: number;
}

interface AppHealth {
    running: boolean;
    pid?: number;
    name?: string;
    cpuPercent?: number;
    memoryPercent?: number;
    status?: string;
}

class AppManager {
    private platform: NodeJS.Platform;

    constructor() {
        this.platform = os.platform();
        logToFile('info', `Initialized AppManager on ${this.platform}`);
    }

    async listInstalledApps(): Promise<AppInfo[]> {
        try {
            let apps: AppInfo[] = [];
            if (this.platform === 'win32') {
                const winApps = await getWinInstalledApps();
                apps = winApps.map(app => ({
                    name: app.displayName || 'Unknown',
                    version: app.displayVersion,
                    publisher: app.publisher,
                    id: app.installLocation || app.systemComponent // Use a more reliable ID if possible
                }));
            } else if (this.platform === 'darwin') {
                const macApps = await getMacInstalledApps();
                apps = macApps.map(app => ({
                    name: app.name,
                    path: app.path,
                    id: app.path // Use path as ID for macOS
                }));
            } else { // Linux
                // This is a very basic attempt for Linux. A real solution needs to parse package managers.
                try {
                    const { stdout } = await this.executeCommand('dpkg -l | grep "^ii" | awk \'{print $2}\'');
                    apps = stdout.split('\n').filter(Boolean).map(name => ({ name, id: name }));
                } catch (dpkgError) {
                    logToFile('warn', `dpkg command failed. Trying snap list...`);
                    try {
                         const { stdout } = await this.executeCommand('snap list | tail -n +2 | awk \'{print $1}\'');
                         apps = apps.concat(stdout.split('\n').filter(Boolean).map(name => ({ name: `Snap: ${name}`, id: `snap-${name}` })));
                    } catch (snapError) {
                        logToFile('error', `Failed to list Linux apps: ${dpkgError} and ${snapError}`);
                    }
                }
            }
            logToFile('info', `Listed ${apps.length} applications.`);
            return apps;
        } catch (error: any) {
            logToFile('error', `Error listing apps: ${error.message}`);
            return [];
        }
    }

    async launchApp(appPathOrName: string): Promise<boolean> {
        try {
            let command = '';
            let args: string[] = [];

            if (this.platform === 'win32') {
                command = 'start';
                args.push(`""`); // Empty title to handle paths with spaces
                args.push(`"${appPathOrName}"`);
            } else if (this.platform === 'darwin') {
                command = 'open';
                args.push(`-a`);
                args.push(appPathOrName);
            } else { // Linux
                command = appPathOrName; // Assumes it's in PATH or full path
            }

            const child = spawn(command, args, { detached: true, stdio: 'ignore', shell: true });
            child.unref();
            logToFile('info', `Attempted to launch: ${appPathOrName}`);
            return true;
        } catch (error: any) {
            logToFile('error', `Error launching ${appPathOrName}: ${error.message}`);
            return false;
        }
    }

    async closeApp(appNameOrPid: string): Promise<boolean> {
        try {
            const processes = await si.processes();
            let targetProcess = null;

            if (!isNaN(parseInt(appNameOrPid))) {
                targetProcess = processes.list.find(p => p.pid === parseInt(appNameOrPid));
            } else {
                targetProcess = processes.list.find(p => p.name.toLowerCase().includes(appNameOrPid.toLowerCase()));
            }

            if (targetProcess) {
                process.kill(targetProcess.pid, 'SIGTERM');
                logToFile('info', `Terminated process: ${targetProcess.name} (PID: ${targetProcess.pid})`);
                return true;
            } else {
                logToFile('warn', `Process not found: ${appNameOrPid}`);
                return false;
            }
        } catch (error: any) {
            logToFile('error', `Error closing ${appNameOrPid}: ${error.message}`);
            return false;
        }
    }

    async getAppReadWriteStats(appNameOrPid: string): Promise<ProcessStats | null> {
        try {
            const processes = await si.processes();
            let targetProcess = null;

            if (!isNaN(parseInt(appNameOrPid))) {
                targetProcess = processes.list.find(p => p.pid === parseInt(appNameOrPid));
            } else {
                targetProcess = processes.list.find(p => p.name.toLowerCase().includes(appNameOrPid.toLowerCase()));
            }

            if (targetProcess) {
                logToFile('info', `Retrieved I/O stats for '${targetProcess.name}' (PID: ${targetProcess.pid}): Read: ${targetProcess.rIO} bytes, Write: ${targetProcess.wIO} bytes`);
                return {
                    pid: targetProcess.pid,
                    name: targetProcess.name,
                    readBytes: targetProcess.rIO,
                    writeBytes: targetProcess.wIO
                };
            }
            logToFile('warn', `Could not find process to get I/O stats: ${appNameOrPid}`);
            return null;
        } catch (error: any) {
            logToFile('error', `Error getting I/O stats for ${appNameOrPid}: ${error.message}`);
            return null;
        }
    }

    private executeCommand(command: string): Promise<{ stdout: string; stderr: string }> {
        return new Promise((resolve, reject) => {
            exec(command, (error, stdout, stderr) => {
                if (error) {
                    reject(new Error(`Command failed: ${command}\n${stderr}`));
                } else {
                    resolve({ stdout, stderr });
                }
            });
        });
    }
}

class ErrorScanner {
    constructor() {
        logToFile('info', 'Initialized ErrorScanner.');
    }

    async scanSystemLogs(keywords: string[] = ['error', 'fail', 'critical']): Promise<string[]> {
        let errorsFound: string[] = [];
        let command = '';
        let args: string[] = [];

        if (os.platform() === 'win32') {
            command = 'powershell.exe';
            args = [
                '-Command',
                `Get-WinEvent -LogName Application,System -ErrorAction SilentlyContinue | Where-Object {($_.Message -match '${keywords.join('|')}') -or ($_.LevelDisplayName -match 'Error' -or $_.LevelDisplayName -match 'Critical')} | Select-Object -First 20 Message | Format-List`
            ];
        } else if (os.platform() === 'darwin') {
            command = 'log';
            args = [
                'show', '--last', '1h', '--predicate',
                `eventType == error OR eventType == fault OR (message CONTAINS "${keywords.join('" OR message CONTAINS "')}")`
            ];
        } else { // Linux
            command = 'journalctl';
            args = ['-p', 'err', '-n', '50', '--no-pager'];
        }

        try {
            const { stdout } = await new Promise<{ stdout: string; stderr: string }>((resolve, reject) => {
                exec(`${command} ${args.join(' ')}`, (error, stdout, stderr) => {
                    if (error) {
                        logToFile('error', `Error scanning system logs: ${stderr}`);
                        reject(error);
                    } else {
                        resolve({ stdout, stderr });
                    }
                });
            });
            errorsFound = stdout.split('\n').filter(line => line.trim() !== '');
            logToFile('info', `Scanned system logs. Found ${errorsFound.length} potential errors.`);
            return errorsFound.slice(0, 10);
        } catch (error: any) {
            logToFile('error', `Failed to scan system logs: ${error.message}`);
            return [`Could not scan system logs: ${error.message}`];
        }
    }

    async checkApplicationHealth(appNameOrPid: string): Promise<AppHealth> {
        try {
            const processes = await si.processes();
            let targetProcess = null;

            if (!isNaN(parseInt(appNameOrPid))) {
                targetProcess = processes.list.find(p => p.pid === parseInt(appNameOrPid));
            } else {
                targetProcess = processes.list.find(p => p.name.toLowerCase().includes(appNameOrPid.toLowerCase()));
            }

            if (targetProcess) {
                logToFile('info', `Health check for '${targetProcess.name}' (PID: ${targetProcess.pid}): CPU: ${targetProcess.cpu.toFixed(2)}%, Memory: ${targetProcess.mem.toFixed(2)}%, Status: ${targetProcess.status}`);
                return {
                    running: true,
                    pid: targetProcess.pid,
                    name: targetProcess.name,
                    cpuPercent: targetProcess.cpu,
                    memoryPercent: targetProcess.mem,
                    status: targetProcess.status
                };
            }
            logToFile('warn', `Application not found for health check: ${appNameOrPid}`);
            return { running: false };
        } catch (error: any) {
            logToFile('error', `Error checking health for ${appNameOrPid}: ${error.message}`);
            return { running: false };
        }
    }
}

class Researcher {
    private openai: OpenAI;
    private hasOpenAI: boolean;

    constructor(apiKey: string) {
        this.openai = new OpenAI({ apiKey: apiKey });
        this.hasOpenAI = !!apiKey;
        logToFile('info', `Initialized Researcher. OpenAI enabled: ${this.hasOpenAI}`);
    }

    async performWebSearch(query: string): Promise<string[]> {
        logToFile('info', `Performing simulated web search for: '${query}'`);
        if (!this.hasOpenAI) {
            logToFile('warn', 'OpenAI API key not provided. Web search will be a placeholder.');
            return [`Simulated search result 1 for '${query}'`, `Simulated search result 2 for '${query}'`];
        }

        try {
            const completion = await this.openai.chat.completions.create({
                model: "gpt-4o",
                messages: [
                    { role: "system", content: "You are a helpful assistant that provides concise research results." },
                    { role: "user", content: `Provide a concise summary of research on: ${query}` }
                ],
                max_tokens: 300,
            });
            const result = completion.choices[0]?.message?.content || "No research results found.";
            return [`AI-generated research result: ${result}`];
        } catch (error: any) {
            logToFile('error', `Error during OpenAI web search simulation for '${query}': ${error.message}`);
            return [`Error retrieving AI-generated research results for '${query}'.`];
        }
    }

    async summarizeText(text: string): Promise<string> {
        if (!this.hasOpenAI) {
            logToFile('warn', 'OpenAI API key not provided. Summarization will be a placeholder.');
            return `Summary of: ${text.substring(0, 100)}... (OpenAI not configured)`;
        }

        try {
            const completion = await this.openai.chat.completions.create({
                model: "gpt-4o",
                messages: [
                    { role: "system", content: "You are a helpful assistant that summarizes text concisely." },
                    { role: "user", content: `Summarize the following text:\n\n${text}` }
                ],
                max_tokens: 200,
            });
            return completion.choices[0]?.message?.content || "Could not generate summary.";
        } catch (error: any) {
            logToFile('error', `Error during text summarization: ${error.message}`);
            return `Failed to summarize text: ${error.message}`;
        }
    }
}

export class AIAssistantCore {
    private appManager: AppManager;
    private errorScanner: ErrorScanner;
    private researcher: Researcher;
    private nlpManager: NlpManager;

    constructor() {
        this.appManager = new AppManager();
        this.errorScanner = new ErrorScanner();
        this.researcher = new Researcher(OPENAI_API_KEY);
        this.nlpManager = new NlpManager({ languages: ['en'], forceNER: true });
        this.setupNlpManager(); // Call setup as part of construction

        logToFile('info', 'AI Assistant Core initialized.');
    }

    private async setupNlpManager() {
        this.nlpManager.addDocument('en', 'list installed apps', 'app.list');
        this.nlpManager.addDocument('en', 'show me my applications', 'app.list');

        this.nlpManager.addDocument('en', 'launch app %appName%', 'app.launch');
        this.nlpManager.addDocument('en', 'open %appName%', 'app.launch');

        this.nlpManager.addDocument('en', 'close app %appNameOrPid%', 'app.close');
        this.nlpManager.addDocument('en', 'terminate %appNameOrPid%', 'app.close');

        this.nlpManager.addDocument('en', 'get app stats for %appNameOrPid%', 'app.stats');
        this.nlpManager.addDocument('en', 'show io for %appNameOrPid%', 'app.stats');

        this.nlpManager.addDocument('en', 'scan system errors', 'system.scan_errors');
        this.nlpManager.addDocument('en', 'check logs for errors', 'system.scan_errors');

        this.nlpManager.addDocument('en', 'research %query%', 'research.web');
        this.nlpManager.addDocument('en', 'find information on %query%', 'research.web');

        this.nlpManager.addDocument('en', 'summarize %text%', 'research.summarize');

        this.nlpManager.addDocument('en', 'check health of %appNameOrPid%', 'app.health');
        this.nlpManager.addDocument('en', 'is %appNameOrPid% running', 'app.health');

        this.nlpManager.addAnswer('en', 'app.list', 'Listing installed applications...');
        this.nlpManager.addAnswer('en', 'app.launch', 'Attempting to launch the application...');
        this.nlpManager.addAnswer('en', 'app.close', 'Attempting to close the application...');
        this.nlpManager.addAnswer('en', 'app.stats', 'Retrieving application statistics...');
        this.nlpManager.addAnswer('en', 'system.scan_errors', 'Scanning system logs for errors...');
        this.nlpManager.addAnswer('en', 'research.web', 'Performing web research...');
        this.nlpManager.addAnswer('en', 'research.summarize', 'Summarizing the provided text...');
        this.nlpManager.addAnswer('en', 'app.health', 'Checking application health...');

        await this.nlpManager.train();
        logToFile('info', 'NLP Manager trained.');
    }

    async processCommand(commandText: string): Promise<string> {
        logToFile('info', `Processing command: '${commandText}'`);
        const result = await this.nlpManager.process('en', commandText);
        const intent = result.intent;
        const entities = result.entities;
        const score = result.score;

        if (score < 0.7) {
            return "I don't fully understand that command. Please try rephrasing.";
        }

        const getEntity = (entityName: string) => entities.find(e => e.entity === entityName)?.utteranceText;

        switch (intent) {
            case 'app.list':
                const apps = await this.appManager.listInstalledApps();
                return "Installed applications:\n" + apps.map(app => app.name).join('\n');
            case 'app.launch':
                const appName = getEntity('appName');
                if (appName) {
                    const success = await this.appManager.launchApp(appName);
                    return success ? `Attempting to launch ${appName}.` : `Failed to launch ${appName}. Check name/path or permissions.`;
                }
                return "Please specify an application to launch (e.g., 'launch app Notepad.exe').";
            case 'app.close':
                const appNameOrPidClose = getEntity('appNameOrPid');
                if (appNameOrPidClose) {
                    const success = await this.appManager.closeApp(appNameOrPidClose);
                    return success ? `Attempting to close ${appNameOrPidClose}.` : `Failed to close ${appNameOrPidClose}. App not found or permission denied.`;
                }
                return "Please specify an application name or PID to close (e.g., 'close app Chrome' or 'close app 1234').";
            case 'app.stats':
                const appNameOrPidStats = getEntity('appNameOrPid');
                if (appNameOrPidStats) {
                    const stats = await this.appManager.getAppReadWriteStats(appNameOrPidStats);
                    if (stats) {
                        return (
                            `I/O Stats for ${stats.name} (PID: ${stats.pid}):\n` +
                            `  Read Bytes: ${stats.readBytes}\n` +
                            `  Write Bytes: ${stats.writeBytes}`
                        );
                    }
                    return `Could not get stats for ${appNameOrPidStats}. App not found or not running.`;
                }
                return "Please specify an application name or PID for stats (e.g., 'app stats firefox' or 'app stats 5678').";
            case 'system.scan_errors':
                const errors = await this.errorScanner.scanSystemLogs();
                if (errors.length > 0) {
                    return "Found potential errors in system logs:\n" + errors.join('\n');
                }
                return "No significant errors found in system logs.";
            case 'research.web':
                const query = getEntity('query');
                if (query) {
                    const results = await this.researcher.performWebSearch(query);
                    return "Research results:\n" + results.join('\n');
                }
                return "Please provide a research query (e.g., 'research Node.js security best practices').";
            case 'research.summarize':
                const textToSummarize = getEntity('text');
                if (textToSummarize) {
                    const summary = await this.researcher.summarizeText(textToSummarize);
                    return `Summary: ${summary}`;
                }
                return "Please provide text to summarize (e.g., 'summarize The quick brown fox...').";
            case 'app.health':
                const appNameOrPidHealth = getEntity('appNameOrPid');
                if (appNameOrPidHealth) {
                    const health = await this.errorScanner.checkApplicationHealth(appNameOrPidHealth);
                    if (health.running) {
                        return `${health.name} (PID: ${health.pid}) is running. CPU: ${health.cpuPercent?.toFixed(2)}%, Memory: ${health.memoryPercent?.toFixed(2)}%, Status: ${health.status}`;
                    }
                    return `${appNameOrPidHealth} is not running.`;
                }
                return "Please specify an application name or PID to check health (e.g., 'check health Safari').";
            default:
                return "I'm not sure how to handle that. Try commands like 'list apps', 'launch app <name>', 'close app <name>', 'app stats <name>', 'scan errors', 'research <query>', 'summarize <text>', or 'check health <name>'.";
        }
    }
}



import { app, BrowserWindow, ipcMain } from 'electron';
import path from 'path';
import { AIAssistantCore } from './api';

// Handle creating/removing shortcuts on Windows when installing/uninstalling.
if (require('electron-squirrel-startup')) {
  app.quit();
}

const createWindow = () => {
  // Create the browser window.
  const mainWindow = new BrowserWindow({
    width: 900,
    height: 700,
    minWidth: 700,
    minHeight: 500,
    webPreferences: {
      preload: path.join(__dirname, '../preload/index.js'),
      // IMPORTANT: Context Isolation should be true for security!
      // NodeIntegration should be false. Preload script is the safe way.
      contextIsolation: true,
      nodeIntegration: false,
      sandbox: false // Set to false if you need access to more Node.js APIs in preload directly, but use with caution.
                    // For this example, keep it false as systeminformation might need broader access.
    },
  });

  // Load the React app.
  if (MAIN_WINDOW_VITE_DEV_SERVER_URL) {
    mainWindow.loadURL(MAIN_WINDOW_VITE_DEV_SERVER_URL);
  } else {
    mainWindow.loadFile(path.join(__dirname, '../renderer/index.html'));
  }

  // Open the DevTools.
  // mainWindow.webContents.openDevTools();
};

// This method will be called when Electron has finished
// initialization and is ready to create browser windows.
// Some APIs can only be used after this event occurs.
app.on('ready', () => {
    createWindow();

    // Initialize the AI Assistant Core
    const assistantCore = new AIAssistantCore();

    // IPC Handler for commands from React renderer
    ipcMain.handle('assistant-command', async (event, commandText: string) => {
        return await assistantCore.processCommand(commandText);
    });
});

// Quit when all windows are closed, except on macOS. There, it's common
// for applications and their menu bar to stay active until the user quits
// explicitly with Cmd + Q.
app.on('window-all-closed', () => {
  if (process.platform !== 'darwin') {
    app.quit();
  }
});

app.on('activate', () => {
  // On OS X it's common to re-create a window in the app when the
  // dock icon is clicked and there are no other windows open.
  if (BrowserWindow.getAllWindows().length === 0) {
    createWindow();
  }
});

// In this file you can include the rest of your app's specific main process
// code. You can also put them in separate files and import them here.



import { contextBridge, ipcRenderer } from 'electron';

// Expose a safe, limited API to the renderer process
contextBridge.exposeInMainWorld('electronAPI', {
    // Function to send a command to the main process and get a response
    sendAssistantCommand: (commandText: string) => ipcRenderer.invoke('assistant-command', commandText),
    // You could add other specific functions here if needed, e.g., to request logging or app lists
});



/// <reference types="vite/client" />

interface Window {
  electronAPI: {
    sendAssistantCommand: (commandText: string) => Promise<string>;
  };
}



import React, { useState, FormEvent, useEffect, useRef } from 'react';
import './App.css'; // Add some basic CSS later

interface Message {
  type: 'user' | 'assistant';
  text: string;
}

function App() {
  const [input, setInput] = useState<string>('');
  const [messages, setMessages] = useState<Message[]>([]);
  const [isLoading, setIsLoading] = useState<boolean>(false);
  const messagesEndRef = useRef<HTMLDivElement>(null);

  const scrollToBottom = () => {
    messagesEndRef.current?.scrollIntoView({ behavior: 'smooth' });
  };

  useEffect(() => {
    scrollToBottom();
  }, [messages]);

  const handleSendMessage = async (e: FormEvent) => {
    e.preventDefault();
    if (input.trim() === '') return;

    const userMessage: Message = { type: 'user', text: input };
    setMessages((prev) => [...prev, userMessage]);
    setInput('');
    setIsLoading(true);

    try {
      // Send command to Electron main process
      const response = await window.electronAPI.sendAssistantCommand(input);
      const assistantMessage: Message = { type: 'assistant', text: response };
      setMessages((prev) => [...prev, assistantMessage]);
    } catch (error: any) {
      console.error("Error sending command to main process:", error);
      const errorMessage: Message = { type: 'assistant', text: `Error: ${error.message || "Failed to get response."}` };
      setMessages((prev) => [...prev, errorMessage]);
    } finally {
      setIsLoading(false);
    }
  };

  return (
    <div className="app-container">
      <header className="app-header">
        <h1>Advanced AI Assistant</h1>
      </header>
      <div className="chat-window">
        {messages.map((msg, index) => (
          <div key={index} className={`message ${msg.type}`}>
            <span className="sender">{msg.type === 'user' ? 'You:' : 'Assistant:'}</span> {msg.text}
          </div>
        ))}
        {isLoading && (
          <div className="message assistant loading">
            <span className="sender">Assistant:</span> Thinking...
          </div>
        )}
        <div ref={messagesEndRef} />
      </div>
      <form onSubmit={handleSendMessage} className="input-form">
        <input
          type="text"
          value={input}
          onChange={(e) => setInput(e.target.value)}
          placeholder="Type your command..."
          disabled={isLoading}
        />
        <button type="submit" disabled={isLoading}>Send</button>
      </form>
    </div>
  );
}

export default App;



body {
  font-family: Arial, sans-serif;
  margin: 0;
  padding: 0;
  background-color: #f4f4f4;
  display: flex;
  justify-content: center;
  align-items: center;
  min-height: 100vh;
}

#root {
  width: 100%;
  height: 100vh;
  display: flex;
  justify-content: center;
  align-items: center;
}

.app-container {
  background-color: #fff;
  border-radius: 8px;
  box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
  width: 90%;
  max-width: 800px;
  height: 90vh;
  display: flex;
  flex-direction: column;
  overflow: hidden;
}

.app-header {
  background-color: #333;
  color: white;
  padding: 15px;
  text-align: center;
  border-top-left-radius: 8px;
  border-top-right-radius: 8px;
}

.chat-window {
  flex-grow: 1;
  padding: 20px;
  overflow-y: auto;
  display: flex;
  flex-direction: column;
  gap: 10px;
  background-color: #e9eff2;
}

.message {
  padding: 10px 15px;
  border-radius: 15px;
  max-width: 80%;
  word-wrap: break-word;
}

.message.user {
  background-color: #007bff;
  color: white;
  align-self: flex-end;
  border-bottom-right-radius: 2px;
}

.message.assistant {
  background-color: #f0f0f0;
  color: #333;
  align-self: flex-start;
  border-bottom-left-radius: 2px;
}

.message .sender {
  font-weight: bold;
  margin-right: 5px;
}

.input-form {
  display: flex;
  padding: 15px;
  border-top: 1px solid #eee;
  background-color: #fff;
}

.input-form input {
  flex-grow: 1;
  padding: 10px 15px;
  border: 1px solid #ddd;
  border-radius: 20px;
  margin-right: 10px;
  font-size: 16px;
}

.input-form button {
  background-color: #28a745;
  color: white;
  border: none;
  padding: 10px 20px;
  border-radius: 20px;
  cursor: pointer;
  font-size: 16px;
  transition: background-color 0.2s ease;
}

.input-form button:hover:not(:disabled) {
  background-color: #218838;
}

.input-form button:disabled {
  background-color: #cccccc;
  cursor: not-allowed;
}

.message.assistant.loading {
    font-style: italic;
    color: #666;
    animation: pulse 1.5s infinite;
}

@keyframes pulse {
    0% { opacity: 0.7; }
    50% { opacity: 1; }
    100% { opacity: 0.7; }
}



npm install



You're aiming to build a sophisticated AI assistant with a user interface (UI) using React, but with the ability to interact deeply with the operating system. This implies building a desktop application, as web browsers (where standard React apps run) have severe security restrictions on accessing local files, running system commands, or monitoring other applications.
The ideal framework for this is Electron, which allows you to build cross-platform desktop applications using web technologies (HTML, CSS, and JavaScript/React). Electron embeds a Chromium browser (for rendering your React UI) and a Node.js runtime (for all the system-level interactions).
Here's a conceptual breakdown of the architecture and example React/Electron code:
Architecture Overview:
 * Electron Main Process (Node.js Environment):
   * This is the "backend" of your desktop app. It has full Node.js capabilities and can access system APIs, run shell commands, interact with the file system, and communicate with your AI models (or their APIs).
   * It will house the AppManager, ErrorScanner, and Researcher logic (similar to the Node.js example).
   * It uses ipcMain to communicate with the React frontend.
 * Electron Renderer Process (React UI):
   * This is the "frontend" where your React components live. It's essentially a web page running within Electron.
   * It handles all UI rendering, user input, and displays results.
   * It uses ipcRenderer to send requests to the main process and receive data back.
 * Preload Script:
   * A secure bridge between the renderer process (React) and the main process (Node.js).
   * It selectively exposes Node.js modules or functions to the renderer process, preventing direct access to the Node.js environment from the untrusted web content.
Project Setup (using Electron Forge for simplicity):
First, create an Electron-React project.
# 1. Create a new Electron React project using Vite template
npm init electron-app@latest my-ai-assistant -- --template=vite-react-ts

# 2. Navigate into your project directory
cd my-ai-assistant

# 3. Install additional dependencies for system interaction and AI
npm install systeminformation get-installed-apps node-nlp openai axios chalk
# For `node-nlp` you might also need to install `fs-extra` if you face issues
# npm install fs-extra

# 4. For system command execution, you might also need to explicitly ensure `child_process`
# (It's usually available in Electron's main process, but good to be explicit for clarity)

File Structure (simplified):
my-ai-assistant/
├── .gitignore
├── package.json
├── electron.vite.config.ts  # Electron Forge config
├── src/
│   ├── main/
│   │   ├── index.ts              # Electron Main Process code (Node.js logic)
│   │   └── api.ts                # System interaction logic (AppManager, ErrorScanner, Researcher)
│   ├── preload/
│   │   └── index.ts              # Preload script for secure communication
│   └── renderer/
│       ├── index.html
│       ├── src/                  # React app
│       │   ├── App.tsx
│       │   ├── main.tsx
│       │   ├── components/
│       │   │   └── AssistantChat.tsx
│       │   └── hooks/
│       │       └── useAssistantApi.ts
│       └── vite-env.d.ts
├── tsconfig.json
└── tsconfig.node.json

Code Generation:
1. src/main/api.ts (Electron Main Process - Backend Logic)
This file will contain the core system interaction logic. It's largely similar to the Node.js code from the previous response, adapted for TypeScript and Electron's IPC.
import { exec, spawn } from 'child_process';
import os from 'os';
import fs from 'fs/promises';
import { getInstalledApps, getWinInstalledApps, getMacInstalledApps } from 'get-installed-apps';
import si from 'systeminformation';
import { NlpManager } from 'node-nlp';
import { OpenAI } from 'openai';
import path from 'path'; // Node.js path module
import { app } from 'electron'; // Electron's app module for paths

// --- Configuration ---
const LOG_FILE = path.join(app.getPath('userData'), 'assistant_log.log');
const OPENAI_API_KEY = process.env.OPENAI_API_KEY || 'YOUR_OPENAI_API_KEY'; // Use environment variable!

// Set up simple logging to file
async function logToFile(level: string, message: string) {
    const timestamp = new Date().toISOString();
    const logMessage = `${timestamp} - ${level.toUpperCase()} - ${message}\n`;
    try {
        await fs.appendFile(LOG_FILE, logMessage);
    } catch (error: any) {
        console.error(`Failed to write to log file: ${error.message}`);
    }
}

interface AppInfo {
    id?: string;
    name: string;
    version?: string;
    publisher?: string;
    path?: string;
}

interface ProcessStats {
    pid: number;
    name: string;
    readBytes: number;
    writeBytes: number;
}

interface AppHealth {
    running: boolean;
    pid?: number;
    name?: string;
    cpuPercent?: number;
    memoryPercent?: number;
    status?: string;
}

class AppManager {
    private platform: NodeJS.Platform;

    constructor() {
        this.platform = os.platform();
        logToFile('info', `Initialized AppManager on ${this.platform}`);
    }

    async listInstalledApps(): Promise<AppInfo[]> {
        try {
            let apps: AppInfo[] = [];
            if (this.platform === 'win32') {
                const winApps = await getWinInstalledApps();
                apps = winApps.map(app => ({
                    name: app.displayName || 'Unknown',
                    version: app.displayVersion,
                    publisher: app.publisher,
                    id: app.installLocation || app.systemComponent // Use a more reliable ID if possible
                }));
            } else if (this.platform === 'darwin') {
                const macApps = await getMacInstalledApps();
                apps = macApps.map(app => ({
                    name: app.name,
                    path: app.path,
                    id: app.path // Use path as ID for macOS
                }));
            } else { // Linux
                // This is a very basic attempt for Linux. A real solution needs to parse package managers.
                try {
                    const { stdout } = await this.executeCommand('dpkg -l | grep "^ii" | awk \'{print $2}\'');
                    apps = stdout.split('\n').filter(Boolean).map(name => ({ name, id: name }));
                } catch (dpkgError) {
                    logToFile('warn', `dpkg command failed. Trying snap list...`);
                    try {
                         const { stdout } = await this.executeCommand('snap list | tail -n +2 | awk \'{print $1}\'');
                         apps = apps.concat(stdout.split('\n').filter(Boolean).map(name => ({ name: `Snap: ${name}`, id: `snap-${name}` })));
                    } catch (snapError) {
                        logToFile('error', `Failed to list Linux apps: ${dpkgError} and ${snapError}`);
                    }
                }
            }
            logToFile('info', `Listed ${apps.length} applications.`);
            return apps;
        } catch (error: any) {
            logToFile('error', `Error listing apps: ${error.message}`);
            return [];
        }
    }

    async launchApp(appPathOrName: string): Promise<boolean> {
        try {
            let command = '';
            let args: string[] = [];

            if (this.platform === 'win32') {
                command = 'start';
                args.push(`""`); // Empty title to handle paths with spaces
                args.push(`"${appPathOrName}"`);
            } else if (this.platform === 'darwin') {
                command = 'open';
                args.push(`-a`);
                args.push(appPathOrName);
            } else { // Linux
                command = appPathOrName; // Assumes it's in PATH or full path
            }

            const child = spawn(command, args, { detached: true, stdio: 'ignore', shell: true });
            child.unref();
            logToFile('info', `Attempted to launch: ${appPathOrName}`);
            return true;
        } catch (error: any) {
            logToFile('error', `Error launching ${appPathOrName}: ${error.message}`);
            return false;
        }
    }

    async closeApp(appNameOrPid: string): Promise<boolean> {
        try {
            const processes = await si.processes();
            let targetProcess = null;

            if (!isNaN(parseInt(appNameOrPid))) {
                targetProcess = processes.list.find(p => p.pid === parseInt(appNameOrPid));
            } else {
                targetProcess = processes.list.find(p => p.name.toLowerCase().includes(appNameOrPid.toLowerCase()));
            }

            if (targetProcess) {
                process.kill(targetProcess.pid, 'SIGTERM');
                logToFile('info', `Terminated process: ${targetProcess.name} (PID: ${targetProcess.pid})`);
                return true;
            } else {
                logToFile('warn', `Process not found: ${appNameOrPid}`);
                return false;
            }
        } catch (error: any) {
            logToFile('error', `Error closing ${appNameOrPid}: ${error.message}`);
            return false;
        }
    }

    async getAppReadWriteStats(appNameOrPid: string): Promise<ProcessStats | null> {
        try {
            const processes = await si.processes();
            let targetProcess = null;

            if (!isNaN(parseInt(appNameOrPid))) {
                targetProcess = processes.list.find(p => p.pid === parseInt(appNameOrPid));
            } else {
                targetProcess = processes.list.find(p => p.name.toLowerCase().includes(appNameOrPid.toLowerCase()));
            }

            if (targetProcess) {
                logToFile('info', `Retrieved I/O stats for '${targetProcess.name}' (PID: ${targetProcess.pid}): Read: ${targetProcess.rIO} bytes, Write: ${targetProcess.wIO} bytes`);
                return {
                    pid: targetProcess.pid,
                    name: targetProcess.name,
                    readBytes: targetProcess.rIO,
                    writeBytes: targetProcess.wIO
                };
            }
            logToFile('warn', `Could not find process to get I/O stats: ${appNameOrPid}`);
            return null;
        } catch (error: any) {
            logToFile('error', `Error getting I/O stats for ${appNameOrPid}: ${error.message}`);
            return null;
        }
    }

    private executeCommand(command: string): Promise<{ stdout: string; stderr: string }> {
        return new Promise((resolve, reject) => {
            exec(command, (error, stdout, stderr) => {
                if (error) {
                    reject(new Error(`Command failed: ${command}\n${stderr}`));
                } else {
                    resolve({ stdout, stderr });
                }
            });
        });
    }
}

class ErrorScanner {
    constructor() {
        logToFile('info', 'Initialized ErrorScanner.');
    }

    async scanSystemLogs(keywords: string[] = ['error', 'fail', 'critical']): Promise<string[]> {
        let errorsFound: string[] = [];
        let command = '';
        let args: string[] = [];

        if (os.platform() === 'win32') {
            command = 'powershell.exe';
            args = [
                '-Command',
                `Get-WinEvent -LogName Application,System -ErrorAction SilentlyContinue | Where-Object {($_.Message -match '${keywords.join('|')}') -or ($_.LevelDisplayName -match 'Error' -or $_.LevelDisplayName -match 'Critical')} | Select-Object -First 20 Message | Format-List`
            ];
        } else if (os.platform() === 'darwin') {
            command = 'log';
            args = [
                'show', '--last', '1h', '--predicate',
                `eventType == error OR eventType == fault OR (message CONTAINS "${keywords.join('" OR message CONTAINS "')}")`
            ];
        } else { // Linux
            command = 'journalctl';
            args = ['-p', 'err', '-n', '50', '--no-pager'];
        }

        try {
            const { stdout } = await new Promise<{ stdout: string; stderr: string }>((resolve, reject) => {
                exec(`${command} ${args.join(' ')}`, (error, stdout, stderr) => {
                    if (error) {
                        logToFile('error', `Error scanning system logs: ${stderr}`);
                        reject(error);
                    } else {
                        resolve({ stdout, stderr });
                    }
                });
            });
            errorsFound = stdout.split('\n').filter(line => line.trim() !== '');
            logToFile('info', `Scanned system logs. Found ${errorsFound.length} potential errors.`);
            return errorsFound.slice(0, 10);
        } catch (error: any) {
            logToFile('error', `Failed to scan system logs: ${error.message}`);
            return [`Could not scan system logs: ${error.message}`];
        }
    }

    async checkApplicationHealth(appNameOrPid: string): Promise<AppHealth> {
        try {
            const processes = await si.processes();
            let targetProcess = null;

            if (!isNaN(parseInt(appNameOrPid))) {
                targetProcess = processes.list.find(p => p.pid === parseInt(appNameOrPid));
            } else {
                targetProcess = processes.list.find(p => p.name.toLowerCase().includes(appNameOrPid.toLowerCase()));
            }

            if (targetProcess) {
                logToFile('info', `Health check for '${targetProcess.name}' (PID: ${targetProcess.pid}): CPU: ${targetProcess.cpu.toFixed(2)}%, Memory: ${targetProcess.mem.toFixed(2)}%, Status: ${targetProcess.status}`);
                return {
                    running: true,
                    pid: targetProcess.pid,
                    name: targetProcess.name,
                    cpuPercent: targetProcess.cpu,
                    memoryPercent: targetProcess.mem,
                    status: targetProcess.status
                };
            }
            logToFile('warn', `Application not found for health check: ${appNameOrPid}`);
            return { running: false };
        } catch (error: any) {
            logToFile('error', `Error checking health for ${appNameOrPid}: ${error.message}`);
            return { running: false };
        }
    }
}

class Researcher {
    private openai: OpenAI;
    private hasOpenAI: boolean;

    constructor(apiKey: string) {
        this.openai = new OpenAI({ apiKey: apiKey });
        this.hasOpenAI = !!apiKey;
        logToFile('info', `Initialized Researcher. OpenAI enabled: ${this.hasOpenAI}`);
    }

    async performWebSearch(query: string): Promise<string[]> {
        logToFile('info', `Performing simulated web search for: '${query}'`);
        if (!this.hasOpenAI) {
            logToFile('warn', 'OpenAI API key not provided. Web search will be a placeholder.');
            return [`Simulated search result 1 for '${query}'`, `Simulated search result 2 for '${query}'`];
        }

        try {
            const completion = await this.openai.chat.completions.create({
                model: "gpt-4o",
                messages: [
                    { role: "system", content: "You are a helpful assistant that provides concise research results." },
                    { role: "user", content: `Provide a concise summary of research on: ${query}` }
                ],
                max_tokens: 300,
            });
            const result = completion.choices[0]?.message?.content || "No research results found.";
            return [`AI-generated research result: ${result}`];
        } catch (error: any) {
            logToFile('error', `Error during OpenAI web search simulation for '${query}': ${error.message}`);
            return [`Error retrieving AI-generated research results for '${query}'.`];
        }
    }

    async summarizeText(text: string): Promise<string> {
        if (!this.hasOpenAI) {
            logToFile('warn', 'OpenAI API key not provided. Summarization will be a placeholder.');
            return `Summary of: ${text.substring(0, 100)}... (OpenAI not configured)`;
        }

        try {
            const completion = await this.openai.chat.completions.create({
                model: "gpt-4o",
                messages: [
                    { role: "system", content: "You are a helpful assistant that summarizes text concisely." },
                    { role: "user", content: `Summarize the following text:\n\n${text}` }
                ],
                max_tokens: 200,
            });
            return completion.choices[0]?.message?.content || "Could not generate summary.";
        } catch (error: any) {
            logToFile('error', `Error during text summarization: ${error.message}`);
            return `Failed to summarize text: ${error.message}`;
        }
    }
}

export class AIAssistantCore {
    private appManager: AppManager;
    private errorScanner: ErrorScanner;
    private researcher: Researcher;
    private nlpManager: NlpManager;

    constructor() {
        this.appManager = new AppManager();
        this.errorScanner = new ErrorScanner();
        this.researcher = new Researcher(OPENAI_API_KEY);
        this.nlpManager = new NlpManager({ languages: ['en'], forceNER: true });
        this.setupNlpManager(); // Call setup as part of construction

        logToFile('info', 'AI Assistant Core initialized.');
    }

    private async setupNlpManager() {
        this.nlpManager.addDocument('en', 'list installed apps', 'app.list');
        this.nlpManager.addDocument('en', 'show me my applications', 'app.list');

        this.nlpManager.addDocument('en', 'launch app %appName%', 'app.launch');
        this.nlpManager.addDocument('en', 'open %appName%', 'app.launch');

        this.nlpManager.addDocument('en', 'close app %appNameOrPid%', 'app.close');
        this.nlpManager.addDocument('en', 'terminate %appNameOrPid%', 'app.close');

        this.nlpManager.addDocument('en', 'get app stats for %appNameOrPid%', 'app.stats');
        this.nlpManager.addDocument('en', 'show io for %appNameOrPid%', 'app.stats');

        this.nlpManager.addDocument('en', 'scan system errors', 'system.scan_errors');
        this.nlpManager.addDocument('en', 'check logs for errors', 'system.scan_errors');

        this.nlpManager.addDocument('en', 'research %query%', 'research.web');
        this.nlpManager.addDocument('en', 'find information on %query%', 'research.web');

        this.nlpManager.addDocument('en', 'summarize %text%', 'research.summarize');

        this.nlpManager.addDocument('en', 'check health of %appNameOrPid%', 'app.health');
        this.nlpManager.addDocument('en', 'is %appNameOrPid% running', 'app.health');

        this.nlpManager.addAnswer('en', 'app.list', 'Listing installed applications...');
        this.nlpManager.addAnswer('en', 'app.launch', 'Attempting to launch the application...');
        this.nlpManager.addAnswer('en', 'app.close', 'Attempting to close the application...');
        this.nlpManager.addAnswer('en', 'app.stats', 'Retrieving application statistics...');
        this.nlpManager.addAnswer('en', 'system.scan_errors', 'Scanning system logs for errors...');
        this.nlpManager.addAnswer('en', 'research.web', 'Performing web research...');
        this.nlpManager.addAnswer('en', 'research.summarize', 'Summarizing the provided text...');
        this.nlpManager.addAnswer('en', 'app.health', 'Checking application health...');

        await this.nlpManager.train();
        logToFile('info', 'NLP Manager trained.');
    }

    async processCommand(commandText: string): Promise<string> {
        logToFile('info', `Processing command: '${commandText}'`);
        const result = await this.nlpManager.process('en', commandText);
        const intent = result.intent;
        const entities = result.entities;
        const score = result.score;

        if (score < 0.7) {
            return "I don't fully understand that command. Please try rephrasing.";
        }

        const getEntity = (entityName: string) => entities.find(e => e.entity === entityName)?.utteranceText;

        switch (intent) {
            case 'app.list':
                const apps = await this.appManager.listInstalledApps();
                return "Installed applications:\n" + apps.map(app => app.name).join('\n');
            case 'app.launch':
                const appName = getEntity('appName');
                if (appName) {
                    const success = await this.appManager.launchApp(appName);
                    return success ? `Attempting to launch ${appName}.` : `Failed to launch ${appName}. Check name/path or permissions.`;
                }
                return "Please specify an application to launch (e.g., 'launch app Notepad.exe').";
            case 'app.close':
                const appNameOrPidClose = getEntity('appNameOrPid');
                if (appNameOrPidClose) {
                    const success = await this.appManager.closeApp(appNameOrPidClose);
                    return success ? `Attempting to close ${appNameOrPidClose}.` : `Failed to close ${appNameOrPidClose}. App not found or permission denied.`;
                }
                return "Please specify an application name or PID to close (e.g., 'close app Chrome' or 'close app 1234').";
            case 'app.stats':
                const appNameOrPidStats = getEntity('appNameOrPid');
                if (appNameOrPidStats) {
                    const stats = await this.appManager.getAppReadWriteStats(appNameOrPidStats);
                    if (stats) {
                        return (
                            `I/O Stats for ${stats.name} (PID: ${stats.pid}):\n` +
                            `  Read Bytes: ${stats.readBytes}\n` +
                            `  Write Bytes: ${stats.writeBytes}`
                        );
                    }
                    return `Could not get stats for ${appNameOrPidStats}. App not found or not running.`;
                }
                return "Please specify an application name or PID for stats (e.g., 'app stats firefox' or 'app stats 5678').";
            case 'system.scan_errors':
                const errors = await this.errorScanner.scanSystemLogs();
                if (errors.length > 0) {
                    return "Found potential errors in system logs:\n" + errors.join('\n');
                }
                return "No significant errors found in system logs.";
            case 'research.web':
                const query = getEntity('query');
                if (query) {
                    const results = await this.researcher.performWebSearch(query);
                    return "Research results:\n" + results.join('\n');
                }
                return "Please provide a research query (e.g., 'research Node.js security best practices').";
            case 'research.summarize':
                const textToSummarize = getEntity('text');
                if (textToSummarize) {
                    const summary = await this.researcher.summarizeText(textToSummarize);
                    return `Summary: ${summary}`;
                }
                return "Please provide text to summarize (e.g., 'summarize The quick brown fox...').";
            case 'app.health':
                const appNameOrPidHealth = getEntity('appNameOrPid');
                if (appNameOrPidHealth) {
                    const health = await this.errorScanner.checkApplicationHealth(appNameOrPidHealth);
                    if (health.running) {
                        return `${health.name} (PID: ${health.pid}) is running. CPU: ${health.cpuPercent?.toFixed(2)}%, Memory: ${health.memoryPercent?.toFixed(2)}%, Status: ${health.status}`;
                    }
                    return `${appNameOrPidHealth} is not running.`;
                }
                return "Please specify an application name or PID to check health (e.g., 'check health Safari').";
            default:
                return "I'm not sure how to handle that. Try commands like 'list apps', 'launch app <name>', 'close app <name>', 'app stats <name>', 'scan errors', 'research <query>', 'summarize <text>', or 'check health <name>'.";
        }
    }
}

2. src/main/index.ts (Electron Main Process - Entry Point)
This file sets up the Electron window and the IPC communication.
import { app, BrowserWindow, ipcMain } from 'electron';
import path from 'path';
import { AIAssistantCore } from './api';

// Handle creating/removing shortcuts on Windows when installing/uninstalling.
if (require('electron-squirrel-startup')) {
  app.quit();
}

const createWindow = () => {
  // Create the browser window.
  const mainWindow = new BrowserWindow({
    width: 900,
    height: 700,
    minWidth: 700,
    minHeight: 500,
    webPreferences: {
      preload: path.join(__dirname, '../preload/index.js'),
      // IMPORTANT: Context Isolation should be true for security!
      // NodeIntegration should be false. Preload script is the safe way.
      contextIsolation: true,
      nodeIntegration: false,
      sandbox: false // Set to false if you need access to more Node.js APIs in preload directly, but use with caution.
                    // For this example, keep it false as systeminformation might need broader access.
    },
  });

  // Load the React app.
  if (MAIN_WINDOW_VITE_DEV_SERVER_URL) {
    mainWindow.loadURL(MAIN_WINDOW_VITE_DEV_SERVER_URL);
  } else {
    mainWindow.loadFile(path.join(__dirname, '../renderer/index.html'));
  }

  // Open the DevTools.
  // mainWindow.webContents.openDevTools();
};

// This method will be called when Electron has finished
// initialization and is ready to create browser windows.
// Some APIs can only be used after this event occurs.
app.on('ready', () => {
    createWindow();

    // Initialize the AI Assistant Core
    const assistantCore = new AIAssistantCore();

    // IPC Handler for commands from React renderer
    ipcMain.handle('assistant-command', async (event, commandText: string) => {
        return await assistantCore.processCommand(commandText);
    });
});

// Quit when all windows are closed, except on macOS. There, it's common
// for applications and their menu bar to stay active until the user quits
// explicitly with Cmd + Q.
app.on('window-all-closed', () => {
  if (process.platform !== 'darwin') {
    app.quit();
  }
});

app.on('activate', () => {
  // On OS X it's common to re-create a window in the app when the
  // dock icon is clicked and there are no other windows open.
  if (BrowserWindow.getAllWindows().length === 0) {
    createWindow();
  }
});

// In this file you can include the rest of your app's specific main process
// code. You can also put them in separate files and import them here.

3. src/preload/index.ts (Preload Script - Secure Bridge)
This script runs before the renderer process's web content is loaded. It's crucial for security as it exposes only specific functions from the Node.js context to the React frontend.
import { contextBridge, ipcRenderer } from 'electron';

// Expose a safe, limited API to the renderer process
contextBridge.exposeInMainWorld('electronAPI', {
    // Function to send a command to the main process and get a response
    sendAssistantCommand: (commandText: string) => ipcRenderer.invoke('assistant-command', commandText),
    // You could add other specific functions here if needed, e.g., to request logging or app lists
});

4. src/renderer/vite-env.d.ts (Type Declaration for Preload API)
Add this to ensure TypeScript knows about the electronAPI you're exposing.
/// <reference types="vite/client" />

interface Window {
  electronAPI: {
    sendAssistantCommand: (commandText: string) => Promise<string>;
  };
}

5. src/renderer/src/App.tsx (React Component - UI)
import React, { useState, FormEvent, useEffect, useRef } from 'react';
import './App.css'; // Add some basic CSS later

interface Message {
  type: 'user' | 'assistant';
  text: string;
}

function App() {
  const [input, setInput] = useState<string>('');
  const [messages, setMessages] = useState<Message[]>([]);
  const [isLoading, setIsLoading] = useState<boolean>(false);
  const messagesEndRef = useRef<HTMLDivElement>(null);

  const scrollToBottom = () => {
    messagesEndRef.current?.scrollIntoView({ behavior: 'smooth' });
  };

  useEffect(() => {
    scrollToBottom();
  }, [messages]);

  const handleSendMessage = async (e: FormEvent) => {
    e.preventDefault();
    if (input.trim() === '') return;

    const userMessage: Message = { type: 'user', text: input };
    setMessages((prev) => [...prev, userMessage]);
    setInput('');
    setIsLoading(true);

    try {
      // Send command to Electron main process
      const response = await window.electronAPI.sendAssistantCommand(input);
      const assistantMessage: Message = { type: 'assistant', text: response };
      setMessages((prev) => [...prev, assistantMessage]);
    } catch (error: any) {
      console.error("Error sending command to main process:", error);
      const errorMessage: Message = { type: 'assistant', text: `Error: ${error.message || "Failed to get response."}` };
      setMessages((prev) => [...prev, errorMessage]);
    } finally {
      setIsLoading(false);
    }
  };

  return (
    <div className="app-container">
      <header className="app-header">
        <h1>Advanced AI Assistant</h1>
      </header>
      <div className="chat-window">
        {messages.map((msg, index) => (
          <div key={index} className={`message ${msg.type}`}>
            <span className="sender">{msg.type === 'user' ? 'You:' : 'Assistant:'}</span> {msg.text}
          </div>
        ))}
        {isLoading && (
          <div className="message assistant loading">
            <span className="sender">Assistant:</span> Thinking...
          </div>
        )}
        <div ref={messagesEndRef} />
      </div>
      <form onSubmit={handleSendMessage} className="input-form">
        <input
          type="text"
          value={input}
          onChange={(e) => setInput(e.target.value)}
          placeholder="Type your command..."
          disabled={isLoading}
        />
        <button type="submit" disabled={isLoading}>Send</button>
      </form>
    </div>
  );
}

export default App;

6. src/renderer/src/App.css (Basic Styling)
body {
  font-family: Arial, sans-serif;
  margin: 0;
  padding: 0;
  background-color: #f4f4f4;
  display: flex;
  justify-content: center;
  align-items: center;
  min-height: 100vh;
}

#root {
  width: 100%;
  height: 100vh;
  display: flex;
  justify-content: center;
  align-items: center;
}

.app-container {
  background-color: #fff;
  border-radius: 8px;
  box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
  width: 90%;
  max-width: 800px;
  height: 90vh;
  display: flex;
  flex-direction: column;
  overflow: hidden;
}

.app-header {
  background-color: #333;
  color: white;
  padding: 15px;
  text-align: center;
  border-top-left-radius: 8px;
  border-top-right-radius: 8px;
}

.chat-window {
  flex-grow: 1;
  padding: 20px;
  overflow-y: auto;
  display: flex;
  flex-direction: column;
  gap: 10px;
  background-color: #e9eff2;
}

.message {
  padding: 10px 15px;
  border-radius: 15px;
  max-width: 80%;
  word-wrap: break-word;
}

.message.user {
  background-color: #007bff;
  color: white;
  align-self: flex-end;
  border-bottom-right-radius: 2px;
}

.message.assistant {
  background-color: #f0f0f0;
  color: #333;
  align-self: flex-start;
  border-bottom-left-radius: 2px;
}

.message .sender {
  font-weight: bold;
  margin-right: 5px;
}

.input-form {
  display: flex;
  padding: 15px;
  border-top: 1px solid #eee;
  background-color: #fff;
}

.input-form input {
  flex-grow: 1;
  padding: 10px 15px;
  border: 1px solid #ddd;
  border-radius: 20px;
  margin-right: 10px;
  font-size: 16px;
}

.input-form button {
  background-color: #28a745;
  color: white;
  border: none;
  padding: 10px 20px;
  border-radius: 20px;
  cursor: pointer;
  font-size: 16px;
  transition: background-color 0.2s ease;
}

.input-form button:hover:not(:disabled) {
  background-color: #218838;
}

.input-form button:disabled {
  background-color: #cccccc;
  cursor: not-allowed;
}

.message.assistant.loading {
    font-style: italic;
    color: #666;
    animation: pulse 1.5s infinite;
}

@keyframes pulse {
    0% { opacity: 0.7; }
    50% { opacity: 1; }
    100% { opacity: 0.7; }
}

How to Run:
 * Install dependencies:
   npm install

 * Set your OpenAI API Key:
   Create a .env file in your project root (my-ai-assistant/) and add:
   OPENAI_API_KEY=sk-YOUR_ACTUAL_OPENAI_API_KEY

   Alternatively, set it directly in your environment before running Electron (e.g., export OPENAI_API_KEY='...' on Linux/macOS, or set OPENAI_API_KEY='...' on Windows).
   Important: For electron.vite.config.ts, you might need to use a plugin like vite-plugin-env-compatible or manually expose the environment variable to the main process for process.env.OPENAI_API_KEY to be picked up. A simpler way for a quick test is to hardcode it in src/main/api.ts (but remove it for any real deployment!).
 * Start the development server:
   npm run dev

   This will start both the React development server and the Electron application.
Key Points and Further Development:
 * IPC (Inter-Process Communication): The core of Electron development is understanding ipcMain (main process listens, sends replies) and ipcRenderer (renderer process sends messages, listens for replies). This separation is vital for security and prevents your UI code from directly accessing Node.js APIs.
 * Security (Preload Script & Context Isolation): The preload/index.ts script is crucial. It uses contextBridge.exposeInMainWorld to create a safe API that your React app can use to interact with the Electron main process. This means your React code cannot directly use require('fs') or child_process, preventing potential vulnerabilities if malicious code were to be injected into your renderer.
 * Error Handling: The current code has basic try...catch blocks. For a production app, you'd want more robust error logging, user-friendly error messages, and perhaps a way to report issues.
 * UI/UX: The React UI is very basic. You'd want to enhance it with:
   * Better styling (using Tailwind CSS, Material UI, Chakra UI, etc.).
   * Clearer visual feedback for loading states, errors, and successful operations.
   * More structured display of results (e.g., tables for app lists, formatted logs, expandable research results).
   * Input validation and suggestions.
 * Loading States: The isLoading state is implemented to disable input while waiting for a response.
 * System Interaction Depth:
   * File I/O Monitoring: As mentioned in previous responses, truly granular, per-process file read/write monitoring is extremely difficult from user-space (even with Electron/Node.js) and typically requires low-level OS APIs or kernel modules. systeminformation gives you aggregated I/O.
   * Advanced App Control: For things like "modifying app attributes" (which could mean configuration files), you'd use fs/promises in the main process to read/write specific configuration files for known applications. This requires knowing the app's configuration file locations and formats.
 * AI Integration: The Researcher class uses OpenAI's API. You could integrate other LLMs, local models (if powerful enough), or a chain of tools (e.g., a web search API combined with an LLM for summarization).
 * Scalability: For more complex NLP or AI logic, consider running a separate local Python/Flask backend and having your Electron app communicate with it (via HTTP or gRPC), allowing you to leverage Python's rich AI ecosystem while keeping your Electron app lean.
This React/Electron setup provides a strong foundation for building a powerful desktop AI assistant.



npm run dev



pip install psutil "python-get-installed-apps>=0.0.1" "node-nlp>=4.27.0" "openai>=1.0" colorama



export OPENAI_API_KEY='your_api_key_here'



set OPENAI_API_KEY=your_api_key_here



$env:OPENAI_API_KEY='your_api_key_here'



import subprocess
import os
import psutil
import logging
import platform
from datetime import datetime
from get_installed_apps import get_installed_apps
from node_nlp import NlpManager # Using the Python wrapper for node-nlp
from openai import OpenAI # Official OpenAI Python client
from colorama import Fore, Style, init # For colorful console output

# Initialize Colorama for cross-platform colored output
init(autoreset=True)

# --- Configuration ---
LOG_FILE = "assistant_log.log"
# OpenAI API Key: Fetched from environment variable for security
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY")

# Set up logging
logging.basicConfig(filename=LOG_FILE, level=logging.INFO,
                    format='%(asctime)s - %(levelname)s - %(message)s')

# --- AppManager: Handles installed applications and processes ---
class AppManager:
    def __init__(self):
        self.os_platform = platform.system()
        logging.info(f"Initialized AppManager on {self.os_platform}")

    def list_installed_apps(self) -> list[dict]:
        """
        Lists installed applications. Uses 'get_installed_apps' for better cross-platform support.
        Returns a list of dictionaries with app info.
        """
        app_list = []
        try:
            # get_installed_apps provides a good cross-platform abstraction
            raw_apps = get_installed_apps()
            app_list = [{
                "name": app.get("name", "Unknown"),
                "version": app.get("version"),
                "publisher": app.get("publisher"),
                "path": app.get("path") # Path is often useful for launching
            } for app in raw_apps]
            logging.info(f"Listed {len(app_list)} applications.")
        except Exception as e:
            logging.error(f"Error listing apps: {e}")
        return app_list

    def launch_app(self, app_name_or_path: str) -> bool:
        """
        Launches an application.
        Supports common ways to launch based on OS.
        """
        try:
            if self.os_platform == "Windows":
                # Use 'start' command which works for EXEs and registered app names
                subprocess.Popen(f'start "" "{app_name_or_path}"', shell=True, creationflags=subprocess.DETACHED_PROCESS)
            elif self.os_platform == "Darwin": # macOS
                # 'open -a' can launch by app name, or directly by path to .app bundle
                if app_name_or_path.endswith(".app"):
                    subprocess.Popen(["open", app_name_or_path])
                else:
                    subprocess.Popen(["open", "-a", app_name_or_path])
            elif self.os_platform == "Linux":
                # Assumes the app is in PATH or given a full path and is executable
                subprocess.Popen([app_name_or_path], preexec_fn=os.setsid) # os.setsid detaches process
            else:
                logging.warning(f"Could not determine how to launch {app_name_or_path} on {self.os_platform}.")
                return False
            logging.info(f"Launched application: {app_name_or_path}")
            return True
        except Exception as e:
            logging.error(f"Error launching {app_name_or_path}: {e}")
            return False

    def close_app(self, app_name_or_pid: str) -> bool:
        """
        Attempts to close an application by name or PID.
        Uses psutil for robust process management.
        """
        try:
            for proc in psutil.process_iter(['pid', 'name']):
                if app_name_or_pid.isdigit() and proc.info['pid'] == int(app_name_or_pid):
                    proc.terminate()
                    logging.info(f"Terminated process with PID: {app_name_or_pid}")
                    return True
                elif app_name_or_pid.lower() in proc.info['name'].lower():
                    proc.terminate()
                    logging.info(f"Terminated process by name: {proc.info['name']} (PID: {proc.info['pid']})")
                    return True
            logging.warning(f"Could not find or terminate application: {app_name_or_pid}")
            return False
        except (psutil.NoSuchProcess, psutil.AccessDenied, psutil.ZombieProcess) as e:
            logging.error(f"Error closing {app_name_or_pid}: {e}")
            return False

    def get_app_read_write_stats(self, app_name_or_pid: str) -> dict | None:
        """
        Gets basic read/write I/O stats for a running application process.
        This provides process-level aggregated I/O, not file-level details.
        """
        for proc in psutil.process_iter(['pid', 'name', 'io_counters']):
            try:
                if app_name_or_pid.isdigit() and proc.info['pid'] == int(app_name_or_pid):
                    io_counters = proc.io_counters()
                    stats = {
                        "name": proc.info['name'],
                        "pid": proc.info['pid'],
                        "read_bytes": io_counters.read_bytes,
                        "write_bytes": io_counters.write_bytes
                    }
                    logging.info(f"Retrieved I/O stats for PID {app_name_or_pid}: {stats}")
                    return stats
                elif app_name_or_pid.lower() in proc.info['name'].lower():
                    io_counters = proc.io_counters()
                    stats = {
                        "name": proc.info['name'],
                        "pid": proc.info['pid'],
                        "read_bytes": io_counters.read_bytes,
                        "write_bytes": io_counters.write_bytes
                    }
                    logging.info(f"Retrieved I/O stats for '{proc.info['name']}' (PID: {proc.info['pid']}): {stats}")
                    return stats
            except (psutil.NoSuchProcess, psutil.AccessDenied, psutil.ZombieProcess):
                continue
        logging.warning(f"Could not find process to get I/O stats: {app_name_or_pid}")
        return None

# --- ErrorScanner: Scans for system errors and checks app health ---
class ErrorScanner:
    def __init__(self):
        logging.info("Initialized ErrorScanner.")

    def _execute_shell_command(self, command: list[str]) -> str:
        """Helper to execute shell commands and return stdout."""
        try:
            result = subprocess.run(command, capture_output=True, text=True, check=True, encoding='utf-8', errors='ignore')
            return result.stdout
        except subprocess.CalledProcessError as e:
            logging.error(f"Shell command failed: {' '.join(command)}. Error: {e.stderr}")
            return ""
        except FileNotFoundError:
            logging.error(f"Command not found: {command[0]}. Make sure it's in your PATH.")
            return ""

    def scan_system_logs(self, keywords: list[str] = ["error", "fail", "critical"]) -> list[str]:
        """
        Scans system logs for specified keywords. Highly OS-dependent.
        Requires appropriate user permissions.
        """
        errors_found = []
        search_pattern = "|".join(keywords) # For regex-like matching

        if platform.system() == "Windows":
            # Windows Event Logs via PowerShell
            command = [
                'powershell.exe',
                '-NoProfile', '-Command',
                f'Get-WinEvent -LogName Application,System -ErrorAction SilentlyContinue | '
                f'Where-Object {{($_.Message -match "{search_pattern}") -or ($_.LevelDisplayName -match "Error" -or $_.LevelDisplayName -match "Critical")}} | '
                f'Select-Object -First 20 Message | Format-List'
            ]
            output = self._execute_shell_command(command)
            errors_found = [line.strip() for line in output.splitlines() if line.strip()]
        elif platform.system() == "Linux":
            # journalctl for systemd-based Linux distros
            command = ['journalctl', '-p', 'err', '-n', '50', '--no-pager']
            output = self._execute_shell_command(command)
            errors_found = [line.strip() for line in output.splitlines() if any(k.lower() in line.lower() for k in keywords)]
        elif platform.system() == "Darwin": # macOS
            # macOS uses 'log show'
            command = [
                'log', 'show', '--last', '1h',
                '--predicate', f'(eventType == error OR eventType == fault) OR (message CONTAINS "{keywords[0]}"' +
                               (f' OR message CONTAINS "{k}"' for k in keywords[1:]) + ')'
            ]
            output = self._execute_shell_command(command)
            errors_found = [line.strip() for line in output.splitlines() if line.strip()]

        logging.info(f"Scanned system logs. Found {len(errors_found)} potential errors.")
        return errors_found[:10] # Return top 10 for brevity

    def check_application_health(self, app_name_or_pid: str) -> dict:
        """
        Checks if an application process is running and its basic health (CPU/memory).
        """
        for proc in psutil.process_iter(['pid', 'name', 'cpu_percent', 'memory_percent', 'status']):
            try:
                if app_name_or_pid.isdigit() and proc.info['pid'] == int(app_name_or_pid):
                    cpu_p = proc.cpu_percent(interval=0.1) # Non-blocking in this context
                    mem_p = proc.memory_percent()
                    return {
                        "running": True,
                        "name": proc.info['name'],
                        "pid": proc.info['pid'],
                        "cpu_percent": cpu_p,
                        "memory_percent": mem_p,
                        "status": proc.info['status']
                    }
                elif app_name_or_pid.lower() in proc.info['name'].lower():
                    cpu_p = proc.cpu_percent(interval=0.1)
                    mem_p = proc.memory_percent()
                    return {
                        "running": True,
                        "name": proc.info['name'],
                        "pid": proc.info['pid'],
                        "cpu_percent": cpu_p,
                        "memory_percent": mem_p,
                        "status": proc.info['status']
                    }
            except (psutil.NoSuchProcess, psutil.AccessDenied, psutil.ZombieProcess):
                continue
        return {"running": False}

# --- Researcher: Performs web research and text summarization ---
class Researcher:
    def __init__(self, api_key: str | None):
        if api_key:
            self.openai_client = OpenAI(api_key=api_key)
            self.has_openai = True
        else:
            self.openai_client = None
            self.has_openai = False
            logging.warning("OpenAI API key not found. Research and summarization will be simulated.")
        logging.info(f"Initialized Researcher. OpenAI enabled: {self.has_openai}")

    def perform_web_search(self, query: str) -> list[str]:
        """
        Simulates a web search using an AI model.
        In a real scenario, this would integrate with a search API (e.g., Google Custom Search API).
        """
        logging.info(f"Performing simulated web search for: '{query}'")
        if not self.has_openai:
            return [f"Simulated search result 1 for '{query}' (OpenAI not configured)",
                    f"Simulated search result 2 for '{query}' (OpenAI not configured)"]

        try:
            # Use OpenAI's chat completion to "simulate" a search result based on its knowledge
            response = self.openai_client.chat.completions.create(
                model="gpt-4o", # Or a smaller model like "gpt-3.5-turbo"
                messages=[
                    {"role": "system", "content": "You are a helpful assistant that provides concise search-like results."},
                    {"role": "user", "content": f"Provide 2-3 concise search results or a brief summary for: {query}"}
                ],
                max_tokens=300,
                temperature=0.7
            )
            result_text = response.choices[0].message.content.strip()
            # Split into lines or paragraphs for better readability if AI provides multiple points
            return result_text.split('\n')
        except Exception as e:
            logging.error(f"Error during OpenAI web search simulation for '{query}': {e}")
            return [f"Error retrieving AI-generated search results for '{query}'."]

    def summarize_text(self, text: str) -> str:
        """
        Summarizes text using an AI model.
        """
        logging.info(f"Attempting to summarize text (first 50 chars): '{text[:50]}...'")
        if not self.has_openai:
            return f"Summary of: {text[:100]}... (OpenAI not configured)"

        try:
            response = self.openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "You are a helpful assistant that summarizes text concisely."},
                    {"role": "user", "content": f"Summarize the following text:\n\n{text}"}
                ],
                max_tokens=200,
                temperature=0.7
            )
            return response.choices[0].message.content.strip()
        except Exception as e:
            logging.error(f"Error during text summarization: {e}")
            return f"Failed to summarize text: {e}"

# --- AIAssistant: Orchestrates commands and interacts with user ---
class AIAssistant:
    def __init__(self):
        self.app_manager = AppManager()
        self.error_scanner = ErrorScanner()
        self.researcher = Researcher(OPENAI_API_KEY)
        self.nlp_manager = NlpManager(languages=['en'], force_ner=True) # Initialize NlpManager
        self._setup_nlp_manager() # Setup and train NLP model

        logging.info("AI Assistant initialized.")
        print(f"{Fore.GREEN}Advanced AI Assistant started. Type '{Fore.CYAN}exit{Style.RESET_ALL}' to quit.")

    def _setup_nlp_manager(self):
        """Sets up and trains the NLP model for intent recognition."""
        print(f"{Fore.YELLOW}Training NLP model... This might take a moment.{Style.RESET_ALL}")
        # Intents for AppManager
        self.nlp_manager.add_document('en', 'list installed apps', 'app.list')
        self.nlp_manager.add_document('en', 'show me my applications', 'app.list')

        self.nlp_manager.add_document('en', 'launch app %appName%', 'app.launch')
        self.nlp_manager.add_document('en', 'open %appName%', 'app.launch')

        self.nlp_manager.add_document('en', 'close app %appNameOrPid%', 'app.close')
        self.nlp_manager.add_document('en', 'terminate %appNameOrPid%', 'app.close')

        self.nlp_manager.add_document('en', 'get app stats for %appNameOrPid%', 'app.stats')
        self.nlp_manager.add_document('en', 'show io for %appNameOrPid%', 'app.stats')

        # Intents for ErrorScanner
        self.nlp_manager.add_document('en', 'scan system errors', 'system.scan_errors')
        self.nlp_manager.add_document('en', 'check logs for errors', 'system.scan_errors')

        self.nlp_manager.add_document('en', 'check health of %appNameOrPid%', 'app.health')
        self.nlp_manager.add_document('en', 'is %appNameOrPid% running', 'app.health')

        # Intents for Researcher
        self.nlp_manager.add_document('en', 'research %query%', 'research.web')
        self.nlp_manager.add_document('en', 'find information on %query%', 'research.web')

        self.nlp_manager.add_document('en', 'summarize %text%', 'research.summarize')

        # Add answers (responses) for the NLP manager
        self.nlp_manager.add_answer('en', 'app.list', 'Listing installed applications...')
        self.nlp_manager.add_answer('en', 'app.launch', 'Attempting to launch the application...')
        self.nlp_manager.add_answer('en', 'app.close', 'Attempting to close the application...')
        self.nlp_manager.add_answer('en', 'app.stats', 'Retrieving application statistics...')
        self.nlp_manager.add_answer('en', 'system.scan_errors', 'Scanning system logs for errors...')
        self.nlp_manager.add_answer('en', 'research.web', 'Performing web research...')
        self.nlp_manager.add_answer('en', 'research.summarize', 'Summarizing the provided text...')
        self.nlp_manager.add_answer('en', 'app.health', 'Checking application health...')

        self.nlp_manager.train()
        print(f"{Fore.GREEN}NLP model trained successfully!{Style.RESET_ALL}")


    def execute_command(self, command_text: str) -> str:
        """
        Parses user commands using NLP and dispatches to appropriate modules.
        """
        command_text = command_text.strip()
        logging.info(f"Received command: '{command_text}'")

        if command_text.lower() in ["exit", "quit"]:
            return "Exiting assistant. Goodbye!"

        # Process the command with NLP
        nlp_result = self.nlp_manager.process('en', command_text)
        intent = nlp_result.intent
        entities = nlp_result.entities
        score = nlp_result.score

        # Confidence threshold for NLP understanding
        if score < 0.7:
            return (f"{Fore.YELLOW}I don't fully understand that command (confidence: {score:.2f}). "
                    f"Please try rephrasing or use a more direct command.{Style.RESET_ALL}")

        # Helper to extract entity value
        def get_entity_value(entity_name: str) -> str | None:
            for entity in entities:
                if entity['entity'] == entity_name:
                    return entity['utteranceText']
            return None

        response = ""
        try:
            if intent == 'app.list':
                apps = self.app_manager.list_installed_apps()
                if apps:
                    response = Fore.GREEN + "Installed applications (top 20):\n" + Style.RESET_ALL
                    for i, app in enumerate(apps[:20]):
                        response += f"  - {app['name']}"
                        if app['version']:
                            response += f" (v{app['version']})"
                        if app['publisher']:
                            response += f" by {app['publisher']}"
                        response += "\n"
                    if len(apps) > 20:
                        response += "  ...\n"
                else:
                    response = Fore.YELLOW + "No installed applications found or an error occurred." + Style.RESET_ALL
            elif intent == 'app.launch':
                app_name = get_entity_value('appName')
                if app_name:
                    if self.app_manager.launch_app(app_name):
                        response = Fore.GREEN + f"Attempting to launch {app_name}." + Style.RESET_ALL
                    else:
                        response = Fore.RED + f"Failed to launch {app_name}. Check application name/path or permissions." + Style.RESET_ALL
                else:
                    response = Fore.YELLOW + "Please specify an application to launch (e.g., 'launch app notepad.exe')." + Style.RESET_ALL
            elif intent == 'app.close':
                app_name_or_pid = get_entity_value('appNameOrPid')
                if app_name_or_pid:
                    if self.app_manager.close_app(app_name_or_pid):
                        response = Fore.GREEN + f"Attempting to close {app_name_or_pid}." + Style.RESET_ALL
                    else:
                        response = Fore.RED + f"Failed to close {app_name_or_pid}. App not found or permission denied." + Style.RESET_ALL
                else:
                    response = Fore.YELLOW + "Please specify an application name or PID to close (e.g., 'close app chrome' or 'close app 1234')." + Style.RESET_ALL
            elif intent == 'app.stats':
                app_name_or_pid = get_entity_value('appNameOrPid')
                if app_name_or_pid:
                    stats = self.app_manager.get_app_read_write_stats(app_name_or_pid)
                    if stats:
                        response = (
                            Fore.CYAN + f"I/O Stats for {stats['name']} (PID: {stats['pid']}):\n" +
                            f"  Read Bytes: {stats['read_bytes']} ({stats['read_bytes'] / (1024*1024):.2f} MB)\n" +
                            f"  Write Bytes: {stats['write_bytes']} ({stats['write_bytes'] / (1024*1024):.2f} MB)" + Style.RESET_ALL
                        )
                    else:
                        response = Fore.RED + f"Could not get stats for {app_name_or_pid}. App not found or not running." + Style.RESET_ALL
                else:
                    response = Fore.YELLOW + "Please specify an application name or PID for stats (e.g., 'app stats firefox' or 'app stats 5678')." + Style.RESET_ALL
            elif intent == 'system.scan_errors':
                errors = self.error_scanner.scan_system_logs()
                if errors:
                    response = Fore.YELLOW + "Found potential errors in system logs:\n" + "\n".join(errors) + Style.RESET_ALL
                else:
                    response = Fore.GREEN + "No significant errors found in system logs." + Style.RESET_ALL
            elif intent == 'research.web':
                query = get_entity_value('query')
                if query:
                    response_parts = self.researcher.perform_web_search(query)
                    response = Fore.BLUE + "Research results:\n" + "\n".join(response_parts) + Style.RESET_ALL
                else:
                    response = Fore.YELLOW + "Please provide a research query (e.g., 'research python performance tuning')." + Style.RESET_ALL
            elif intent == 'research.summarize':
                text_to_summarize = get_entity_value('text')
                if text_to_summarize:
                    summary = self.researcher.summarize_text(text_to_summarize)
                    response = Fore.MAGENTA + f"Summary: {summary}" + Style.RESET_ALL
                else:
                    response = Fore.YELLOW + "Please provide text to summarize (e.g., 'summarize This is a long piece of text...')." + Style.RESET_ALL
            elif intent == 'app.health':
                app_name_or_pid = get_entity_value('appNameOrPid')
                if app_name_or_pid:
                    health = self.error_scanner.check_application_health(app_name_or_pid)
                    if health["running"]:
                        response = (
                            Fore.GREEN + f"{health['name']} (PID: {health['pid']}) is running.\n" +
                            f"  CPU Usage: {health['cpu_percent']:.2f}%\n" +
                            f"  Memory Usage: {health['memory_percent']:.2f}%\n" +
                            f"  Status: {health['status']}" + Style.RESET_ALL
                        )
                    else:
                        response = Fore.RED + f"{app_name_or_pid} is not running or not found." + Style.RESET_ALL
                else:
                    response = Fore.YELLOW + "Please specify an application name or PID to check health (e.g., 'check health firefox')." + Style.RESET_ALL
            else:
                response = (f"{Fore.GREY}I'm not sure how to handle that command based on my current understanding. "
                            f"Intent: {intent} (Confidence: {score:.2f}).\n"
                            f"Try commands like: "
                            f"'list apps', 'launch app <name>', 'close app <name>', "
                            f"'app stats <name>', 'scan errors', 'research <query>', "
                            f"'summarize <text>', or 'check health <name>'.{Style.RESET_ALL}")
        except Exception as e:
            logging.critical(f"Unhandled error during command execution: {e}", exc_info=True)
            response = Fore.RED + f"An unexpected error occurred: {e}. Please check the logs." + Style.RESET_ALL
        return response

# --- Main Interaction Loop ---
if __name__ == "__main__":
    assistant = AIAssistant()

    while True:
        user_input = input(f"{Fore.CYAN}You: {Style.RESET_ALL}").strip()
        if user_input.lower() in ["exit", "quit"]:
            print(f"{Fore.MAGENTA}Assistant:{Style.RESET_ALL} {assistant.execute_command(user_input)}")
            break
        
        response = assistant.execute_command(user_input)
        print(f"{Fore.MAGENTA}Assistant:{Style.RESET_ALL} {response}")




python ai_assistant.py



Creating an "advanced AI assistant" in C++ that handles all installed apps, executes read/write attributes, scans errors, and performs research is an extremely complex and ambitious undertaking, especially for cross-platform compatibility.
Here's why and what's involved, followed by a conceptual outline and C++ code snippets.
Challenges in C++ for this Task:
 * Cross-Platform System Interaction:
   * Listing Installed Apps: There's no single cross-platform C++ standard library function for this.
     * Windows: Requires interacting with the Windows Registry (HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\Windows\CurrentVersion\Uninstall).
     * Linux: Involves parsing package manager databases (APT, RPM, Snap, Flatpak, etc.) which vary by distribution.
     * macOS: Involves scanning /Applications or using specific macOS frameworks.
   * Launching/Closing Apps: Requires OS-specific APIs (ShellExecute on Windows, fork/exec or NSTask on macOS/Linux).
   * Read/Write Monitoring (Deep Level): This is the most challenging aspect.
     * Windows: Requires kernel-level drivers, hooking system calls, or using advanced APIs like ETW (Event Tracing for Windows) or minifilter drivers. User-mode C++ cannot simply "monitor" another process's file I/O.
     * Linux: Involves ptrace, fanotify, inotify (for directory changes, not per-process I/O), or Linux Audit System. Again, often requires root privileges or complex setup.
     * macOS: Similar to Linux, using DTrace, Endpoint Security Framework, or other low-level mechanisms.
     * Practical Approach (User-level): We can get aggregated I/O statistics for a process (like psutil in Python) using libraries that abstract OS-specific process information (e.g., parsing /proc on Linux, using NtQuerySystemInformation on Windows).
 * Error Scanning (System Logs):
   * Windows: Event Log API.
   * Linux: journalctl (for systemd), parsing /var/log files.
   * macOS: log command or Unified Logging System APIs.
 * AI/NLP and Research:
   * NLP: C++ has libraries for numerical computation (Eigen, Boost.Numeric_Bindings) and some machine learning frameworks (TensorFlow C++ API, PyTorch C++ Frontend, ONNX Runtime, NCNN), but a direct equivalent to node-nlp (for easy intent recognition) or high-level NLP libraries like spaCy/NLTK in Python is less common or requires more manual setup. You'd likely need to integrate with a pre-trained model or build your own from scratch using a deep learning framework.
   * Web Research: Requires HTTP client libraries (e.g., libcurl, Boost.Asio, cpprestsdk) and potentially HTML parsers (libxml2, Gumbo). Interacting with LLM APIs (like OpenAI) means making HTTP requests and parsing JSON.
Due to these complexities, a full, production-ready, cross-platform C++ AI assistant with all requested features would be an extremely large project, often requiring kernel-level development and deep OS-specific knowledge.
Conceptual C++ Structure (Illustrative, not a complete runnable application):
This example focuses on how you might structure the C++ code and points to the necessary OS-specific calls or external libraries. We'll prioritize cross-platform design patterns where possible, but the actual implementation of core functionalities will heavily rely on platform-specific APIs.
Required Libraries (External - You'll need to install/configure these):
 * Process Information/System Stats:
   * libproc (macOS)
   * /proc filesystem parsing (Linux)
   * Windows.h / Psapi.h (Windows)
 * HTTP Client (for AI APIs/Web Research):
   * libcurl (cross-platform, C API but often used in C++)
   * Boost.Asio (networking, more C++ idiomatic)
 * JSON Parsing (for API responses):
   * nlohmann/json (easy to use, header-only)
 * NLP/ML (Advanced):
   * ONNX Runtime or TensorFlow Lite (for deploying pre-trained models)
   * FANN (Fast Artificial Neural Network Library - for simpler ANNs if you train locally)
   * Alternatively, a C++ wrapper around Python (e.g., Boost.Python) or a direct system call to a Python script for NLP could be simpler.
Project Structure Idea:
ai_assistant_cpp/
├── src/
│   ├── main.cpp
│   ├── CoreAssistant.hpp
│   ├── CoreAssistant.cpp
│   ├── AppManager.hpp
│   ├── AppManager.cpp
│   ├── AppManager_Win.cpp (Windows-specific implementation)
│   ├── AppManager_Linux.cpp (Linux-specific implementation)
│   ├── AppManager_Mac.cpp (macOS-specific implementation)
│   ├── ErrorScanner.hpp
│   ├── ErrorScanner.cpp
│   ├── ErrorScanner_Win.cpp
│   ├── ErrorScanner_Linux.cpp
│   ├── ErrorScanner_Mac.cpp
│   ├── Researcher.hpp
│   ├── Researcher.cpp
│   ├── NLPManager.hpp (Interface for NLP)
│   ├── NLPManager.cpp (Implementation using an ML library or external call)
│   ├── utils/
│   │   ├── PlatformUtils.hpp (OS detection, basic helper functions)
│   │   ├── PlatformUtils.cpp
│   │   ├── Logger.hpp
│   │   └── Logger.cpp
├── CMakeLists.txt (or Makefile)
├── external/ (for downloaded libraries, if not using a package manager)
├── README.md

Conceptual C++ Code Snippets
This is not a fully compilable and runnable project, but rather a guide to the structure and the types of functions you would implement.
1. utils/Logger.hpp (Basic Logging Utility)
#pragma once
#include <string>
#include <iostream>
#include <fstream>
#include <chrono>
#include <iomanip>
#include <mutex>

enum class LogLevel { INFO, WARNING, ERROR, CRITICAL };

class Logger {
public:
    static Logger& getInstance() {
        static Logger instance;
        return instance;
    }

    void setLogFile(const std::string& filename) {
        std::lock_guard<std::mutex> lock(mtx_);
        if (logFile_.is_open()) {
            logFile_.close();
        }
        logFile_.open(filename, std::ios_base::app);
        if (!logFile_.is_open()) {
            std::cerr << "Failed to open log file: " << filename << std::endl;
        }
    }

    void log(LogLevel level, const std::string& message) {
        std::lock_guard<std::mutex> lock(mtx_);
        std::string levelStr;
        switch (level) {
            case LogLevel::INFO: levelStr = "INFO"; break;
            case LogLevel::WARNING: levelStr = "WARNING"; break;
            case LogLevel::ERROR: levelStr = "ERROR"; break;
            case LogLevel::CRITICAL: levelStr = "CRITICAL"; break;
        }

        auto now = std::chrono::system_clock::now();
        auto in_time_t = std::chrono::system_clock::to_time_t(now);
        std::stringstream ss;
        ss << std::put_time(std::localtime(&in_time_t), "%Y-%m-%d %H:%M:%S")
           << " - " << levelStr << " - " << message << std::endl;

        std::cout << ss.str(); // Also print to console
        if (logFile_.is_open()) {
            logFile_ << ss.str();
            logFile_.flush();
        }
    }

private:
    Logger() {} // Private constructor
    Logger(const Logger&) = delete; // Delete copy constructor
    Logger& operator=(const Logger&) = delete; // Delete assignment operator

    std::ofstream logFile_;
    std::mutex mtx_;
};

// Convenience macros
#define LOG_INFO(msg) Logger::getInstance().log(LogLevel::INFO, msg)
#define LOG_WARN(msg) Logger::getInstance().log(LogLevel::WARNING, msg)
#define LOG_ERROR(msg) Logger::getInstance().log(LogLevel::ERROR, msg)
#define LOG_CRITICAL(msg) Logger::getInstance().log(LogLevel::CRITICAL, msg)

2. AppManager.hpp (Interface)
#pragma once
#include <string>
#include <vector>
#include <map>

// Structs to hold application and process information
struct AppInfo {
    std::string name;
    std::string version;
    std::string publisher;
    std::string installLocation; // Path to executable or bundle
    // Add more fields as needed
};

struct ProcessStats {
    int pid;
    std::string name;
    long long readBytes;
    long long writeBytes;
    double cpuPercent;
    double memoryPercent;
    std::string status;
};

class AppManager {
public:
    virtual ~AppManager() = default;

    virtual std::vector<AppInfo> listInstalledApps() = 0;
    virtual bool launchApp(const std::string& appNameOrPath) = 0;
    virtual bool closeApp(const std::string& appNameOrPid) = 0;
    virtual ProcessStats getAppReadWriteStats(const std::string& appNameOrPid) = 0;
    virtual ProcessStats getAppHealth(const std::string& appNameOrPid) = 0;

    // Factory method to create platform-specific AppManager
    static AppManager* create();
};

3. AppManager_Win.cpp (Windows Implementation - partial)
#include "AppManager.hpp"
#include "utils/Logger.hpp"

// Windows specific headers
#include <windows.h>
#include <winreg.h> // For registry access
#include <Psapi.h>  // For process info (GetProcessMemoryInfo, GetProcessIoCounters)
#include <tlhelp32.h> // For process snapshot (CreateToolhelp32Snapshot)

// Need to link against Advapi32.lib, Psapi.lib

class AppManager_Win : public AppManager {
public:
    std::vector<AppInfo> listInstalledApps() override {
        std::vector<AppInfo> apps;
        HKEY hKey;
        LPCSTR subKey = "SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Uninstall";

        if (RegOpenKeyExA(HKEY_LOCAL_MACHINE, subKey, 0, KEY_READ, &hKey) == ERROR_SUCCESS) {
            char subkeyName[256];
            DWORD subkeyNameSize;
            for (DWORD i = 0; ; ++i) {
                subkeyNameSize = sizeof(subkeyName);
                if (RegEnumKeyExA(hKey, i, subkeyName, &subkeyNameSize, NULL, NULL, NULL, NULL) != ERROR_SUCCESS) {
                    break;
                }

                HKEY hSubKey;
                std::string appSubKey = std::string(subKey) + "\\" + subkeyName;
                if (RegOpenKeyExA(HKEY_LOCAL_MACHINE, appSubKey.c_str(), 0, KEY_READ, &hSubKey) == ERROR_SUCCESS) {
                    AppInfo app;
                    char value[1024];
                    DWORD valueSize;

                    valueSize = sizeof(value);
                    if (RegQueryValueExA(hSubKey, "DisplayName", NULL, NULL, (LPBYTE)value, &valueSize) == ERROR_SUCCESS) {
                        app.name = value;
                    }
                    valueSize = sizeof(value);
                    if (RegQueryValueExA(hSubKey, "DisplayVersion", NULL, NULL, (LPBYTE)value, &valueSize) == ERROR_SUCCESS) {
                        app.version = value;
                    }
                    valueSize = sizeof(value);
                    if (RegQueryValueExA(hSubKey, "Publisher", NULL, NULL, (LPBYTE)value, &valueSize) == ERROR_SUCCESS) {
                        app.publisher = value;
                    }
                    valueSize = sizeof(value);
                    if (RegQueryValueExA(hSubKey, "InstallLocation", NULL, NULL, (LPBYTE)value, &valueSize) == ERROR_SUCCESS) {
                        app.installLocation = value;
                    }
                    if (!app.name.empty()) {
                        apps.push_back(app);
                    }
                    RegCloseKey(hSubKey);
                }
            }
            RegCloseKey(hKey);
            LOG_INFO("Listed " + std::to_string(apps.size()) + " applications on Windows.");
        } else {
            LOG_ERROR("Failed to open registry key for installed apps.");
        }
        return apps;
    }

    bool launchApp(const std::string& appNameOrPath) override {
        // Use ShellExecuteEx for robust launching
        SHELLEXECUTEINFOA sei = { sizeof(SHELLEXECUTEINFOA) };
        sei.lpVerb = "open";
        sei.lpFile = appNameOrPath.c_str();
        sei.nShow = SW_SHOWNORMAL;
        sei.fMask = SEE_MASK_NOCLOSEPROCESS; // Keep process handle

        if (ShellExecuteExA(&sei)) {
            // Optionally wait for process or get its PID
            if (sei.hProcess) {
                // WaitForSingleObject(sei.hProcess, INFINITE); // If you need to wait
                CloseHandle(sei.hProcess);
            }
            LOG_INFO("Attempted to launch: " + appNameOrPath);
            return true;
        }
        LOG_ERROR("Failed to launch " + appNameOrPath + ". Error: " + std::to_string(GetLastError()));
        return false;
    }

    bool closeApp(const std::string& appNameOrPid) override {
        // Implementation using TerminateProcess and CreateToolhelp32Snapshot
        // Similar logic to Python's psutil iteration
        // Requires OpenProcess with PROCESS_TERMINATE access
        LOG_INFO("Attempting to close: " + appNameOrPid);
        return false; // Placeholder
    }

    ProcessStats getAppReadWriteStats(const std::string& appNameOrPid) override {
        ProcessStats stats = {0, appNameOrPid, 0, 0, 0.0, 0.0, "N/A"};
        // Use OpenProcess, GetProcessIoCounters, GetProcessTimes
        // This is complex and requires specific permissions.
        // Reading CPU/Memory percent is also non-trivial and requires sampling over time.
        LOG_INFO("Getting I/O stats for: " + appNameOrPid);
        return stats; // Placeholder
    }

    ProcessStats getAppHealth(const std::string& appNameOrPid) override {
        ProcessStats stats = {0, appNameOrPid, 0, 0, 0.0, 0.0, "N/A"};
        // Similar to getAppReadWriteStats, involves process enumeration and performance counters.
        LOG_INFO("Checking health for: " + appNameOrPid);
        return stats; // Placeholder
    }
};

// Factory method implementation
AppManager* AppManager::create() {
    return new AppManager_Win();
}

4. AppManager_Linux.cpp (Linux Implementation - partial)
#include "AppManager.hpp"
#include "utils/Logger.hpp"
#include <fstream>
#include <dirent.h> // For directory listing
#include <algorithm> // For std::find_if
#include <cstdlib>   // For system()

// Note: Listing installed apps on Linux is highly dependent on the package manager (apt, rpm, pacman, snap, flatpak).
// This is a simplified example for Debian/Ubuntu using `dpkg`.

class AppManager_Linux : public AppManager {
public:
    std::vector<AppInfo> listInstalledApps() override {
        std::vector<AppInfo> apps;
        // Example for Debian/Ubuntu systems
        FILE* pipe = popen("dpkg -l | grep '^ii' | awk '{print $2, $3}'", "r");
        if (!pipe) {
            LOG_ERROR("Failed to run dpkg command.");
            return apps;
        }
        char buffer[128];
        while (fgets(buffer, sizeof(buffer), pipe) != NULL) {
            std::string line = buffer;
            size_t space_pos = line.find(' ');
            if (space_pos != std::string::npos) {
                AppInfo app;
                app.name = line.substr(0, space_pos);
                app.version = line.substr(space_pos + 1);
                app.version.pop_back(); // Remove newline
                apps.push_back(app);
            }
        }
        pclose(pipe);
        LOG_INFO("Listed " + std::to_string(apps.size()) + " applications on Linux.");
        return apps;
    }

    bool launchApp(const std::string& appNameOrPath) override {
        // Attempt to launch via system() or fork/exec
        // For GUI apps, you might need `xdg-open` or specific desktop environment commands.
        std::string command = "nohup " + appNameOrPath + " &"; // 'nohup' and '&' to detach
        int result = system(command.c_str());
        if (result == 0) {
            LOG_INFO("Attempted to launch: " + appNameOrPath);
            return true;
        }
        LOG_ERROR("Failed to launch " + appNameOrPath + ". Error code: " + std::to_string(result));
        return false;
    }

    bool closeApp(const std::string& appNameOrPid) override {
        // Use `kill` command or iterate `/proc` for PID and send SIGTERM
        // Needs proper parsing of /proc/[pid]/status or /proc/[pid]/comm
        LOG_INFO("Attempting to close: " + appNameOrPid);
        return false; // Placeholder
    }

    ProcessStats getAppReadWriteStats(const std::string& appNameOrPid) override {
        ProcessStats stats = {0, appNameOrPid, 0, 0, 0.0, 0.0, "N/A"};
        // Read from /proc/[pid]/io for read_bytes/write_bytes
        // Read from /proc/[pid]/stat for CPU/Memory (complex parsing needed)
        LOG_INFO("Getting I/O stats for: " + appNameOrPid);
        return stats; // Placeholder
    }

    ProcessStats getAppHealth(const std::string& appNameOrPid) override {
        ProcessStats stats = {0, appNameOrPid, 0, 0, 0.0, 0.0, "N/A"};
        // Similar to getAppReadWriteStats, involves parsing /proc.
        LOG_INFO("Checking health for: " + appNameOrPid);
        return stats; // Placeholder
    }
};

// Factory method implementation (Linux specific part)
#include <iostream>
#include <string>

// In AppManager.cpp, you'd have the actual factory logic
// For this example, we'll put a simple placeholder here.
// In a real build system (CMake), you'd conditionally compile these.
#ifdef __linux__
AppManager* AppManager::create() {
    return new AppManager_Linux();
}
#endif

5. ErrorScanner.hpp (Interface)
#pragma once
#include <string>
#include <vector>

struct AppHealth {
    bool isRunning;
    int pid;
    std::string name;
    double cpuUsagePercent;
    double memoryUsagePercent;
    std::string status; // e.g., "running", "sleeping", "zombie"
};

class ErrorScanner {
public:
    virtual ~ErrorScanner() = default;

    virtual std::vector<std::string> scanSystemLogs(const std::vector<std::string>& keywords) = 0;
    virtual AppHealth checkApplicationHealth(const std::string& appNameOrPid) = 0;

    static ErrorScanner* create();
};

6. ErrorScanner_Win.cpp (Windows Implementation - partial)
#include "ErrorScanner.hpp"
#include "utils/Logger.hpp"

// Windows specific headers
#include <windows.h>
#include <winnt.h> // For Event Log types
#include <winevt.h> // For modern Event Log API (Evt* functions)

// Need to link against Wevtapi.lib

class ErrorScanner_Win : public ErrorScanner {
public:
    std::vector<std::string> scanSystemLogs(const std::vector<std::string>& keywords) override {
        std::vector<std::string> errors;
        // Using the modern Windows Event Log API (EvtQuery, EvtRender)
        // This is complex, but powerful.
        // Example query for errors/critical events in Application and System logs:
        // L"*[System[(Level=1 or Level=2) and (Provider/@Name='Application' or Provider/@Name='System')]]"
        // And then filter messages for keywords.
        LOG_INFO("Scanning Windows Event Logs for errors.");
        return errors; // Placeholder
    }

    AppHealth checkApplicationHealth(const std::string& appNameOrPid) override {
        AppHealth health = {false, 0, appNameOrPid, 0.0, 0.0, "N/A"};
        // Similar to AppManager_Win::getAppReadWriteStats, requires process enumeration.
        LOG_INFO("Checking Windows app health for: " + appNameOrPid);
        return health; // Placeholder
    }
};

// Factory method implementation (Windows specific part)
#ifdef _WIN32
ErrorScanner* ErrorScanner::create() {
    return new ErrorScanner_Win();
}
#endif

7. Researcher.hpp
#pragma once
#include <string>
#include <vector>
#include <optional> // C++17

// Requires nlohmann/json and libcurl
// For OpenAI API calls

class Researcher {
public:
    Researcher(const std::optional<std::string>& openaiApiKey = std::nullopt);
    ~Researcher();

    std::vector<std::string> performWebSearch(const std::string& query);
    std::string summarizeText(const std::string& text);

private:
    std::optional<std::string> openaiApiKey_;
    void* curl_handle_; // Opaque pointer for CURL handle

    std::string makeOpenAIRequest(const std::string& endpoint, const std::string& json_payload);
    // Helper for curl write callback
    static size_t WriteCallback(void* contents, size_t size, size_t nmemb, void* userp);
};

8. Researcher.cpp (Partial - requires libcurl setup)
#include "Researcher.hpp"
#include "utils/Logger.hpp"
#include "nlohmann/json.hpp" // For JSON parsing

// For libcurl - include appropriate headers and link library
#include <curl/curl.h>

// Static member for curl callback
size_t Researcher::WriteCallback(void* contents, size_t size, size_t nmemb, void* userp) {
    ((std::string*)userp)->append((char*)contents, size * nmemb);
    return size * nmemb;
}

Researcher::Researcher(const std::optional<std::string>& openaiApiKey)
    : openaiApiKey_(openaiApiKey), curl_handle_(nullptr) {
    if (openaiApiKey_.has_value()) {
        curl_global_init(CURL_GLOBAL_DEFAULT);
        curl_handle_ = curl_easy_init();
        if (!curl_handle_) {
            LOG_ERROR("Failed to initialize cURL for Researcher.");
            openaiApiKey_ = std::nullopt; // Disable OpenAI if curl fails
        }
        LOG_INFO("Researcher initialized. OpenAI enabled.");
    } else {
        LOG_WARN("OpenAI API key not provided. Research and summarization will be simulated.");
    }
}

Researcher::~Researcher() {
    if (curl_handle_) {
        curl_easy_cleanup(static_cast<CURL*>(curl_handle_));
        curl_global_cleanup();
    }
}

std::string Researcher::makeOpenAIRequest(const std::string& endpoint, const std::string& json_payload) {
    if (!openaiApiKey_.has_value() || !curl_handle_) {
        return "OpenAI not configured.";
    }

    CURL* curl = static_cast<CURL*>(curl_handle_);
    std::string readBuffer;

    struct curl_slist *headers = NULL;
    headers = curl_slist_append(headers, "Content-Type: application/json");
    headers = curl_slist_append(headers, ("Authorization: Bearer " + openaiApiKey_.value()).c_str());

    curl_easy_setopt(curl, CURLOPT_URL, ("https://api.openai.com/v1/" + endpoint).c_str());
    curl_easy_setopt(curl, CURLOPT_HTTPHEADER, headers);
    curl_easy_setopt(curl, CURLOPT_POSTFIELDS, json_payload.c_str());
    curl_easy_setopt(curl, CURLOPT_WRITEFUNCTION, WriteCallback);
    curl_easy_setopt(curl, CURLOPT_WRITEDATA, &readBuffer);

    CURLcode res = curl_easy_perform(curl);
    curl_slist_free_all(headers);

    if (res != CURLE_OK) {
        LOG_ERROR("cURL failed: " + std::string(curl_easy_strerror(res)));
        return "Error making OpenAI request.";
    }

    // Parse JSON response
    try {
        nlohmann::json jsonResponse = nlohmann::json::parse(readBuffer);
        if (jsonResponse.contains("choices") && !jsonResponse["choices"].empty()) {
            return jsonResponse["choices"][0]["message"]["content"].get<std::string>();
        }
    } catch (const nlohmann::json::exception& e) {
        LOG_ERROR("Failed to parse JSON response: " + std::string(e.what()));
    }
    return "No content in OpenAI response.";
}


std::vector<std::string> Researcher::performWebSearch(const std::string& query) {
    LOG_INFO("Performing simulated web search for: '" + query + "'");
    if (!openaiApiKey_.has_value()) {
        return {"Simulated search result 1 for '" + query + "'", "Simulated search result 2 for '" + query + "'"};
    }

    nlohmann::json payload;
    payload["model"] = "gpt-4o";
    payload["messages"] = {
        {{"role", "system"}, {"content", "You are a helpful assistant that provides concise search-like results."}},
        {{"role", "user"}, {"content", "Provide 2-3 concise search results or a brief summary for: " + query}}
    };
    payload["max_tokens"] = 300;
    payload["temperature"] = 0.7;

    std::string response = makeOpenAIRequest("chat/completions", payload.dump());
    if (response.find("Error") == 0 || response.find("No content") == 0) {
        return {response};
    }
    // Simple split by newline for demonstration
    std::vector<std::string> results;
    std::string line;
    std::istringstream iss(response);
    while (std::getline(iss, line)) {
        if (!line.empty()) {
            results.push_back(line);
        }
    }
    return results;
}

std::string Researcher::summarizeText(const std::string& text) {
    LOG_INFO("Attempting to summarize text (first 50 chars): '" + text.substr(0, 50) + "...'");
    if (!openaiApiKey_.has_value()) {
        return "Summary of: " + text.substr(0, 100) + "... (OpenAI not configured)";
    }

    nlohmann::json payload;
    payload["model"] = "gpt-4o";
    payload["messages"] = {
        {{"role", "system"}, {"content", "You are a helpful assistant that summarizes text concisely."}},
        {{"role", "user"}, {"content", "Summarize the following text:\n\n" + text}}
    };
    payload["max_tokens"] = 200;
    payload["temperature"] = 0.7;

    std::string response = makeOpenAIRequest("chat/completions", payload.dump());
    if (response.find("Error") == 0 || response.find("No content") == 0) {
        return response;
    }
    return response;
}

9. NLPManager.hpp (Interface for NLP)
#pragma once
#include <string>
#include <vector>
#include <map>

// Struct to represent NLP processing result
struct NlpResult {
    std::string intent;
    double score;
    std::map<std::string, std::string> entities; // entity_name -> value
};

class NLPManager {
public:
    virtual ~NLPManager() = default;

    virtual bool initialize() = 0; // Load/train model
    virtual NlpResult process(const std::string& text) = 0;
};

// You'd have concrete implementations like NLPManager_InternalML.cpp
// or NLPManager_PythonBridge.cpp

10. CoreAssistant.hpp (Main Orchestrator)
#pragma once
#include "AppManager.hpp"
#include "ErrorScanner.hpp"
#include "Researcher.hpp"
#include "NLPManager.hpp"
#include "utils/Logger.hpp"

#include <memory> // For std::unique_ptr

class CoreAssistant {
public:
    CoreAssistant(const std::string& openaiApiKey);
    std::string executeCommand(const std::string& command);

private:
    std::unique_ptr<AppManager> appManager_;
    std::unique_ptr<ErrorScanner> errorScanner_;
    std::unique_ptr<Researcher> researcher_;
    std::unique_ptr<NLPManager> nlpManager_;

    // Helper to extract entities from NLP result
    std::string getEntityValue(const NlpResult& result, const std::string& entityName) const;
};

11. CoreAssistant.cpp (Main Logic)
#include "CoreAssistant.hpp"
#include <iostream>
#include <sstream>

CoreAssistant::CoreAssistant(const std::string& openaiApiKey) {
    Logger::getInstance().setLogFile("assistant.log");
    LOG_INFO("CoreAssistant initializing...");

    appManager_ = std::unique_ptr<AppManager>(AppManager::create());
    errorScanner_ = std::unique_ptr<ErrorScanner>(ErrorScanner::create());
    researcher_ = std::make_unique<Researcher>(openaiApiKey);

    // Placeholder for NLPManager - in a real app, this would be complex
    // For a minimal example, you might even do rule-based NLP here instead of a full NLPManager
    // nlpManager_ = std::unique_ptr<NLPManager>(NLPManager::create());
    // nlpManager_->initialize(); // Initialize NLP model

    LOG_INFO("CoreAssistant initialized.");
}

std::string CoreAssistant::getEntityValue(const NlpResult& result, const std::string& entityName) const {
    auto it = result.entities.find(entityName);
    if (it != result.entities.end()) {
        return it->second;
    }
    return "";
}

std::string CoreAssistant::executeCommand(const std::string& command) {
    LOG_INFO("Executing command: " + command);

    // --- Placeholder/Rule-based NLP for demonstration ---
    // In a real C++ NLP solution, you'd integrate a proper NLP library here.
    // This is a very basic keyword matching for demonstration purposes.
    std::string lowerCommand = command;
    std::transform(lowerCommand.begin(), lowerCommand.end(), lowerCommand.begin(), ::tolower);

    if (lowerCommand == "list installed apps" || lowerCommand == "show me my applications") {
        std::stringstream ss;
        ss << "Listing installed applications...\n";
        std::vector<AppInfo> apps = appManager_->listInstalledApps();
        if (apps.empty()) {
            ss << "No apps found or error occurred.";
        } else {
            for (const auto& app : apps) {
                ss << "  - " << app.name;
                if (!app.version.empty()) ss << " (v" << app.version << ")";
                if (!app.publisher.empty()) ss << " by " << app.publisher;
                ss << "\n";
            }
        }
        return ss.str();
    }
    else if (lowerCommand.rfind("launch app ", 0) == 0) {
        std::string appName = command.substr(11); // "launch app " is 11 chars
        if (appManager_->launchApp(appName)) {
            return "Attempting to launch " + appName + ".";
        } else {
            return "Failed to launch " + appName + ".";
        }
    }
    else if (lowerCommand.rfind("close app ", 0) == 0) {
        std::string appNameOrPid = command.substr(10);
        if (appManager_->closeApp(appNameOrPid)) {
            return "Attempting to close " + appNameOrPid + ".";
        } else {
            return "Failed to close " + appNameOrPid + ".";
        }
    }
    else if (lowerCommand.rfind("get app stats for ", 0) == 0) {
        std::string appNameOrPid = command.substr(18);
        ProcessStats stats = appManager_->getAppReadWriteStats(appNameOrPid);
        if (stats.pid != 0) { // Assuming PID 0 means not found
            std::stringstream ss;
            ss << "I/O Stats for " << stats.name << " (PID: " << stats.pid << "):\n"
               << "  Read Bytes: " << stats.readBytes << " (" << (double)stats.readBytes / (1024*1024) << " MB)\n"
               << "  Write Bytes: " << stats.writeBytes << " (" << (double)stats.writeBytes / (1024*1024) << " MB)";
            return ss.str();
        } else {
            return "Could not get stats for " + appNameOrPid + ". App not found or not running.";
        }
    }
    else if (lowerCommand == "scan system errors") {
        std::stringstream ss;
        ss << "Scanning system logs for errors...\n";
        std::vector<std::string> errors = errorScanner_->scanSystemLogs({"error", "fail", "critical"});
        if (errors.empty()) {
            ss << "No significant errors found in system logs.";
        } else {
            ss << "Found potential errors:\n";
            for (const auto& error : errors) {
                ss << "- " << error << "\n";
            }
        }
        return ss.str();
    }
    else if (lowerCommand.rfind("research ", 0) == 0) {
        std::string query = command.substr(9);
        std::stringstream ss;
        ss << "Performing web research for: '" << query << "'\n";
        std::vector<std::string> results = researcher_->performWebSearch(query);
        for (const auto& result : results) {
            ss << "- " << result << "\n";
        }
        return ss.str();
    }
    else if (lowerCommand.rfind("summarize ", 0) == 0) {
        std::string text = command.substr(10);
        std::stringstream ss;
        ss << "Summarizing text...\n";
        std::string summary = researcher_->summarizeText(text);
        ss << summary;
        return ss.str();
    }
    else if (lowerCommand.rfind("check health of ", 0) == 0) {
        std::string appNameOrPid = command.substr(16);
        AppHealth health = errorScanner_->checkApplicationHealth(appNameOrPid);
        if (health.isRunning) {
            std::stringstream ss;
            ss << health.name << " (PID: " << health.pid << ") is running.\n"
               << "  CPU Usage: " << health.cpuUsagePercent << "%\n"
               << "  Memory Usage: " << health.memoryUsagePercent << "%\n"
               << "  Status: " << health.status;
            return ss.str();
        } else {
            return appNameOrPid + " is not running or not found.";
        }
    }
    else {
        return "I don't understand that command. Try: 'list installed apps', 'launch app <name>', 'scan system errors', 'research <query>', 'summarize <text>', 'check health of <name>'.";
    }

    // In a real NLP scenario, you'd get NlpResult from nlpManager_
    // NlpResult nlpResult = nlpManager_->process(command);
    // double confidence = nlpResult.score;
    // std::string intent = nlpResult.intent;
    // ... then use switch-case based on 'intent'
}

12. main.cpp
#include "CoreAssistant.hpp"
#include "utils/Logger.hpp" // For Logger setup
#include <iostream>
#include <string>

int main() {
    // Set your OpenAI API key here, or retrieve from environment variable
    // For C++, it's common to use environment variables or a config file
    // For example:
    const char* openai_api_key_env = std::getenv("OPENAI_API_KEY");
    std::string openaiApiKey = openai_api_key_env ? openai_api_key_env : "";

    CoreAssistant assistant(openaiApiKey);

    std::cout << "Advanced AI Assistant started. Type 'exit' to quit." << std::endl;

    std::string userInput;
    while (true) {
        std::cout << "\nYou: ";
        std::getline(std::cin, userInput);

        if (userInput == "exit" || userInput == "quit") {
            std::cout << "Assistant: Exiting. Goodbye!" << std::endl;
            break;
        }

        std::string response = assistant.executeCommand(userInput);
        std::cout << "Assistant: " << response << std::endl;
    }

    return 0;
}

Building and Running (Conceptual CMake)
You would typically use CMake to manage the build process for a cross-platform C++ project.
CMakeLists.txt (Simplified example)
cmake_minimum_required(VERSION 3.10)
project(AIAssistant CXX)

set(CMAKE_CXX_STANDARD 17)
set(CMAKE_CXX_STANDARD_REQUIRED True)

# Detect OS to include platform-specific files
if(WIN32)
    add_definitions(-D_WIN32)
    set(PLATFORM_SPECIFIC_SRCS
        src/AppManager_Win.cpp
        src/ErrorScanner_Win.cpp
    )
    # Link Windows specific libraries
    target_link_libraries(${PROJECT_NAME} PRIVATE Advapi32.lib Psapi.lib Wevtapi.lib Shell32.lib)
elseif(UNIX) # Covers Linux and macOS
    if(APPLE)
        add_definitions(-D__APPLE__)
        set(PLATFORM_SPECIFIC_SRCS
            src/AppManager_Mac.cpp
            src/ErrorScanner_Mac.cpp
        )
        # Link macOS specific frameworks/libraries
        # target_link_libraries(${PROJECT_NAME} PRIVATE -framework Foundation -framework AppKit -lobjc)
    else() # Linux
        add_definitions(-D__linux__)
        set(PLATFORM_SPECIFIC_SRCS
            src/AppManager_Linux.cpp
            src/ErrorScanner_Linux.cpp
        )
        # Link Linux specific libraries (e.g., for system stats, if needed)
    endif()
endif()

# Source files
set(SOURCES
    src/main.cpp
    src/CoreAssistant.cpp
    src/AppManager.cpp # Base AppManager implementation (might be empty or contain factory)
    src/ErrorScanner.cpp # Base ErrorScanner implementation (might be empty or contain factory)
    src/Researcher.cpp
    src/utils/Logger.cpp
    ${PLATFORM_SPECIFIC_SRCS}
)

add_executable(${PROJECT_NAME} ${SOURCES})

# --- External Library Integration (Conceptual) ---

# Find and link libcurl
# Find_Package(CURL REQUIRED)
# target_link_libraries(${PROJECT_NAME} PRIVATE ${CURL_LIBRARIES})
# include_directories(${CURL_INCLUDE_DIRS})

# Include nlohmann/json (assuming it's header-only and in a known path or external/)
# target_include_directories(${PROJECT_NAME} PUBLIC ${CMAKE_SOURCE_DIR}/external/json)

# If using ONNX Runtime or TensorFlow Lite C++ API, you'd add similar find_package/target_link_libraries calls.

To build (Linux/macOS example):
mkdir build
cd build
cmake ..
make
./AIAssistant # To run

To build (Windows - Visual Studio):
Use CMake to generate Visual Studio project files, then open and build in VS.
Deep I/O Monitoring Note:
The getAppReadWriteStats methods in the C++ examples are highly simplified placeholders. Achieving accurate, real-time, per-file I/O monitoring for arbitrary processes in C++ without deep OS-specific system programming (kernel drivers, hooking, etc.) is practically impossible from a standard user-mode application. Libraries like psutil in Python (which itself often relies on OS-specific kernel interfaces or /proc filesystem parsing) abstract this complexity.
For a true "advanced AI assistant" in C++ focusing on this, you would be venturing into security software development, requiring strong expertise in kernel programming for each target OS.
AI/NLP in C++ Note:
For the NLP part (NLPManager), you have a few options:
 * Rule-based/Keyword Matching: As shown in CoreAssistant.cpp, for very simple commands. This is limited.
 * Integrate a C++ ML/DL Framework: Use TensorFlow C++ API, PyTorch C++ Frontend, or ONNX Runtime to load a pre-trained model (e.g., for intent classification or entity recognition). This involves training a model in Python (or another ML-friendly language) and then exporting it to a C++ compatible format.
 * Embed Python: Use Boost.Python or Python's C API to run Python scripts/libraries directly from your C++ code. This allows you to leverage Python's rich NLP ecosystem while keeping your main application in C++. This is often the most practical approach for complex NLP.
 * OpenAI API (as implemented): For higher-level AI capabilities like summarization and simulated research, directly calling cloud-based LLM APIs via libcurl is a feasible C++ approach.
Conclusion:
Building this in C++ is a monumental task due to the need for low-level OS interaction and the less mature C++ ecosystem for high-level AI/NLP compared to Python. The provided code gives you a structured starting point, highlighting where OS-specific implementations are crucial and the external libraries you'd need to integrate.


#pragma once
#include <string>
#include <iostream>
#include <fstream>
#include <chrono>
#include <iomanip>
#include <mutex>

enum class LogLevel { INFO, WARNING, ERROR, CRITICAL };

class Logger {
public:
    static Logger& getInstance() {
        static Logger instance;
        return instance;
    }

    void setLogFile(const std::string& filename) {
        std::lock_guard<std::mutex> lock(mtx_);
        if (logFile_.is_open()) {
            logFile_.close();
        }
        logFile_.open(filename, std::ios_base::app);
        if (!logFile_.is_open()) {
            std::cerr << "Failed to open log file: " << filename << std::endl;
        }
    }

    void log(LogLevel level, const std::string& message) {
        std::lock_guard<std::mutex> lock(mtx_);
        std::string levelStr;
        switch (level) {
            case LogLevel::INFO: levelStr = "INFO"; break;
            case LogLevel::WARNING: levelStr = "WARNING"; break;
            case LogLevel::ERROR: levelStr = "ERROR"; break;
            case LogLevel::CRITICAL: levelStr = "CRITICAL"; break;
        }

        auto now = std::chrono::system_clock::now();
        auto in_time_t = std::chrono::system_clock::to_time_t(now);
        std::stringstream ss;
        ss << std::put_time(std::localtime(&in_time_t), "%Y-%m-%d %H:%M:%S")
           << " - " << levelStr << " - " << message << std::endl;

        std::cout << ss.str(); // Also print to console
        if (logFile_.is_open()) {
            logFile_ << ss.str();
            logFile_.flush();
        }
    }

private:
    Logger() {} // Private constructor
    Logger(const Logger&) = delete; // Delete copy constructor
    Logger& operator=(const Logger&) = delete; // Delete assignment operator

    std::ofstream logFile_;
    std::mutex mtx_;
};

// Convenience macros
#define LOG_INFO(msg) Logger::getInstance().log(LogLevel::INFO, msg)
#define LOG_WARN(msg) Logger::getInstance().log(LogLevel::WARNING, msg)
#define LOG_ERROR(msg) Logger::getInstance().log(LogLevel::ERROR, msg)
#define LOG_CRITICAL(msg) Logger::getInstance().log(LogLevel::CRITICAL, msg)



#pragma once
#include <string>
#include <vector>
#include <map>

// Structs to hold application and process information
struct AppInfo {
    std::string name;
    std::string version;
    std::string publisher;
    std::string installLocation; // Path to executable or bundle
    // Add more fields as needed
};

struct ProcessStats {
    int pid;
    std::string name;
    long long readBytes;
    long long writeBytes;
    double cpuPercent;
    double memoryPercent;
    std::string status;
};

class AppManager {
public:
    virtual ~AppManager() = default;

    virtual std::vector<AppInfo> listInstalledApps() = 0;
    virtual bool launchApp(const std::string& appNameOrPath) = 0;
    virtual bool closeApp(const std::string& appNameOrPid) = 0;
    virtual ProcessStats getAppReadWriteStats(const std::string& appNameOrPid) = 0;
    virtual ProcessStats getAppHealth(const std::string& appNameOrPid) = 0;

    // Factory method to create platform-specific AppManager
    static AppManager* create();
};



#include "AppManager.hpp"
#include "utils/Logger.hpp"

// Windows specific headers
#include <windows.h>
#include <winreg.h> // For registry access
#include <Psapi.h>  // For process info (GetProcessMemoryInfo, GetProcessIoCounters)
#include <tlhelp32.h> // For process snapshot (CreateToolhelp32Snapshot)

// Need to link against Advapi32.lib, Psapi.lib

class AppManager_Win : public AppManager {
public:
    std::vector<AppInfo> listInstalledApps() override {
        std::vector<AppInfo> apps;
        HKEY hKey;
        LPCSTR subKey = "SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Uninstall";

        if (RegOpenKeyExA(HKEY_LOCAL_MACHINE, subKey, 0, KEY_READ, &hKey) == ERROR_SUCCESS) {
            char subkeyName[256];
            DWORD subkeyNameSize;
            for (DWORD i = 0; ; ++i) {
                subkeyNameSize = sizeof(subkeyName);
                if (RegEnumKeyExA(hKey, i, subkeyName, &subkeyNameSize, NULL, NULL, NULL, NULL) != ERROR_SUCCESS) {
                    break;
                }

                HKEY hSubKey;
                std::string appSubKey = std::string(subKey) + "\\" + subkeyName;
                if (RegOpenKeyExA(HKEY_LOCAL_MACHINE, appSubKey.c_str(), 0, KEY_READ, &hSubKey) == ERROR_SUCCESS) {
                    AppInfo app;
                    char value[1024];
                    DWORD valueSize;

                    valueSize = sizeof(value);
                    if (RegQueryValueExA(hSubKey, "DisplayName", NULL, NULL, (LPBYTE)value, &valueSize) == ERROR_SUCCESS) {
                        app.name = value;
                    }
                    valueSize = sizeof(value);
                    if (RegQueryValueExA(hSubKey, "DisplayVersion", NULL, NULL, (LPBYTE)value, &valueSize) == ERROR_SUCCESS) {
                        app.version = value;
                    }
                    valueSize = sizeof(value);
                    if (RegQueryValueExA(hSubKey, "Publisher", NULL, NULL, (LPBYTE)value, &valueSize) == ERROR_SUCCESS) {
                        app.publisher = value;
                    }
                    valueSize = sizeof(value);
                    if (RegQueryValueExA(hSubKey, "InstallLocation", NULL, NULL, (LPBYTE)value, &valueSize) == ERROR_SUCCESS) {
                        app.installLocation = value;
                    }
                    if (!app.name.empty()) {
                        apps.push_back(app);
                    }
                    RegCloseKey(hSubKey);
                }
            }
            RegCloseKey(hKey);
            LOG_INFO("Listed " + std::to_string(apps.size()) + " applications on Windows.");
        } else {
            LOG_ERROR("Failed to open registry key for installed apps.");
        }
        return apps;
    }

    bool launchApp(const std::string& appNameOrPath) override {
        // Use ShellExecuteEx for robust launching
        SHELLEXECUTEINFOA sei = { sizeof(SHELLEXECUTEINFOA) };
        sei.lpVerb = "open";
        sei.lpFile = appNameOrPath.c_str();
        sei.nShow = SW_SHOWNORMAL;
        sei.fMask = SEE_MASK_NOCLOSEPROCESS; // Keep process handle

        if (ShellExecuteExA(&sei)) {
            // Optionally wait for process or get its PID
            if (sei.hProcess) {
                // WaitForSingleObject(sei.hProcess, INFINITE); // If you need to wait
                CloseHandle(sei.hProcess);
            }
            LOG_INFO("Attempted to launch: " + appNameOrPath);
            return true;
        }
        LOG_ERROR("Failed to launch " + appNameOrPath + ". Error: " + std::to_string(GetLastError()));
        return false;
    }

    bool closeApp(const std::string& appNameOrPid) override {
        // Implementation using TerminateProcess and CreateToolhelp32Snapshot
        // Similar logic to Python's psutil iteration
        // Requires OpenProcess with PROCESS_TERMINATE access
        LOG_INFO("Attempting to close: " + appNameOrPid);
        return false; // Placeholder
    }

    ProcessStats getAppReadWriteStats(const std::string& appNameOrPid) override {
        ProcessStats stats = {0, appNameOrPid, 0, 0, 0.0, 0.0, "N/A"};
        // Use OpenProcess, GetProcessIoCounters, GetProcessTimes
        // This is complex and requires specific permissions.
        // Reading CPU/Memory percent is also non-trivial and requires sampling over time.
        LOG_INFO("Getting I/O stats for: " + appNameOrPid);
        return stats; // Placeholder
    }

    ProcessStats getAppHealth(const std::string& appNameOrPid) override {
        ProcessStats stats = {0, appNameOrPid, 0, 0, 0.0, 0.0, "N/A"};
        // Similar to getAppReadWriteStats, involves process enumeration and performance counters.
        LOG_INFO("Checking health for: " + appNameOrPid);
        return stats; // Placeholder
    }
};

// Factory method implementation
AppManager* AppManager::create() {
    return new AppManager_Win();
}



#include "AppManager.hpp"
#include "utils/Logger.hpp"
#include <fstream>
#include <dirent.h> // For directory listing
#include <algorithm> // For std::find_if
#include <cstdlib>   // For system()

// Note: Listing installed apps on Linux is highly dependent on the package manager (apt, rpm, pacman, snap, flatpak).
// This is a simplified example for Debian/Ubuntu using `dpkg`.

class AppManager_Linux : public AppManager {
public:
    std::vector<AppInfo> listInstalledApps() override {
        std::vector<AppInfo> apps;
        // Example for Debian/Ubuntu systems
        FILE* pipe = popen("dpkg -l | grep '^ii' | awk '{print $2, $3}'", "r");
        if (!pipe) {
            LOG_ERROR("Failed to run dpkg command.");
            return apps;
        }
        char buffer[128];
        while (fgets(buffer, sizeof(buffer), pipe) != NULL) {
            std::string line = buffer;
            size_t space_pos = line.find(' ');
            if (space_pos != std::string::npos) {
                AppInfo app;
                app.name = line.substr(0, space_pos);
                app.version = line.substr(space_pos + 1);
                app.version.pop_back(); // Remove newline
                apps.push_back(app);
            }
        }
        pclose(pipe);
        LOG_INFO("Listed " + std::to_string(apps.size()) + " applications on Linux.");
        return apps;
    }

    bool launchApp(const std::string& appNameOrPath) override {
        // Attempt to launch via system() or fork/exec
        // For GUI apps, you might need `xdg-open` or specific desktop environment commands.
        std::string command = "nohup " + appNameOrPath + " &"; // 'nohup' and '&' to detach
        int result = system(command.c_str());
        if (result == 0) {
            LOG_INFO("Attempted to launch: " + appNameOrPath);
            return true;
        }
        LOG_ERROR("Failed to launch " + appNameOrPath + ". Error code: " + std::to_string(result));
        return false;
    }

    bool closeApp(const std::string& appNameOrPid) override {
        // Use `kill` command or iterate `/proc` for PID and send SIGTERM
        // Needs proper parsing of /proc/[pid]/status or /proc/[pid]/comm
        LOG_INFO("Attempting to close: " + appNameOrPid);
        return false; // Placeholder
    }

    ProcessStats getAppReadWriteStats(const std::string& appNameOrPid) override {
        ProcessStats stats = {0, appNameOrPid, 0, 0, 0.0, 0.0, "N/A"};
        // Read from /proc/[pid]/io for read_bytes/write_bytes
        // Read from /proc/[pid]/stat for CPU/Memory (complex parsing needed)
        LOG_INFO("Getting I/O stats for: " + appNameOrPid);
        return stats; // Placeholder
    }

    ProcessStats getAppHealth(const std::string& appNameOrPid) override {
        ProcessStats stats = {0, appNameOrPid, 0, 0, 0.0, 0.0, "N/A"};
        // Similar to getAppReadWriteStats, involves parsing /proc.
        LOG_INFO("Checking health for: " + appNameOrPid);
        return stats; // Placeholder
    }
};

// Factory method implementation (Linux specific part)
#include <iostream>
#include <string>

// In AppManager.cpp, you'd have the actual factory logic
// For this example, we'll put a simple placeholder here.
// In a real build system (CMake), you'd conditionally compile these.
#ifdef __linux__
AppManager* AppManager::create() {
    return new AppManager_Linux();
}
#endif



#pragma once
#include <string>
#include <vector>

struct AppHealth {
    bool isRunning;
    int pid;
    std::string name;
    double cpuUsagePercent;
    double memoryUsagePercent;
    std::string status; // e.g., "running", "sleeping", "zombie"
};

class ErrorScanner {
public:
    virtual ~ErrorScanner() = default;

    virtual std::vector<std::string> scanSystemLogs(const std::vector<std::string>& keywords) = 0;
    virtual AppHealth checkApplicationHealth(const std::string& appNameOrPid) = 0;

    static ErrorScanner* create();
};



#include "ErrorScanner.hpp"
#include "utils/Logger.hpp"

// Windows specific headers
#include <windows.h>
#include <winnt.h> // For Event Log types
#include <winevt.h> // For modern Event Log API (Evt* functions)

// Need to link against Wevtapi.lib

class ErrorScanner_Win : public ErrorScanner {
public:
    std::vector<std::string> scanSystemLogs(const std::vector<std::string>& keywords) override {
        std::vector<std::string> errors;
        // Using the modern Windows Event Log API (EvtQuery, EvtRender)
        // This is complex, but powerful.
        // Example query for errors/critical events in Application and System logs:
        // L"*[System[(Level=1 or Level=2) and (Provider/@Name='Application' or Provider/@Name='System')]]"
        // And then filter messages for keywords.
        LOG_INFO("Scanning Windows Event Logs for errors.");
        return errors; // Placeholder
    }

    AppHealth checkApplicationHealth(const std::string& appNameOrPid) override {
        AppHealth health = {false, 0, appNameOrPid, 0.0, 0.0, "N/A"};
        // Similar to AppManager_Win::getAppReadWriteStats, requires process enumeration.
        LOG_INFO("Checking Windows app health for: " + appNameOrPid);
        return health; // Placeholder
    }
};

// Factory method implementation (Windows specific part)
#ifdef _WIN32
ErrorScanner* ErrorScanner::create() {
    return new ErrorScanner_Win();
}
#endif



#pragma once
#include <string>
#include <vector>
#include <optional> // C++17

// Requires nlohmann/json and libcurl
// For OpenAI API calls

class Researcher {
public:
    Researcher(const std::optional<std::string>& openaiApiKey = std::nullopt);
    ~Researcher();

    std::vector<std::string> performWebSearch(const std::string& query);
    std::string summarizeText(const std::string& text);

private:
    std::optional<std::string> openaiApiKey_;
    void* curl_handle_; // Opaque pointer for CURL handle

    std::string makeOpenAIRequest(const std::string& endpoint, const std::string& json_payload);
    // Helper for curl write callback
    static size_t WriteCallback(void* contents, size_t size, size_t nmemb, void* userp);
};



#include "Researcher.hpp"
#include "utils/Logger.hpp"
#include "nlohmann/json.hpp" // For JSON parsing

// For libcurl - include appropriate headers and link library
#include <curl/curl.h>

// Static member for curl callback
size_t Researcher::WriteCallback(void* contents, size_t size, size_t nmemb, void* userp) {
    ((std::string*)userp)->append((char*)contents, size * nmemb);
    return size * nmemb;
}

Researcher::Researcher(const std::optional<std::string>& openaiApiKey)
    : openaiApiKey_(openaiApiKey), curl_handle_(nullptr) {
    if (openaiApiKey_.has_value()) {
        curl_global_init(CURL_GLOBAL_DEFAULT);
        curl_handle_ = curl_easy_init();
        if (!curl_handle_) {
            LOG_ERROR("Failed to initialize cURL for Researcher.");
            openaiApiKey_ = std::nullopt; // Disable OpenAI if curl fails
        }
        LOG_INFO("Researcher initialized. OpenAI enabled.");
    } else {
        LOG_WARN("OpenAI API key not provided. Research and summarization will be simulated.");
    }
}

Researcher::~Researcher() {
    if (curl_handle_) {
        curl_easy_cleanup(static_cast<CURL*>(curl_handle_));
        curl_global_cleanup();
    }
}

std::string Researcher::makeOpenAIRequest(const std::string& endpoint, const std::string& json_payload) {
    if (!openaiApiKey_.has_value() || !curl_handle_) {
        return "OpenAI not configured.";
    }

    CURL* curl = static_cast<CURL*>(curl_handle_);
    std::string readBuffer;

    struct curl_slist *headers = NULL;
    headers = curl_slist_append(headers, "Content-Type: application/json");
    headers = curl_slist_append(headers, ("Authorization: Bearer " + openaiApiKey_.value()).c_str());

    curl_easy_setopt(curl, CURLOPT_URL, ("https://api.openai.com/v1/" + endpoint).c_str());
    curl_easy_setopt(curl, CURLOPT_HTTPHEADER, headers);
    curl_easy_setopt(curl, CURLOPT_POSTFIELDS, json_payload.c_str());
    curl_easy_setopt(curl, CURLOPT_WRITEFUNCTION, WriteCallback);
    curl_easy_setopt(curl, CURLOPT_WRITEDATA, &readBuffer);

    CURLcode res = curl_easy_perform(curl);
    curl_slist_free_all(headers);

    if (res != CURLE_OK) {
        LOG_ERROR("cURL failed: " + std::string(curl_easy_strerror(res)));
        return "Error making OpenAI request.";
    }

    // Parse JSON response
    try {
        nlohmann::json jsonResponse = nlohmann::json::parse(readBuffer);
        if (jsonResponse.contains("choices") && !jsonResponse["choices"].empty()) {
            return jsonResponse["choices"][0]["message"]["content"].get<std::string>();
        }
    } catch (const nlohmann::json::exception& e) {
        LOG_ERROR("Failed to parse JSON response: " + std::string(e.what()));
    }
    return "No content in OpenAI response.";
}


std::vector<std::string> Researcher::performWebSearch(const std::string& query) {
    LOG_INFO("Performing simulated web search for: '" + query + "'");
    if (!openaiApiKey_.has_value()) {
        return {"Simulated search result 1 for '" + query + "'", "Simulated search result 2 for '" + query + "'"};
    }

    nlohmann::json payload;
    payload["model"] = "gpt-4o";
    payload["messages"] = {
        {{"role", "system"}, {"content", "You are a helpful assistant that provides concise search-like results."}},
        {{"role", "user"}, {"content", "Provide 2-3 concise search results or a brief summary for: " + query}}
    };
    payload["max_tokens"] = 300;
    payload["temperature"] = 0.7;

    std::string response = makeOpenAIRequest("chat/completions", payload.dump());
    if (response.find("Error") == 0 || response.find("No content") == 0) {
        return {response};
    }
    // Simple split by newline for demonstration
    std::vector<std::string> results;
    std::string line;
    std::istringstream iss(response);
    while (std::getline(iss, line)) {
        if (!line.empty()) {
            results.push_back(line);
        }
    }
    return results;
}

std::string Researcher::summarizeText(const std::string& text) {
    LOG_INFO("Attempting to summarize text (first 50 chars): '" + text.substr(0, 50) + "...'");
    if (!openaiApiKey_.has_value()) {
        return "Summary of: " + text.substr(0, 100) + "... (OpenAI not configured)";
    }

    nlohmann::json payload;
    payload["model"] = "gpt-4o";
    payload["messages"] = {
        {{"role", "system"}, {"content", "You are a helpful assistant that summarizes text concisely."}},
        {{"role", "user"}, {"content", "Summarize the following text:\n\n" + text}}
    };
    payload["max_tokens"] = 200;
    payload["temperature"] = 0.7;

    std::string response = makeOpenAIRequest("chat/completions", payload.dump());
    if (response.find("Error") == 0 || response.find("No content") == 0) {
        return response;
    }
    return response;
}



#pragma once
#include <string>
#include <vector>
#include <map>

// Struct to represent NLP processing result
struct NlpResult {
    std::string intent;
    double score;
    std::map<std::string, std::string> entities; // entity_name -> value
};

class NLPManager {
public:
    virtual ~NLPManager() = default;

    virtual bool initialize() = 0; // Load/train model
    virtual NlpResult process(const std::string& text) = 0;
};

// You'd have concrete implementations like NLPManager_InternalML.cpp
// or NLPManager_PythonBridge.cpp



#pragma once
#include "AppManager.hpp"
#include "ErrorScanner.hpp"
#include "Researcher.hpp"
#include "NLPManager.hpp"
#include "utils/Logger.hpp"

#include <memory> // For std::unique_ptr

class CoreAssistant {
public:
    CoreAssistant(const std::string& openaiApiKey);
    std::string executeCommand(const std::string& command);

private:
    std::unique_ptr<AppManager> appManager_;
    std::unique_ptr<ErrorScanner> errorScanner_;
    std::unique_ptr<Researcher> researcher_;
    std::unique_ptr<NLPManager> nlpManager_;

    // Helper to extract entities from NLP result
    std::string getEntityValue(const NlpResult& result, const std::string& entityName) const;
};



#include "CoreAssistant.hpp"
#include <iostream>
#include <sstream>

CoreAssistant::CoreAssistant(const std::string& openaiApiKey) {
    Logger::getInstance().setLogFile("assistant.log");
    LOG_INFO("CoreAssistant initializing...");

    appManager_ = std::unique_ptr<AppManager>(AppManager::create());
    errorScanner_ = std::unique_ptr<ErrorScanner>(ErrorScanner::create());
    researcher_ = std::make_unique<Researcher>(openaiApiKey);

    // Placeholder for NLPManager - in a real app, this would be complex
    // For a minimal example, you might even do rule-based NLP here instead of a full NLPManager
    // nlpManager_ = std::unique_ptr<NLPManager>(NLPManager::create());
    // nlpManager_->initialize(); // Initialize NLP model

    LOG_INFO("CoreAssistant initialized.");
}

std::string CoreAssistant::getEntityValue(const NlpResult& result, const std::string& entityName) const {
    auto it = result.entities.find(entityName);
    if (it != result.entities.end()) {
        return it->second;
    }
    return "";
}

std::string CoreAssistant::executeCommand(const std::string& command) {
    LOG_INFO("Executing command: " + command);

    // --- Placeholder/Rule-based NLP for demonstration ---
    // In a real C++ NLP solution, you'd integrate a proper NLP library here.
    // This is a very basic keyword matching for demonstration purposes.
    std::string lowerCommand = command;
    std::transform(lowerCommand.begin(), lowerCommand.end(), lowerCommand.begin(), ::tolower);

    if (lowerCommand == "list installed apps" || lowerCommand == "show me my applications") {
        std::stringstream ss;
        ss << "Listing installed applications...\n";
        std::vector<AppInfo> apps = appManager_->listInstalledApps();
        if (apps.empty()) {
            ss << "No apps found or error occurred.";
        } else {
            for (const auto& app : apps) {
                ss << "  - " << app.name;
                if (!app.version.empty()) ss << " (v" << app.version << ")";
                if (!app.publisher.empty()) ss << " by " << app.publisher;
                ss << "\n";
            }
        }
        return ss.str();
    }
    else if (lowerCommand.rfind("launch app ", 0) == 0) {
        std::string appName = command.substr(11); // "launch app " is 11 chars
        if (appManager_->launchApp(appName)) {
            return "Attempting to launch " + appName + ".";
        } else {
            return "Failed to launch " + appName + ".";
        }
    }
    else if (lowerCommand.rfind("close app ", 0) == 0) {
        std::string appNameOrPid = command.substr(10);
        if (appManager_->closeApp(appNameOrPid)) {
            return "Attempting to close " + appNameOrPid + ".";
        } else {
            return "Failed to close " + appNameOrPid + ".";
        }
    }
    else if (lowerCommand.rfind("get app stats for ", 0) == 0) {
        std::string appNameOrPid = command.substr(18);
        ProcessStats stats = appManager_->getAppReadWriteStats(appNameOrPid);
        if (stats.pid != 0) { // Assuming PID 0 means not found
            std::stringstream ss;
            ss << "I/O Stats for " << stats.name << " (PID: " << stats.pid << "):\n"
               << "  Read Bytes: " << stats.readBytes << " (" << (double)stats.readBytes / (1024*1024) << " MB)\n"
               << "  Write Bytes: " << stats.writeBytes << " (" << (double)stats.writeBytes / (1024*1024) << " MB)";
            return ss.str();
        } else {
            return "Could not get stats for " + appNameOrPid + ". App not found or not running.";
        }
    }
    else if (lowerCommand == "scan system errors") {
        std::stringstream ss;
        ss << "Scanning system logs for errors...\n";
        std::vector<std::string> errors = errorScanner_->scanSystemLogs({"error", "fail", "critical"});
        if (errors.empty()) {
            ss << "No significant errors found in system logs.";
        } else {
            ss << "Found potential errors:\n";
            for (const auto& error : errors) {
                ss << "- " << error << "\n";
            }
        }
        return ss.str();
    }
    else if (lowerCommand.rfind("research ", 0) == 0) {
        std::string query = command.substr(9);
        std::stringstream ss;
        ss << "Performing web research for: '" << query << "'\n";
        std::vector<std::string> results = researcher_->performWebSearch(query);
        for (const auto& result : results) {
            ss << "- " << result << "\n";
        }
        return ss.str();
    }
    else if (lowerCommand.rfind("summarize ", 0) == 0) {
        std::string text = command.substr(10);
        std::stringstream ss;
        ss << "Summarizing text...\n";
        std::string summary = researcher_->summarizeText(text);
        ss << summary;
        return ss.str();
    }
    else if (lowerCommand.rfind("check health of ", 0) == 0) {
        std::string appNameOrPid = command.substr(16);
        AppHealth health = errorScanner_->checkApplicationHealth(appNameOrPid);
        if (health.isRunning) {
            std::stringstream ss;
            ss << health.name << " (PID: " << health.pid << ") is running.\n"
               << "  CPU Usage: " << health.cpuUsagePercent << "%\n"
               << "  Memory Usage: " << health.memoryUsagePercent << "%\n"
               << "  Status: " << health.status;
            return ss.str();
        } else {
            return appNameOrPid + " is not running or not found.";
        }
    }
    else {
        return "I don't understand that command. Try: 'list installed apps', 'launch app <name>', 'scan system errors', 'research <query>', 'summarize <text>', 'check health of <name>'.";
    }

    // In a real NLP scenario, you'd get NlpResult from nlpManager_
    // NlpResult nlpResult = nlpManager_->process(command);
    // double confidence = nlpResult.score;
    // std::string intent = nlpResult.intent;
    // ... then use switch-case based on 'intent'
}



#include "CoreAssistant.hpp"
#include "utils/Logger.hpp" // For Logger setup
#include <iostream>
#include <string>

int main() {
    // Set your OpenAI API key here, or retrieve from environment variable
    // For C++, it's common to use environment variables or a config file
    // For example:
    const char* openai_api_key_env = std::getenv("OPENAI_API_KEY");
    std::string openaiApiKey = openai_api_key_env ? openai_api_key_env : "";

    CoreAssistant assistant(openaiApiKey);

    std::cout << "Advanced AI Assistant started. Type 'exit' to quit." << std::endl;

    std::string userInput;
    while (true) {
        std::cout << "\nYou: ";
        std::getline(std::cin, userInput);

        if (userInput == "exit" || userInput == "quit") {
            std::cout << "Assistant: Exiting. Goodbye!" << std::endl;
            break;
        }

        std::string response = assistant.executeCommand(userInput);
        std::cout << "Assistant: " << response << std::endl;
    }

    return 0;
}



cmake_minimum_required(VERSION 3.10)
project(AIAssistant CXX)

set(CMAKE_CXX_STANDARD 17)
set(CMAKE_CXX_STANDARD_REQUIRED True)

# Detect OS to include platform-specific files
if(WIN32)
    add_definitions(-D_WIN32)
    set(PLATFORM_SPECIFIC_SRCS
        src/AppManager_Win.cpp
        src/ErrorScanner_Win.cpp
    )
    # Link Windows specific libraries
    target_link_libraries(${PROJECT_NAME} PRIVATE Advapi32.lib Psapi.lib Wevtapi.lib Shell32.lib)
elseif(UNIX) # Covers Linux and macOS
    if(APPLE)
        add_definitions(-D__APPLE__)
        set(PLATFORM_SPECIFIC_SRCS
            src/AppManager_Mac.cpp
            src/ErrorScanner_Mac.cpp
        )
        # Link macOS specific frameworks/libraries
        # target_link_libraries(${PROJECT_NAME} PRIVATE -framework Foundation -framework AppKit -lobjc)
    else() # Linux
        add_definitions(-D__linux__)
        set(PLATFORM_SPECIFIC_SRCS
            src/AppManager_Linux.cpp
            src/ErrorScanner_Linux.cpp
        )
        # Link Linux specific libraries (e.g., for system stats, if needed)
    endif()
endif()

# Source files
set(SOURCES
    src/main.cpp
    src/CoreAssistant.cpp
    src/AppManager.cpp # Base AppManager implementation (might be empty or contain factory)
    src/ErrorScanner.cpp # Base ErrorScanner implementation (might be empty or contain factory)
    src/Researcher.cpp
    src/utils/Logger.cpp
    ${PLATFORM_SPECIFIC_SRCS}
)

add_executable(${PROJECT_NAME} ${SOURCES})

# --- External Library Integration (Conceptual) ---

# Find and link libcurl
# Find_Package(CURL REQUIRED)
# target_link_libraries(${PROJECT_NAME} PRIVATE ${CURL_LIBRARIES})
# include_directories(${CURL_INCLUDE_DIRS})

# Include nlohmann/json (assuming it's header-only and in a known path or external/)
# target_include_directories(${PROJECT_NAME} PUBLIC ${CMAKE_SOURCE_DIR}/external/json)

# If using ONNX Runtime or TensorFlow Lite C++ API, you'd add similar find_package/target_link_libraries calls.



mkdir build
cd build
cmake ..
make
./AIAssistant # To run



import Foundation
import SwiftUI
import AppKit // For NSWorkspace, NSRunningApplication
import os.log   // For Unified Logging System
import Combine  // For asynchronous operations

// MARK: - Data Models

struct AppInfo: Identifiable, Hashable {
    let id = UUID()
    let name: String
    var version: String?
    var path: String? // Path to .app bundle
    var bundleIdentifier: String? // Uniquely identifies an app
    var isRunning: Bool = false
    var pid: Int32? // Process ID if running
}

struct ProcessStats {
    let pid: Int32
    let name: String
    var cpuPercent: Double = 0.0
    var memoryPercent: Double = 0.0 // in MB
    var readBytes: UInt64 = 0 // Aggregated I/O for the process
    var writeBytes: UInt64 = 0 // Aggregated I/O for the process
    var status: String = "Unknown"
}

struct AssistantMessage: Identifiable {
    let id = UUID()
    let text: String
    let sender: Sender
    let timestamp: Date = Date()

    enum Sender {
        case user
        case assistant
    }
}

// MARK: - Protocols for Modularity

protocol AppManaging {
    func listInstalledApps() async -> [AppInfo]
    func launchApp(atPath path: String) async -> Bool
    func launchApp(withBundleIdentifier bundleIdentifier: String) async -> Bool
    func closeApp(withBundleIdentifier bundleIdentifier: String) async -> Bool
    func closeApp(withPID pid: Int32) async -> Bool
    func getProcessStats(for appNameOrPid: String) async -> ProcessStats?
}

protocol ErrorScanning {
    func scanSystemLogs(keywords: [String]) async -> [String]
    func checkAppHealth(appNameOrPid: String) async -> ProcessStats?
}

protocol Researching {
    func performWebSearch(query: String) async -> [String]
    func summarizeText(_ text: String) async -> String
}

protocol NLPProcessing {
    // This would ideally use Core ML or an external API for proper intent recognition
    func processCommand(_ command: String) async -> (intent: String, entities: [String: String])
}

// MARK: - Assistant Core Implementation

class AssistantCore: ObservableObject {
    @Published var messages: [AssistantMessage] = []
    @Published var isProcessing: Bool = false

    private let appManager: AppManaging
    private let errorScanner: ErrorScanning
    private let researcher: Researching
    private let nlpProcessor: NLPProcessing // Placeholder for NLP

    // Use an environment variable for the API key for security
    private let openAIAPIKey: String? = {
        guard let path = Bundle.main.path(forResource: "Secrets", ofType: "plist"),
              let dict = NSDictionary(contentsOfFile: path) as? [String: Any],
              let key = dict["OPENAI_API_KEY"] as? String else {
            os_log("OPENAI_API_KEY not found in Secrets.plist. Research functionality will be limited.", type: .error)
            return nil
        }
        return key
    }()

    init() {
        // Initialize concrete implementations
        self.appManager = AppManagerImpl()
        self.errorScanner = ErrorScannerImpl()
        self.researcher = ResearcherImpl(openAIAPIKey: self.openAIAPIKey)
        self.nlpProcessor = NLPProcessorImpl() // Simplified NLP for now

        addAssistantMessage("Hello! How can I help you today? Try 'list apps' or 'scan errors'.")
    }

    func addMessage(_ message: AssistantMessage) {
        DispatchQueue.main.async {
            self.messages.append(message)
        }
    }

    func addAssistantMessage(_ text: String) {
        addMessage(AssistantMessage(text: text, sender: .assistant))
    }

    @MainActor
    func sendCommand(_ command: String) async {
        guard !isProcessing else { return }

        addMessage(AssistantMessage(text: command, sender: .user))
        isProcessing = true
        addAssistantMessage("Thinking...") // Indicate processing

        do {
            let (intent, entities) = await nlpProcessor.processCommand(command)
            var assistantResponse = ""

            os_log("Processed command. Intent: %s, Entities: %{public}@", type: .info, intent, entities as NSDictionary)

            switch intent {
            case "app.list":
                let apps = await appManager.listInstalledApps()
                if apps.isEmpty {
                    assistantResponse = "No installed applications found."
                } else {
                    let topApps = apps.prefix(20).map { $0.name + ($0.version.map { " (v\($0))" } ?? "") }.joined(separator: "\n- ")
                    assistantResponse = "Installed applications (top 20):\n- " + topApps + (apps.count > 20 ? "\n..." : "")
                }

            case "app.launch":
                if let appName = entities["appName"] {
                    // Try by bundle identifier first, then by path if common app
                    let success = await appManager.launchApp(withBundleIdentifier: appName) || await appManager.launchApp(atPath: appName)
                    assistantResponse = success ? "Attempted to launch \(appName)." : "Failed to launch \(appName). Please ensure the app name or path is correct."
                } else {
                    assistantResponse = "Please specify an application to launch (e.g., 'launch app Safari')."
                }

            case "app.close":
                if let appNameOrPid = entities["appNameOrPid"] {
                    var success = false
                    if let pid = Int32(appNameOrPid) {
                        success = await appManager.closeApp(withPID: pid)
                    } else {
                        success = await appManager.closeApp(withBundleIdentifier: appNameOrPid)
                    }
                    assistantResponse = success ? "Attempted to close \(appNameOrPid)." : "Failed to close \(appNameOrPid). App not found or permission denied."
                } else {
                    assistantResponse = "Please specify an application name or PID to close (e.g., 'close app Chrome' or 'close app 1234')."
                }
            
            case "app.stats":
                if let appNameOrPid = entities["appNameOrPid"] {
                    if let stats = await appManager.getProcessStats(for: appNameOrPid) {
                        assistantResponse = """
                        I/O Stats for \(stats.name) (PID: \(stats.pid)):
                          CPU Usage: \(String(format: "%.2f", stats.cpuPercent))%
                          Memory Usage: \(String(format: "%.2f", stats.memoryPercent)) MB
                          Read Bytes: \(stats.readBytes) (\(ByteCountFormatter.string(fromByteCount: Int64(stats.readBytes), countStyle: .file)))
                          Write Bytes: \(stats.writeBytes) (\(ByteCountFormatter.string(fromByteCount: Int64(stats.writeBytes), countStyle: .file)))
                        """
                    } else {
                        assistantResponse = "Could not get stats for \(appNameOrPid). App not found or not running."
                    }
                } else {
                    assistantResponse = "Please specify an application name or PID for stats (e.g., 'app stats Safari')."
                }

            case "system.scan_errors":
                let errors = await errorScanner.scanSystemLogs(keywords: ["error", "fail", "critical"])
                if errors.isEmpty {
                    assistantResponse = "No significant errors found in system logs."
                } else {
                    assistantResponse = "Found potential errors in system logs (top 10):\n" + errors.joined(separator: "\n")
                }

            case "app.health":
                if let appNameOrPid = entities["appNameOrPid"] {
                    if let health = await errorScanner.checkAppHealth(appNameOrPid) {
                        assistantResponse = """
                        \(health.name) (PID: \(health.pid)) is running.
                          CPU Usage: \(String(format: "%.2f", health.cpuPercent))%
                          Memory Usage: \(String(format: "%.2f", health.memoryPercent)) MB
                          Status: \(health.status)
                        """
                    } else {
                        assistantResponse = "\(appNameOrPid) is not running or not found."
                    }
                } else {
                    assistantResponse = "Please specify an application name or PID to check health (e.g., 'check health Safari')."
                }

            case "research.web":
                if let query = entities["query"] {
                    let results = await researcher.performWebSearch(query)
                    assistantResponse = "Research results:\n" + results.joined(separator: "\n")
                } else {
                    assistantResponse = "Please provide a research query (e.g., 'research Swift concurrency')."
                }

            case "research.summarize":
                if let text = entities["text"] {
                    let summary = await researcher.summarizeText(text)
                    assistantResponse = "Summary: " + summary
                } else {
                    assistantResponse = "Please provide text to summarize (e.g., 'summarize The quick brown fox...')."
                }

            default:
                assistantResponse = "I'm not sure how to handle that command. Try 'list apps', 'launch app <name>', 'scan errors', 'research <query>', or 'summarize <text>'."
            }

            addAssistantMessage(assistantResponse)

        } catch {
            os_log("Error processing command: %{public}@", type: .error, error.localizedDescription)
            addAssistantMessage("An error occurred while processing your request: \(error.localizedDescription)")
        }

        isProcessing = false
    }
}



import Foundation
import AppKit // For NSWorkspace, NSRunningApplication
import os.log // For logging

class AppManagerImpl: AppManaging {

    func listInstalledApps() async -> [AppInfo] {
        os_log("Listing installed applications...", type: .info)
        var apps: [AppInfo] = []

        let fileManager = FileManager.default

        // Common application directories
        let appDirs = [
            "/Applications",
            "~/Applications", // User's Applications folder
            "/System/Applications",
            "/Library/Application Support" // Some apps install here, but usually helpers
        ].map { ($0 as NSString).expandingTildeInPath }

        for dirPath in appDirs {
            do {
                let contents = try fileManager.contentsOfDirectory(atPath: dirPath)
                for item in contents {
                    if item.hasSuffix(".app") {
                        let appPath = (dirPath as NSString).appendingPathComponent(item)
                        if let bundle = Bundle(path: appPath) {
                            let appName = bundle.object(forInfoDictionaryKey: "CFBundleDisplayName") as? String ??
                                          bundle.object(forInfoDictionaryKey: "CFBundleName") as? String ??
                                          (item as NSString).deletingPathExtension

                            let appVersion = bundle.object(forInfoDictionaryKey: "CFBundleShortVersionString") as? String
                            let bundleIdentifier = bundle.bundleIdentifier

                            let runningApp = NSRunningApplication.runningApplications(withBundleIdentifier: bundleIdentifier ?? "").first
                            
                            apps.append(AppInfo(
                                name: appName,
                                version: appVersion,
                                path: appPath,
                                bundleIdentifier: bundleIdentifier,
                                isRunning: runningApp != nil,
                                pid: runningApp?.processIdentifier
                            ))
                        }
                    }
                }
            } catch {
                os_log("Error listing contents of directory %{public}@: %{public}@", type: .error, dirPath, error.localizedDescription)
            }
        }
        os_log("Found %d applications.", type: .info, apps.count)
        return apps.sorted { $0.name.localizedCaseInsensitiveCompare($1.name) == .orderedAscending }
    }

    func launchApp(atPath path: String) async -> Bool {
        os_log("Attempting to launch app at path: %{public}@", type: .info, path)
        return await withCheckedContinuation { continuation in
            NSWorkspace.shared.openApplication(at: URL(fileURLWithPath: path),
                                               configuration: .init()) { (app, error) in
                if let error = error {
                    os_log("Failed to launch app %{public}@ at path %{public}@: %{public}@", type: .error, path, error.localizedDescription)
                    continuation.resume(returning: false)
                } else {
                    os_log("Successfully launched app at path: %{public}@", type: .info, path)
                    continuation.resume(returning: true)
                }
            }
        }
    }

    func launchApp(withBundleIdentifier bundleIdentifier: String) async -> Bool {
        os_log("Attempting to launch app with bundle ID: %{public}@", type: .info, bundleIdentifier)
        return NSWorkspace.shared.launchApplication(withBundleIdentifier: bundleIdentifier, options: .default, additionalEventParamDescriptor: nil, launchIdentifier: nil)
    }

    func closeApp(withBundleIdentifier bundleIdentifier: String) async -> Bool {
        os_log("Attempting to close app with bundle ID: %{public}@", type: .info, bundleIdentifier)
        guard let app = NSRunningApplication.runningApplications(withBundleIdentifier: bundleIdentifier).first else {
            os_log("App with bundle ID %{public}@ not found.", type: .info, bundleIdentifier)
            return false
        }
        // Force quit if terminate fails. Be cautious with force terminating.
        let success = app.terminate() || app.forceTerminate()
        os_log("App %{public}@ terminated: %s", type: .info, bundleIdentifier, success ? "true" : "false")
        return success
    }

    func closeApp(withPID pid: Int32) async -> Bool {
        os_log("Attempting to close app with PID: %d", type: .info, pid)
        guard let app = NSRunningApplication.runningApplications(withProcessIdentifier: pid) else {
            os_log("App with PID %d not found.", type: .info, pid)
            return false
        }
        let success = app.terminate() || app.forceTerminate()
        os_log("App with PID %d terminated: %s", type: .info, pid, success ? "true" : "false")
        return success
    }

    func getProcessStats(for appNameOrPid: String) async -> ProcessStats? {
        os_log("Getting process stats for: %{public}@", type: .info, appNameOrPid)
        var targetProcess: NSRunningApplication?
        
        if let pid = Int32(appNameOrPid) {
            targetProcess = NSRunningApplication.runningApplications(withProcessIdentifier: pid)
        } else {
            // Find by name (case-insensitive contains)
            targetProcess = NSRunningApplication.allApplications.first { app in
                app.localizedName?.lowercased().contains(appNameOrPid.lowercased()) ?? false
            }
        }

        guard let app = targetProcess, let pid = app.processIdentifier else {
            os_log("Process %{public}@ not found.", type: .info, appNameOrPid)
            return nil
        }
        
        var stats = ProcessStats(pid: pid, name: app.localizedName ?? "Unknown")

        // MARK: - CPU and Memory Usage (Requires elevated permissions for some processes)
        // This is where it gets tricky without root/Accessibility access.
        // For owned processes or processes the user has given permissions for,
        // you might use `mach_task_self()` and `task_info()` or `getrusage()`.
        // For general processes, getting reliable per-process CPU/Memory is hard.
        // psutil (Python) usually parses `/proc` on Linux or uses complex APIs on Windows/macOS.
        
        // For demonstration, we'll use a very simplified approach or note the limitation.
        // To get process CPU/memory reliably, you often need to iterate through all processes
        // using `sysctl` with `KERN_PROC_ALL` and then get `task_info`.
        // This typically requires special entitlements or running as root.

        // A very basic CPU percent (will be inaccurate without repeated sampling)
        // You'd need to compare previous times for accurate CPU %
        if let process = Process(processIdentifier: pid) {
            // Memory Usage (Resident Set Size)
            let memoryInfo = process.initiateMemoryReading()
            stats.memoryPercent = Double(memoryInfo.residentMemorySize ?? 0) / (1024.0 * 1024.0) // Convert to MB

            // Basic CPU usage (This is a simplified approach, real CPU usage requires time-series data)
            // You would need to store previous CPU times and calculate delta.
            // For general process monitoring, `sysctlbyname("kern.proc.all")` + `proc_pidinfo` is more common.
            // Or use a third-party library that handles this.
            stats.cpuPercent = 0.0 // Placeholder
        }


        // MARK: - Read/Write Bytes (Aggregated per process)
        // This also requires specific functions. On macOS, you might use:
        // `proc_pidinfo(pid, PROC_PIDTHREADINFO, 0, &pinfo, sizeof(pinfo))`
        // and look at `pinfo.pti_pagein` and `pinfo.pti_pageout`, or other I/O related fields.
        // These are aggregates, not file-level.
        
        // Example (conceptual, requires including <libproc.h> and linking libproc.tbd)
        // #import <libproc.h>
        // struct proc_taskinfo pinfo;
        // if (proc_pidinfo(pid, PROC_PIDTHREADINFO, 0, &pinfo, sizeof(pinfo)) == sizeof(pinfo)) {
        //     stats.readBytes = pinfo.pti_total_user_read_bytes;
        //     stats.writeBytes = pinfo.pti_total_user_write_bytes;
        // }
        stats.readBytes = 0 // Placeholder
        stats.writeBytes = 0 // Placeholder
        stats.status = app.isTerminated ? "Terminated" : (app.isHidden ? "Hidden" : (app.isActive ? "Active" : "Background"))
        
        os_log("Retrieved stats for %{public}@: CPU: %.2f%%, Memory: %.2fMB, Read: %llu, Write: %llu", type: .info, stats.name, stats.cpuPercent, stats.memoryPercent, stats.readBytes, stats.writeBytes)

        return stats
    }
}

// Helper extension to get basic process info
extension Process {
    struct MemoryInfo {
        var residentMemorySize: UInt64?
        // Add more memory stats here if needed
    }

    func initiateMemoryReading() -> MemoryInfo {
        var info = MemoryInfo()
        if let task = taskForPid(self.processIdentifier) {
            var rinfo = task_basic_info_data_t()
            var count = mach_msg_type_number_t(MemoryLayout<task_basic_info_data_t>.size) / 4
            let status = task_info(task, task_flavor_t(TASK_BASIC_INFO), &rinfo.m_basic_info, &count)

            if status == KERN_SUCCESS {
                info.residentMemorySize = UInt64(rinfo.resident_size)
            }
            mach_port_deallocate(mach_task_self_, task)
        }
        return info
    }

    // Helper to get mach_port_t for a PID (requires entitlements for other processes)
    private func taskForPid(_ pid: Int32) -> mach_port_t? {
        var task = mach_port_t()
        let kr = task_for_pid(mach_task_self_, pid, &task)
        if kr != KERN_SUCCESS {
            os_log("task_for_pid failed for PID %d: %d", type: .error, pid, kr)
            return nil
        }
        return task
    }
}



import Foundation
import os.log
import OSLog // Unified Logging System

class ErrorScannerImpl: ErrorScanning {
    func scanSystemLogs(keywords: [String]) async -> [String] {
        os_log("Scanning system logs for keywords: %{public}@", type: .info, keywords.joined(separator: ", "))
        var errors: [String] = []

        // Create a custom log store for system logs
        guard let logStore = try? OSLogStore(scope: .system) else {
            os_log("Failed to create OSLogStore for system logs.", type: .error)
            return ["Could not access system logs. Permission denied or API unavailable."]
        }

        // Fetch entries from the last 24 hours (example)
        let twentyFourHoursAgo = logStore.position(date: Date().addingTimeInterval(-24 * 3600))

        do {
            let entries = try logStore.get-->D_LOG_TYPE_INFO
            _ = logStore.getEntries(with: [.logs], at: twentyFourHoursAgo, matching: nil).compactMap { $0 as? OSLogEntryLog }
            
            // Filter entries by level and keywords
            for entry in entries.prefix(1000) { // Limit number of entries to process
                guard entry.level == .error || entry.level == .fault else { continue }

                let message = entry.composedMessage
                if keywords.contains(where: { message.localizedCaseInsensitiveContains($0) }) {
                    errors.append("\(entry.date.formatted()) [\(entry.category ?? "")] \(message)")
                    if errors.count >= 10 { break } // Limit to top 10 errors
                }
            }
        } catch {
            os_log("Error reading system logs: %{public}@", type: .error, error.localizedDescription)
            return ["Error reading system logs: \(error.localizedDescription)"]
        }

        os_log("Found %d potential errors in system logs.", type: .info, errors.count)
        return errors
    }

    func checkAppHealth(appNameOrPid: String) async -> ProcessStats? {
        os_log("Checking app health for: %{public}@", type: .info, appNameOrPid)
        // This reuses the getProcessStats logic from AppManager
        let appManager = AppManagerImpl() // Could pass AppManagerImpl instance from AssistantCore
        return await appManager.getProcessStats(for: appNameOrPid)
    }
}



import Foundation
import os.log

class ResearcherImpl: Researching {
    private let openAIAPIKey: String?

    init(openAIAPIKey: String?) {
        self.openAIAPIKey = openAIAPIKey
        if openAIAPIKey == nil {
            os_log("OpenAI API key not provided. Research and summarization will be simulated.", type: .warning)
        }
    }

    private func makeOpenAIRequest(endpoint: String, payload: [String: Any]) async throws -> String {
        guard let apiKey = openAIAPIKey, !apiKey.isEmpty else {
            throw NSError(domain: "ResearcherError", code: 1, userInfo: [NSLocalizedDescriptionKey: "OpenAI API key not configured."])
        }

        guard let url = URL(string: "https://api.openai.com/v1/\(endpoint)") else {
            throw NSError(domain: "ResearcherError", code: 2, userInfo: [NSLocalizedDescriptionKey: "Invalid OpenAI URL."])
        }

        var request = URLRequest(url: url)
        request.httpMethod = "POST"
        request.addValue("application/json", forHTTPHeaderField: "Content-Type")
        request.addValue("Bearer \(apiKey)", forHTTPHeaderField: "Authorization")

        request.httpBody = try JSONSerialization.data(withJSONObject: payload, options: [])

        let (data, response) = try await URLSession.shared.data(for: request)

        guard let httpResponse = response as? HTTPURLResponse, (200...299).contains(httpResponse.statusCode) else {
            let errorDetails = String(data: data, encoding: .utf8) ?? "No error details"
            throw NSError(domain: "ResearcherError", code: (response as? HTTPURLResponse)?.statusCode ?? -1, userInfo: [NSLocalizedDescriptionKey: "HTTP Error: \(httpResponse.statusCode). Details: \(errorDetails)"])
        }

        guard let json = try JSONSerialization.jsonObject(with: data) as? [String: Any],
              let choices = json["choices"] as? [[String: Any]],
              let firstChoice = choices.first,
              let message = firstChoice["message"] as? [String: Any],
              let content = message["content"] as? String else {
            throw NSError(domain: "ResearcherError", code: 3, userInfo: [NSLocalizedDescriptionKey: "Invalid JSON response from OpenAI."])
        }
        return content
    }

    func performWebSearch(query: String) async -> [String] {
        os_log("Performing simulated web search for: %{public}@", type: .info, query)
        if openAIAPIKey == nil {
            return ["Simulated search result 1 for '\(query)' (OpenAI not configured)",
                    "Simulated search result 2 for '\(query)' (OpenAI not configured)"]
        }

        let payload: [String: Any] = [
            "model": "gpt-4o", // Or another suitable model
            "messages": [
                ["role": "system", "content": "You are a helpful assistant that provides concise search-like results."],
                ["role": "user", "content": "Provide 2-3 concise search results or a brief summary for: \(query)"]
            ],
            "max_tokens": 300,
            "temperature": 0.7
        ]

        do {
            let result = try await makeOpenAIRequest(endpoint: "chat/completions", payload: payload)
            return result.split(separator: "\n").map(String.init) // Split by newline for simple results
        } catch {
            os_log("Error during OpenAI web search simulation for '%{public}@': %{public}@", type: .error, query, error.localizedDescription)
            return ["Error retrieving AI-generated search results: \(error.localizedDescription)"]
        }
    }

    func summarizeText(_ text: String) async -> String {
        os_log("Attempting to summarize text (first 50 chars): %{public}@", type: .info, text.prefix(50).description)
        if openAIAPIKey == nil {
            return "Summary of: \(text.prefix(100))... (OpenAI not configured)"
        }

        let payload: [String: Any] = [
            "model": "gpt-4o",
            "messages": [
                ["role": "system", "content": "You are a helpful assistant that summarizes text concisely."],
                ["role": "user", "content": "Summarize the following text:\n\n\(text)"]
            ],
            "max_tokens": 200,
            "temperature": 0.7
        ]

        do {
            return try await makeOpenAIRequest(endpoint: "chat/completions", payload: payload)
        } catch {
            os_log("Error during text summarization: %{public}@", type: .error, error.localizedDescription)
            return "Failed to summarize text: \(error.localizedDescription)"
        }
    }
}



import Foundation
import os.log

class NLPProcessorImpl: NLPProcessing {
    func processCommand(_ command: String) async -> (intent: String, entities: [String: String]) {
        os_log("Processing command with simplified NLP: %{public}@", type: .info, command)
        let lowercasedCommand = command.lowercased()
        var entities: [String: String] = [:]
        var intent: String = "unknown"

        if lowercasedCommand.contains("list apps") || lowercasedCommand.contains("show me my applications") {
            intent = "app.list"
        } else if lowercasedCommand.contains("launch app") || lowercasedCommand.contains("open ") {
            intent = "app.launch"
            // Extract app name after "launch app " or "open "
            if let range = lowercasedCommand.range(of: "launch app ") {
                entities["appName"] = String(command[range.upperBound...]).trimmingCharacters(in: .whitespacesAndNewlines)
            } else if let range = lowercasedCommand.range(of: "open ") {
                entities["appName"] = String(command[range.upperBound...]).trimmingCharacters(in: .whitespacesAndNewlines)
            }
        } else if lowercasedCommand.contains("close app") || lowercasedCommand.contains("terminate ") {
            intent = "app.close"
            if let range = lowercasedCommand.range(of: "close app ") {
                entities["appNameOrPid"] = String(command[range.upperBound...]).trimmingCharacters(in: .whitespacesAndNewlines)
            } else if let range = lowercasedCommand.range(of: "terminate ") {
                entities["appNameOrPid"] = String(command[range.upperBound...]).trimmingCharacters(in: .whitespacesAndNewlines)
            }
        } else if lowercasedCommand.contains("get app stats for") || lowercasedCommand.contains("show io for") {
            intent = "app.stats"
            if let range = lowercasedCommand.range(of: "get app stats for ") {
                entities["appNameOrPid"] = String(command[range.upperBound...]).trimmingCharacters(in: .whitespacesAndNewlines)
            } else if let range = lowercasedCommand.range(of: "show io for ") {
                 entities["appNameOrPid"] = String(command[range.upperBound...]).trimmingCharacters(in: .whitespacesAndNewlines)
            }
        } else if lowercasedCommand.contains("scan system errors") || lowercasedCommand.contains("check logs for errors") {
            intent = "system.scan_errors"
        } else if lowercasedCommand.contains("check health of") || lowercasedCommand.contains("is running") {
            intent = "app.health"
            if let range = lowercasedCommand.range(of: "check health of ") {
                entities["appNameOrPid"] = String(command[range.upperBound...]).trimmingCharacters(in: .whitespacesAndNewlines)
            } else if let range = lowercasedCommand.range(of: "is running ") {
                 entities["appNameOrPid"] = String(command[range.upperBound...]).trimmingCharacters(in: .whitespacesAndNewlines)
            }
        } else if lowercasedCommand.contains("research ") || lowercasedCommand.contains("find information on ") {
            intent = "research.web"
            if let range = lowercasedCommand.range(of: "research ") {
                entities["query"] = String(command[range.upperBound...]).trimmingCharacters(in: .whitespacesAndNewlines)
            } else if let range = lowercasedCommand.range(of: "find information on ") {
                entities["query"] = String(command[range.upperBound...]).trimmingCharacters(in: .whitespacesAndNewlines)
            }
        } else if lowercasedCommand.contains("summarize ") {
            intent = "research.summarize"
            if let range = lowercasedCommand.range(of: "summarize ") {
                entities["text"] = String(command[range.upperBound...]).trimmingCharacters(in: .whitespacesAndNewlines)
            }
        }
        
        os_log("Simplified NLP Result: Intent: %{public}s, Entities: %{public}@", type: .info, intent, entities as NSDictionary)
        return (intent, entities)
    }
}



import SwiftUI

@main
struct AIAssistantApp: App {
    @StateObject private var assistantCore = AssistantCore()

    var body: some Scene {
        WindowGroup {
            ContentView()
                .environmentObject(assistantCore)
        }
    }
}



import SwiftUI

struct ContentView: View {
    @EnvironmentObject var assistantCore: AssistantCore
    @State private var inputText: String = ""
    @FocusState private var isInputFocused: Bool

    var body: some View {
        VStack(spacing: 0) {
            // Header
            Text("Advanced AI Assistant")
                .font(.largeTitle)
                .fontWeight(.bold)
                .padding()
                .frame(maxWidth: .infinity)
                .background(Color.accentColor.opacity(0.1))
                .cornerRadius(10, corners: [.topLeft, .topRight]) // Rounded corners for the header

            // Chat Window
            ScrollViewReader { proxy in
                ScrollView {
                    VStack(alignment: .leading, spacing: 10) {
                        ForEach(assistantCore.messages) { message in
                            MessageView(message: message)
                                .id(message.id)
                        }
                    }
                    .padding()
                }
                .onChange(of: assistantCore.messages.count) { _ in
                    // Scroll to bottom when new messages arrive
                    if let lastMessage = assistantCore.messages.last {
                        proxy.scrollTo(lastMessage.id, anchor: .bottom)
                    }
                }
            }
            .background(Color.gray.opacity(0.1))
            .cornerRadius(10, corners: [.bottomLeft, .bottomRight]) // Rounded corners for the chat area
            .padding([.horizontal, .bottom])

            // Input Area
            HStack {
                TextField("Type your command here...", text: $inputText)
                    .textFieldStyle(.roundedBorder)
                    .padding(.vertical, 8)
                    .focused($isInputFocused)
                    .onSubmit {
                        Task { await sendMessage() }
                    }
                    .disabled(assistantCore.isProcessing)

                Button {
                    Task { await sendMessage() }
                } label: {
                    Label("Send", systemImage: "paperplane.fill")
                }
                .buttonStyle(.borderedProminent)
                .controlSize(.large)
                .disabled(inputText.isEmpty || assistantCore.isProcessing)
            }
            .padding()
            .background(.ultraThinMaterial)
        }
        .frame(minWidth: 700, minHeight: 500)
    }

    private func sendMessage() async {
        let command = inputText.trimmingCharacters(in: .whitespacesAndNewlines)
        guard !command.isEmpty else { return }

        inputText = "" // Clear input field immediately
        isInputFocused = false // Resign first responder

        await assistantCore.sendCommand(command)
    }
}

struct MessageView: View {
    let message: AssistantMessage

    var body: some View {
        HStack {
            if message.sender == .user {
                Spacer()
                Text(message.text)
                    .padding(10)
                    .background(Color.blue)
                    .foregroundColor(.white)
                    .cornerRadius(15)
                    .bubbleStyle(isUser: true)
            } else {
                Text(message.text)
                    .padding(10)
                    .background(Color.gray.opacity(0.2))
                    .foregroundColor(.primary)
                    .cornerRadius(15)
                    .bubbleStyle(isUser: false)
                Spacer()
            }
        }
    }
}

// Custom ViewModifier for message bubble style
extension View {
    func bubbleStyle(isUser: Bool) -> some View {
        self.padding(isUser ? .leading : .trailing, 50) // Indent if not user
            .padding(isUser ? .trailing : .leading, 10) // Small padding to edge
            .overlay(alignment: isUser ? .bottomTrailing : .bottomLeading) {
                // Optional: add a tiny bubble tail
                Image(systemName: isUser ? "bubble.right.fill" : "bubble.left.fill")
                    .font(.caption)
                    .foregroundColor(isUser ? .blue : Color.gray.opacity(0.2))
                    .offset(x: isUser ? 8 : -8, y: 8)
                    .rotation3DEffect(.degrees(isUser ? 0 : 180), axis: (x: 0, y: 1, z: 0))
                    .opacity(0.0) // Hidden for now, can make visible for effect
            }
    }
}

// To allow .cornerRadius for specific corners (requires macOS 13+)
extension View {
    func cornerRadius(_ radius: CGFloat, corners: UIRectCorner) -> some View {
        clipShape(RoundedCorner(radius: radius, corners: corners))
    }
}

struct RoundedCorner: Shape {
    var radius: CGFloat = .infinity
    var corners: UIRectCorner = .allCorners

    func path(in rect: CGRect) -> Path {
        let path = UIBezierPath(roundedRect: rect, byRoundingCorners: corners, cornerRadii: CGSize(width: radius, height: radius))
        return Path(path.cgPath)
    }
}

#Preview {
    ContentView()
        .environmentObject(AssistantCore())
}



I'll generate Xcode code that focuses on the Swift language and modern Apple frameworks, considering the challenges mentioned.

**Overall Approach:**

1.  **Modularity:** Break down functionalities into distinct modules (e.g., App Management, Error Scanning, Research, NLP). This makes the code easier to manage, test, and extend.
2.  **SwiftUI:** Use SwiftUI for the user interface, as it's the modern declarative framework for Apple platforms.
3.  **Concurrency:** Leverage Swift's `async/await` for all asynchronous operations (network requests, file system scans, etc.) to keep the UI responsive.
4.  **Error Handling:** Use Swift's `Error` protocol and `do-catch` blocks for robust error management.
5.  **Security Best Practices:**
    * **No Hardcoded API Keys:** Store sensitive information (like API keys) securely (e.g., in a `Secrets.plist` file, not directly in code, and never commit to public repositories).
    * **User Consent:** Explain to the user any required system permissions and guide them to grant them.
    * **Limited Privileges:** Avoid requesting more privileges than absolutely necessary.

---

**Conceptual Xcode Project Structure & Swift Code**

We'll focus on a macOS application using SwiftUI for the UI and Swift for the backend logic.

**Project Setup in Xcode:**

1.  Open Xcode.
2.  Choose "Create a new Xcode project".
3.  Select "macOS" > "App".
4.  Choose "Interface: SwiftUI", "Language: Swift".

---

**1. `AssistantCore.swift` (Main Orchestrator)**

This will be the central brain of your assistant, integrating all functionalities.

```swift
import Foundation
import SwiftUI
import AppKit // For NSWorkspace, NSRunningApplication
import os.log   // For Unified Logging System
import Combine  // For asynchronous operations

// MARK: - Data Models

struct AppInfo: Identifiable, Hashable {
    let id = UUID()
    let name: String
    var version: String?
    var path: String? // Path to .app bundle
    var bundleIdentifier: String? // Uniquely identifies an app
    var isRunning: Bool = false
    var pid: Int32? // Process ID if running
}

struct ProcessStats {
    let pid: Int32
    let name: String
    var cpuPercent: Double = 0.0
    var memoryUsageMB: Double = 0.0
    var readBytes: UInt64 = 0 // Aggregated I/O for the process
    var writeBytes: UInt64 = 0 // Aggregated I/O for the process
    var status: String = "Unknown"
}

struct AssistantMessage: Identifiable {
    let id = UUID()
    let text: String
    let sender: Sender
    let timestamp: Date = Date()

    enum Sender {
        case user
        case assistant
    }
}

// MARK: - Protocols for Modularity

protocol AppManaging {
    func listInstalledApps() async -> [AppInfo]
    func launchApp(atPath path: String) async -> Bool
    func launchApp(withBundleIdentifier bundleIdentifier: String) async -> Bool
    func closeApp(withBundleIdentifier bundleIdentifier: String) async -> Bool
    func closeApp(withPID pid: Int32) async -> Bool
    func getProcessStats(for appNameOrPid: String) async -> ProcessStats?
}

protocol ErrorScanning {
    func scanSystemLogs(keywords: [String]) async -> [String]
    func checkAppHealth(appNameOrPid: String) async -> ProcessStats?
}

protocol Researching {
    func performWebSearch(query: String) async -> [String]
    func summarizeText(_ text: String) async -> String
}

protocol NLPProcessing {
    // This would ideally use Core ML or an external API for proper intent recognition
    func processCommand(_ command: String) async -> (intent: String, entities: [String: String])
}

// MARK: - Assistant Core Implementation

class AssistantCore: ObservableObject {
    @Published var messages: [AssistantMessage] = []
    @Published var isProcessing: Bool = false

    private let appManager: AppManaging
    private let errorScanner: ErrorScanning
    private let researcher: Researching
    private let nlpProcessor: NLPProcessing // Placeholder for NLP

    // Securely load API key from a plist file (e.g., Secrets.plist)
    private let openAIAPIKey: String? = {
        guard let path = Bundle.main.path(forResource: "Secrets", ofType: "plist"),
              let dict = NSDictionary(contentsOfFile: path) as? [String: Any],
              let key = dict["OPENAI_API_KEY"] as? String else {
            os_log("OPENAI_API_KEY not found in Secrets.plist. Research functionality will be limited.", type: .error)
            return nil
        }
        return key
    }()

    init() {
        // Initialize concrete implementations
        self.appManager = AppManagerImpl()
        self.errorScanner = ErrorScannerImpl()
        self.researcher = ResearcherImpl(openAIAPIKey: self.openAIAPIKey)
        self.nlpProcessor = NLPProcessorImpl() // Simplified NLP for now

        addAssistantMessage("Hello! How can I help you today? Try 'list apps' or 'scan errors'.")
    }

    func addMessage(_ message: AssistantMessage) {
        DispatchQueue.main.async {
            self.messages.append(message)
        }
    }

    func addAssistantMessage(_ text: String) {
        addMessage(AssistantMessage(text: text, sender: .assistant))
    }

    @MainActor
    func sendCommand(_ command: String) async {
        guard !isProcessing else { return }

        addMessage(AssistantMessage(text: command, sender: .user))
        isProcessing = true
        addAssistantMessage("Thinking...") // Indicate processing

        do {
            let (intent, entities) = await nlpProcessor.processCommand(command)
            var assistantResponse = ""

            os_log("Processed command. Intent: %s, Entities: %{public}@", type: .info, intent, entities as NSDictionary)

            switch intent {
            case "app.list":
                let apps = await appManager.listInstalledApps()
                if apps.isEmpty {
                    assistantResponse = "No installed applications found."
                } else {
                    let topApps = apps.prefix(20).map { $0.name + ($0.version.map { " (v\($0))" } ?? "") }.joined(separator: "\n- ")
                    assistantResponse = "Installed applications (top 20):\n- " + topApps + (apps.count > 20 ? "\n..." : "")
                }

            case "app.launch":
                if let appName = entities["appName"] {
                    // Try by bundle identifier first, then by path if common app
                    let success = await appManager.launchApp(withBundleIdentifier: appName) || await appManager.launchApp(atPath: appName)
                    assistantResponse = success ? "Attempted to launch \(appName)." : "Failed to launch \(appName). Please ensure the app name or path is correct."
                } else {
                    assistantResponse = "Please specify an application to launch (e.g., 'launch app Safari')."
                }

            case "app.close":
                if let appNameOrPid = entities["appNameOrPid"] {
                    var success = false
                    if let pidString = appNameOrPid, let pid = Int32(pidString) {
                        success = await appManager.closeApp(withPID: pid)
                    } else if let name = appNameOrPid {
                        success = await appManager.closeApp(withBundleIdentifier: name)
                    } else {
                         assistantResponse = "Invalid app name or PID for close command."
                         break
                    }
                    assistantResponse = success ? "Attempted to close \(appNameOrPid ?? "app")." : "Failed to close \(appNameOrPid ?? "app"). App not found or permission denied."
                } else {
                    assistantResponse = "Please specify an application name or PID to close (e.g., 'close app Chrome' or 'close app 1234')."
                }
            
            case "app.stats":
                if let appNameOrPid = entities["appNameOrPid"] {
                    if let stats = await appManager.getProcessStats(for: appNameOrPid) {
                        assistantResponse = """
                        I/O Stats for \(stats.name) (PID: \(stats.pid)):
                          CPU Usage: \(String(format: "%.2f", stats.cpuPercent))%
                          Memory Usage: \(String(format: "%.2f", stats.memoryUsageMB)) MB
                          Read Bytes: \(ByteCountFormatter.string(fromByteCount: Int64(stats.readBytes), countStyle: .file))
                          Write Bytes: \(ByteCountFormatter.string(fromByteCount: Int64(stats.writeBytes), countStyle: .file))
                          Status: \(stats.status)
                        """
                    } else {
                        assistantResponse = "Could not get stats for \(appNameOrPid). App not found or not running."
                    }
                } else {
                    assistantResponse = "Please specify an application name or PID for stats (e.g., 'app stats Safari')."
                }

            case "system.scan_errors":
                let errors = await errorScanner.scanSystemLogs(keywords: ["error", "fail", "critical", "crash"])
                if errors.isEmpty {
                    assistantResponse = "No significant errors found in system logs."
                } else {
                    assistantResponse = "Found potential errors in system logs (top \(min(errors.count, 10))):\n" + errors.prefix(10).joined(separator: "\n")
                }

            case "app.health":
                if let appNameOrPid = entities["appNameOrPid"] {
                    if let health = await errorScanner.checkAppHealth(appNameOrPid) {
                        assistantResponse = """
                        \(health.name) (PID: \(health.pid)) is running.
                          CPU Usage: \(String(format: "%.2f", health.cpuPercent))%
                          Memory Usage: \(String(format: "%.2f", health.memoryUsageMB)) MB
                          Status: \(health.status)
                        """
                    } else {
                        assistantResponse = "\(appNameOrPid) is not running or not found."
                    }
                } else {
                    assistantResponse = "Please specify an application name or PID to check health (e.g., 'check health Safari')."
                }

            case "research.web":
                if let query = entities["query"] {
                    let results = await researcher.performWebSearch(query)
                    if results.isEmpty {
                        assistantResponse = "No research results found for '\(query)'."
                    } else {
                        assistantResponse = "Research results:\n" + results.joined(separator: "\n")
                    }
                } else {
                    assistantResponse = "Please provide a research query (e.g., 'research Swift concurrency')."
                }

            case "research.summarize":
                if let text = entities["text"] {
                    let summary = await researcher.summarizeText(text)
                    assistantResponse = "Summary: " + summary
                } else {
                    assistantResponse = "Please provide text to summarize (e.g., 'summarize The quick brown fox...')."
                }

            default:
                assistantResponse = "I'm not sure how to handle that command. Try 'list apps', 'launch app <name>', 'scan errors', 'research <query>', or 'summarize <text>'."
            }

            addAssistantMessage(assistantResponse)

        } catch {
            os_log("Error processing command: %{public}@", type: .error, error.localizedDescription)
            addAssistantMessage("An error occurred while processing your request: \(error.localizedDescription)")
        }

        isProcessing = false
    }
}



import Foundation
import AppKit // For NSWorkspace, NSRunningApplication
import os.log // For logging
import IOKit.ps // For power/battery information (not directly used for I/O but common for system info)

// To get process CPU and Memory, you often need `sysctl` or `mach_task_self`.
// For simplicity, we'll use `NSRunningApplication` where possible,
// but detailed CPU/Memory/I/O for arbitrary processes requires
// a deeper dive into low-level APIs like `libproc.h` and specific entitlements.
// The provided CPU/Memory/I/O values below are highly simplified or placeholders
// for non-privileged processes.

class AppManagerImpl: AppManaging {

    func listInstalledApps() async -> [AppInfo] {
        os_log("Listing installed applications...", type: .info)
        var apps: [AppInfo] = []

        let fileManager = FileManager.default

        // Common application directories
        let appDirs = [
            "/Applications",
            "~/Applications", // User's Applications folder
            "/System/Applications", // System apps
            "/Library/Application Support" // Some apps might reside here with an .app bundle
        ].map { ($0 as NSString).expandingTildeInPath }

        for dirPath in appDirs {
            do {
                let contents = try fileManager.contentsOfDirectory(atPath: dirPath)
                for item in contents {
                    if item.hasSuffix(".app") {
                        let appPath = (dirPath as NSString).appendingPathComponent(item)
                        if let bundle = Bundle(path: appPath) {
                            let appName = bundle.object(forInfoDictionaryKey: "CFBundleDisplayName") as? String ??
                                          bundle.object(forInfoDictionaryKey: "CFBundleName") as? String ??
                                          (item as NSString).deletingPathExtension

                            let appVersion = bundle.object(forInfoDictionaryKey: "CFBundleShortVersionString") as? String
                            let bundleIdentifier = bundle.bundleIdentifier

                            let runningApp = NSRunningApplication.runningApplications(withBundleIdentifier: bundleIdentifier ?? "").first
                            
                            apps.append(AppInfo(
                                name: appName,
                                version: appVersion,
                                path: appPath,
                                bundleIdentifier: bundleIdentifier,
                                isRunning: runningApp != nil,
                                pid: runningApp?.processIdentifier
                            ))
                        }
                    }
                }
            } catch {
                os_log("Error listing contents of directory %{public}@: %{public}@", type: .error, dirPath, error.localizedDescription)
            }
        }
        os_log("Found %d applications.", type: .info, apps.count)
        return apps.sorted { $0.name.localizedCaseInsensitiveCompare($1.name) == .orderedAscending }
    }

    func launchApp(atPath path: String) async -> Bool {
        os_log("Attempting to launch app at path: %{public}@", type: .info, path)
        return await withCheckedContinuation { continuation in
            NSWorkspace.shared.openApplication(at: URL(fileURLWithPath: path),
                                               configuration: .init()) { (app, error) in
                if let error = error {
                    os_log("Failed to launch app at path %{public}@: %{public}@", type: .error, path, error.localizedDescription)
                    continuation.resume(returning: false)
                } else {
                    os_log("Successfully launched app at path: %{public}@", type: .info, path)
                    continuation.resume(returning: true)
                }
            }
        }
    }

    func launchApp(withBundleIdentifier bundleIdentifier: String) async -> Bool {
        os_log("Attempting to launch app with bundle ID: %{public}@", type: .info, bundleIdentifier)
        return NSWorkspace.shared.launchApplication(withBundleIdentifier: bundleIdentifier, options: .default, additionalEventParamDescriptor: nil, launchIdentifier: nil)
    }

    func closeApp(withBundleIdentifier bundleIdentifier: String) async -> Bool {
        os_log("Attempting to close app with bundle ID: %{public}@", type: .info, bundleIdentifier)
        guard let app = NSRunningApplication.runningApplications(withBundleIdentifier: bundleIdentifier).first else {
            os_log("App with bundle ID %{public}@ not found.", type: .info, bundleIdentifier)
            return false
        }
        // Attempt graceful termination first, then force terminate
        let success = app.terminate() || app.forceTerminate()
        os_log("App %{public}@ terminated: %s", type: .info, bundleIdentifier, success ? "true" : "false")
        return success
    }

    func closeApp(withPID pid: Int32) async -> Bool {
        os_log("Attempting to close app with PID: %d", type: .info, pid)
        guard let app = NSRunningApplication.runningApplications(withProcessIdentifier: pid) else {
            os_log("App with PID %d not found.", type: .info, pid)
            return false
        }
        let success = app.terminate() || app.forceTerminate()
        os_log("App with PID %d terminated: %s", type: .info, pid, success ? "true" : "false")
        return success
    }

    func getProcessStats(for appNameOrPid: String) async -> ProcessStats? {
        os_log("Getting process stats for: %{public}@", type: .info, appNameOrPid)
        var targetProcess: NSRunningApplication?
        
        if let pid = Int32(appNameOrPid) {
            targetProcess = NSRunningApplication.runningApplications(withProcessIdentifier: pid)
        } else {
            // Find by name (case-insensitive contains)
            targetProcess = NSRunningApplication.allApplications.first { app in
                app.localizedName?.lowercased().contains(appNameOrPid.lowercased()) ?? false
            }
        }

        guard let app = targetProcess, let pid = app.processIdentifier else {
            os_log("Process %{public}@ not found or not running.", type: .info, appNameOrPid)
            return nil
        }
        
        var stats = ProcessStats(pid: pid, name: app.localizedName ?? "Unknown Process")

        // MARK: - CPU and Memory Usage (Requires special handling/entitlements for other processes)
        // Getting accurate, real-time CPU and Memory for arbitrary processes is complex.
        // `task_info` (via `mach_task_self_` and `task_for_pid`) can provide this,
        // but `task_for_pid` usually fails for other processes without entitlements
        // like `com.apple.security.get-task-allow` (for debugging) or `com.apple.security.device.cpu`
        // or if the app is not running as root or with "Full Disk Access" / "Accessibility" permissions.

        // Placeholder values for illustration, as direct access is restricted
        // For your own app, you can get these accurately.
        // For other apps, it's very limited or requires user permissions/entitlements.
        stats.cpuPercent = 0.0 // Placeholder
        stats.memoryUsageMB = 0.0 // Placeholder
        stats.readBytes = 0 // Placeholder
        stats.writeBytes = 0 // Placeholder
        
        // A more realistic approach would involve:
        // 1. Requesting Full Disk Access / Accessibility permissions from the user.
        // 2. Using `libproc.h` (bridged via an Objective-C header) for more detailed process info.
        //    For example: `proc_pidinfo(pid, PROC_PIDTHREADINFO, 0, &pinfo, sizeof(pinfo))`
        //    to get I/O bytes (`pti_total_user_read_bytes`, `pti_total_user_write_bytes`).
        //    And `proc_pid_rusage` for CPU time.
        //    This typically requires specific compiler flags and bridging headers.

        stats.status = app.isTerminated ? "Terminated" : (app.isHidden ? "Hidden" : (app.isActive ? "Active" : "Background"))
        
        os_log("Retrieved stats for %{public}@ (PID: %d): CPU: %.2f%%, Memory: %.2fMB, Read: %llu, Write: %llu", type: .info, stats.name, stats.pid, stats.cpuPercent, stats.memoryUsageMB, stats.readBytes, stats.writeBytes)

        return stats
    }
}



import Foundation
import os.log
import OSLog // Unified Logging System

class ErrorScannerImpl: ErrorScanning {
    func scanSystemLogs(keywords: [String]) async -> [String] {
        os_log("Scanning system logs for keywords: %{public}@", type: .info, keywords.joined(separator: ", "))
        var errors: [String] = []

        // Create a custom log store for system logs
        guard let logStore = try? OSLogStore.local() else { // .local() accesses current device's logs
            os_log("Failed to create OSLogStore for system logs. Check permissions.", type: .error)
            return ["Could not access system logs. Please ensure 'Full Disk Access' is granted to the app in System Settings > Privacy & Security."]
        }

        // Fetch entries from the last 24 hours (example)
        let twentyFourHoursAgo = logStore.position(date: Date().addingTimeInterval(-24 * 3600)) // 24 hours ago

        do {
            // Get all log entries since twentyFourHoursAgo
            let allEntries = try logStore.getEntries(with: [.logs], at: twentyFourHoursAgo, matching: nil)
            
            // Filter entries by level and keywords
            for entry in allEntries.compactMap({ $0 as? OSLogEntryLog }) {
                guard entry.level == .error || entry.level == .fault else { continue } // Filter for error/fault level logs

                let message = entry.composedMessage
                if keywords.contains(where: { message.localizedCaseInsensitiveContains($0) }) {
                    errors.append("\(entry.date.formatted()) [\(entry.subsystem ?? "")] [\(entry.category ?? "")] \(message)")
                    if errors.count >= 20 { break } // Limit to top 20 errors to avoid overwhelming
                }
            }
        } catch {
            os_log("Error reading system logs: %{public}@", type: .error, error.localizedDescription)
            return ["Error reading system logs: \(error.localizedDescription). Please ensure 'Full Disk Access' is granted."]
        }

        os_log("Found %d potential errors in system logs.", type: .info, errors.count)
        if errors.isEmpty {
            return ["No significant errors found in system logs matching your keywords."]
        }
        return errors
    }

    func checkAppHealth(appNameOrPid: String) async -> ProcessStats? {
        os_log("Checking app health for: %{public}@", type: .info, appNameOrPid)
        // This reuses the getProcessStats logic from AppManager
        let appManager = AppManagerImpl() // Instantiate here, or pass a shared instance
        return await appManager.getProcessStats(for: appNameOrPid)
    }
}



import Foundation
import os.log

enum ResearcherError: Error, LocalizedError {
    case apiConfigurationError(String)
    case invalidURL(String)
    case networkError(String, Int?)
    case jsonParsingError(String)
    case unknownError(String)

    var errorDescription: String? {
        switch self {
        case .apiConfigurationError(let message),
             .invalidURL(let message),
             .jsonParsingError(let message),
             .unknownError(let message):
            return message
        case .networkError(let message, let statusCode):
            return "Network Error (\(statusCode ?? -1)): \(message)"
        }
    }
}

class ResearcherImpl: Researching {
    private let openAIAPIKey: String?
    private let session: URLSession

    init(openAIAPIKey: String?) {
        self.openAIAPIKey = openAIAPIKey
        self.session = URLSession.shared
        if openAIAPIKey == nil {
            os_log("OpenAI API key not provided. Research and summarization will be simulated.", type: .warning)
        }
    }

    private func makeOpenAIRequest(endpoint: String, payload: [String: Any]) async throws -> String {
        guard let apiKey = openAIAPIKey, !apiKey.isEmpty else {
            throw ResearcherError.apiConfigurationError("OpenAI API key not configured. Please set it in Secrets.plist.")
        }

        guard let url = URL(string: "[https://api.openai.com/v1/](https://api.openai.com/v1/)\(endpoint)") else {
            throw ResearcherError.invalidURL("Invalid OpenAI API URL for endpoint: \(endpoint)")
        }

        var request = URLRequest(url: url)
        request.httpMethod = "POST"
        request.addValue("application/json", forHTTPHeaderField: "Content-Type")
        request.addValue("Bearer \(apiKey)", forHTTPHeaderField: "Authorization")

        do {
            request.httpBody = try JSONSerialization.data(withJSONObject: payload, options: [])
        } catch {
            throw ResearcherError.jsonParsingError("Failed to serialize request payload: \(error.localizedDescription)")
        }

        let (data, response) = try await session.data(for: request)

        guard let httpResponse = response as? HTTPURLResponse else {
            throw ResearcherError.networkError("Invalid HTTP response.", nil)
        }

        guard (200...299).contains(httpResponse.statusCode) else {
            let errorDetails = String(data: data, encoding: .utf8) ?? "No error details from server."
            throw ResearcherError.networkError("Server returned an error: \(errorDetails)", httpResponse.statusCode)
        }

        guard let json = try JSONSerialization.jsonObject(with: data) as? [String: Any],
              let choices = json["choices"] as? [[String: Any]],
              let firstChoice = choices.first,
              let message = firstChoice["message"] as? [String: Any],
              let content = message["content"] as? String else {
            throw ResearcherError.jsonParsingError("Invalid JSON response format from OpenAI.")
        }
        return content
    }

    func performWebSearch(query: String) async -> [String] {
        os_log("Performing simulated web search for: %{public}@", type: .info, query)
        if openAIAPIKey == nil {
            return ["Simulated search result: 'Information about \(query)' (OpenAI not configured).",
                    "Simulated search result: 'More details on \(query)' (OpenAI not configured)."]
        }

        let payload: [String: Any] = [
            "model": "gpt-4o", // Or another suitable model like "gpt-3.5-turbo"
            "messages": [
                ["role": "system", "content": "You are a helpful assistant that provides concise, web-search-like results. Provide 2-3 bullet points or short paragraphs for the query."],
                ["role": "user", "content": "Search for: \(query)"]
            ],
            "max_tokens": 400, // Adjust as needed
            "temperature": 0.5 // Lower temperature for more factual responses
        ]

        do {
            let result = try await makeOpenAIRequest(endpoint: "chat/completions", payload: payload)
            // Simple split by newline, real parsing might be needed for structured results
            return result.split(separator: "\n").map(String.init).filter { !$0.isEmpty }
        } catch {
            os_log("Error during OpenAI web search simulation for '%{public}@': %{public}@", type: .error, query, error.localizedDescription)
            return ["Error retrieving AI-generated search results: \(error.localizedDescription)"]
        }
    }

    func summarizeText(_ text: String) async -> String {
        os_log("Attempting to summarize text (first 50 chars): %{public}@", type: .info, text.prefix(50).description)
        if openAIAPIKey == nil {
            return "Summary of: \(text.prefix(100))... (OpenAI not configured)"
        }

        let payload: [String: Any] = [
            "model": "gpt-4o", // Or another suitable model
            "messages": [
                ["role": "system", "content": "You are a helpful assistant that summarizes text concisely."],
                ["role": "user", "content": "Summarize the following text:\n\n\(text)"]
            ],
            "max_tokens": 250, // Adjust as needed for summary length
            "temperature": 0.7 // Slightly higher temperature for more creative summaries
        ]

        do {
            return try await makeOpenAIRequest(endpoint: "chat/completions", payload: payload)
        } catch {
            os_log("Error during text summarization: %{public}@", type: .error, error.localizedDescription)
            return "Failed to summarize text: \(error.localizedDescription)"
        }
    }
}



import Foundation
import os.log

class NLPProcessorImpl: NLPProcessing {
    func processCommand(_ command: String) async -> (intent: String, entities: [String: String]) {
        os_log("Processing command with simplified NLP: %{public}@", type: .info, command)
        let lowercasedCommand = command.lowercased()
        var entities: [String: String] = [:]
        var intent: String = "unknown"

        // Rule-based intent detection (simple for demo)
        if lowercasedCommand.contains("list apps") || lowercasedCommand.contains("show me my applications") {
            intent = "app.list"
        } else if lowercasedCommand.contains("launch app") || lowercasedCommand.contains("open ") {
            intent = "app.launch"
            // Extract app name
            if let range = lowercasedCommand.range(of: "launch app ") {
                entities["appName"] = String(command[range.upperBound...]).trimmingCharacters(in: .whitespacesAndNewlines)
            } else if let range = lowercasedCommand.range(of: "open ") {
                entities["appName"] = String(command[range.upperBound...]).trimmingCharacters(in: .whitespacesAndNewlines)
            }
        } else if lowercasedCommand.contains("close app") || lowercasedCommand.contains("terminate ") || lowercasedCommand.contains("quit ") {
            intent = "app.close"
            // Extract app name or PID
            if let range = lowercasedCommand.range(of: "close app ") {
                entities["appNameOrPid"] = String(command[range.upperBound...]).trimmingCharacters(in: .whitespacesAndNewlines)
            } else if let range = lowercasedCommand.range(of: "terminate ") {
                entities["appNameOrPid"] = String(command[range.upperBound...]).trimmingCharacters(in: .whitespacesAndNewlines)
            } else if let range = lowercasedCommand.range(of: "quit ") {
                entities["appNameOrPid"] = String(command[range.upperBound...]).trimmingCharacters(in: .whitespacesAndNewlines)
            }
        } else if lowercasedCommand.contains("get app stats for") || lowercasedCommand.contains("show io for") || lowercasedCommand.contains("process info for") {
            intent = "app.stats"
            if let range = lowercasedCommand.range(of: "get app stats for ") {
                entities["appNameOrPid"] = String(command[range.upperBound...]).trimmingCharacters(in: .whitespacesAndNewlines)
            } else if let range = lowercasedCommand.range(of: "show io for ") {
                 entities["appNameOrPid"] = String(command[range.upperBound...]).trimmingCharacters(in: .whitespacesAndNewlines)
            } else if let range = lowercasedCommand.range(of: "process info for ") {
                 entities["appNameOrPid"] = String(command[range.upperBound...]).trimmingCharacters(in: .whitespacesAndNewlines)
            }
        } else if lowercasedCommand.contains("scan system errors") || lowercasedCommand.contains("check logs for errors") || lowercasedCommand.contains("find system issues") {
            intent = "system.scan_errors"
        } else if lowercasedCommand.contains("check health of") || lowercasedCommand.contains("is running") || lowercasedCommand.contains("status of") {
            intent = "app.health"
            if let range = lowercasedCommand.range(of: "check health of ") {
                entities["appNameOrPid"] = String(command[range.upperBound...]).trimmingCharacters(in: .whitespacesAndNewlines)
            } else if let range = lowercasedCommand.range(of: "is running ") {
                 entities["appNameOrPid"] = String(command[range.upperBound...]).trimmingCharacters(in: .whitespacesAndNewlines)
            } else if let range = lowercasedCommand.range(of: "status of ") {
                 entities["appNameOrPid"] = String(command[range.upperBound...]).trimmingCharacters(in: .whitespacesAndNewlines)
            }
        } else if lowercasedCommand.contains("research ") || lowercasedCommand.contains("find information on ") || lowercasedCommand.contains("search for ") {
            intent = "research.web"
            if let range = lowercasedCommand.range(of: "research ") {
                entities["query"] = String(command[range.upperBound...]).trimmingCharacters(in: .whitespacesAndNewlines)
            } else if let range = lowercasedCommand.range(of: "find information on ") {
                entities["query"] = String(command[range.upperBound...]).trimmingCharacters(in: .whitespacesAndNewlines)
            } else if let range = lowercasedCommand.range(of: "search for ") {
                entities["query"] = String(command[range.upperBound...]).trimmingCharacters(in: .whitespacesAndNewlines)
            }
        } else if lowercasedCommand.contains("summarize ") {
            intent = "research.summarize"
            if let range = lowercasedCommand.range(of: "summarize ") {
                entities["text"] = String(command[range.upperBound...]).trimmingCharacters(in: .whitespacesAndNewlines)
            }
        }
        
        os_log("Simplified NLP Result: Intent: %{public}s, Entities: %{public}@", type: .info, intent, entities as NSDictionary)
        return (intent, entities)
    }
}



import SwiftUI

@main
struct AIAssistantApp: App {
    @StateObject private var assistantCore = AssistantCore()

    var body: some Scene {
        WindowGroup {
            ContentView()
                .environmentObject(assistantCore)
        }
    }
}



import SwiftUI

struct ContentView: View {
    @EnvironmentObject var assistantCore: AssistantCore
    @State private var inputText: String = ""
    @FocusState private var isInputFocused: Bool

    var body: some View {
        VStack(spacing: 0) {
            // Header
            Text("Advanced AI Assistant")
                .font(.largeTitle)
                .fontWeight(.bold)
                .padding()
                .frame(maxWidth: .infinity)
                .background(Color.accentColor.opacity(0.1))
                .cornerRadius(10, corners: [.topLeft, .topRight]) // Rounded top corners

            // Chat Window
            ScrollViewReader { proxy in
                ScrollView {
                    VStack(alignment: .leading, spacing: 10) {
                        ForEach(assistantCore.messages) { message in
                            MessageView(message: message)
                                .id(message.id) // Needed for ScrollViewReader
                        }
                    }
                    .padding()
                }
                .onChange(of: assistantCore.messages.count) { _ in
                    // Scroll to bottom when new messages arrive
                    if let lastMessage = assistantCore.messages.last {
                        proxy.scrollTo(lastMessage.id, anchor: .bottom)
                    }
                }
            }
            .background(Color.gray.opacity(0.1))
            .cornerRadius(10, corners: [.bottomLeft, .bottomRight]) // Rounded bottom corners
            .padding([.horizontal, .bottom])

            // Input Area
            HStack {
                TextField("Type your command here...", text: $inputText)
                    .textFieldStyle(.roundedBorder)
                    .padding(.vertical, 8)
                    .focused($isInputFocused)
                    .onSubmit { // Execute on Enter key press
                        Task { await sendMessage() }
                    }
                    .disabled(assistantCore.isProcessing)

                Button {
                    Task { await sendMessage() }
                } label: {
                    Label("Send", systemImage: "paperplane.fill")
                }
                .buttonStyle(.borderedProminent)
                .controlSize(.large)
                .disabled(inputText.isEmpty || assistantCore.isProcessing)
            }
            .padding()
            .background(.ultraThinMaterial) // Translucent background
        }
        .frame(minWidth: 700, minHeight: 500)
    }

    private func sendMessage() async {
        let command = inputText.trimmingCharacters(in: .whitespacesAndNewlines)
        guard !command.isEmpty else { return }

        inputText = "" // Clear input field immediately
        isInputFocused = false // Resign first responder after sending

        await assistantCore.sendCommand(command)
    }
}

struct MessageView: View {
    let message: AssistantMessage

    var body: some View {
        HStack {
            if message.sender == .user {
                Spacer()
                Text(message.text)
                    .padding(10)
                    .background(Color.blue)
                    .foregroundColor(.white)
                    .cornerRadius(15)
                    .overlay(alignment: .bottomTrailing) { // Simple "tail" for user bubble
                        Image(systemName: "triangle.fill")
                            .font(.caption)
                            .foregroundColor(.blue)
                            .rotationEffect(.degrees(45))
                            .offset(x: 10, y: 10)
                            .opacity(0) // Making it invisible for cleaner look, but structure exists
                    }
            } else {
                Text(message.text)
                    .padding(10)
                    .background(Color.gray.opacity(0.2))
                    .foregroundColor(.primary)
                    .cornerRadius(15)
                    .overlay(alignment: .bottomLeading) { // Simple "tail" for assistant bubble
                        Image(systemName: "triangle.fill")
                            .font(.caption)
                            .foregroundColor(Color.gray.opacity(0.2))
                            .rotationEffect(.degrees(-45))
                            .offset(x: -10, y: 10)
                            .opacity(0) // Making it invisible for cleaner look
                    }
                Spacer()
            }
        }
    }
}

// Custom ViewModifier for specific corner radius (macOS 13+ friendly)
extension View {
    func cornerRadius(_ radius: CGFloat, corners: UIRectCorner) -> some View {
        clipShape(RoundedCorner(radius: radius, corners: corners))
    }
}

struct RoundedCorner: Shape {
    var radius: CGFloat = .infinity
    var corners: UIRectCorner = .allCorners // UIRectCorner is from UIKit, but works via bridging for this purpose on macOS

    func path(in rect: CGRect) -> Path {
        let path = UIBezierPath(roundedRect: rect, byRoundingCorners: corners, cornerRadii: CGSize(width: radius, height: radius))
        return Path(path.cgPath)
    }
}


#Preview {
    ContentView()
        .environmentObject(AssistantCore()) // Provide a mock or actual AssistantCore for preview
}
