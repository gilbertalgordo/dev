const CACHE_NAME = 'my-workspace-app-cache-v1';
const urlsToCache = [
  '/',
  '/index.html',
  '/styles.css',
  '/main.js',
  '/manifest.json',
  // Add other essential assets
];

self.addEventListener('install', (event) => {
  event.waitUntil(
    caches.open(CACHE_NAME)
      .then((cache) => {
        console.log('Opened cache');
        return cache.addAll(urlsToCache);
      })
  );
});

self.addEventListener('fetch', (event) => {
  event.respondWith(
    caches.match(event.request)
      .then((response) => {
        // Cache hit - return response
        if (response) {
          return response;
        }
        return fetch(event.request);
      })
  );
});

self.addEventListener('activate', (event) => {
  event.waitUntil(
    caches.keys().then((cacheNames) => {
      return Promise.all(
        cacheNames.map((cacheName) => {
          if (cacheName !== CACHE_NAME) {
            console.log('Deleting old cache:', cacheName);
            return caches.delete(cacheName);
          }
        })
      );
    })
  );
});



if ('serviceWorker' in navigator) {
  window.addEventListener('load', () => {
    navigator.serviceWorker.register('/service-worker.js')
      .then(registration => {
        console.log('Service Worker registered with scope:', registration.scope);
      })
      .catch(error => {
        console.error('Service Worker registration failed:', error);
      });
  });
}



// main.js (conceptual)

// Open (or create) a database
let db;
const request = indexedDB.open('GoogleWorkspaceAppData', 1);

request.onerror = (event) => {
  console.error('IndexedDB error:', event.target.errorCode);
};

request.onupgradeneeded = (event) => {
  db = event.target.result;
  const objectStore = db.createObjectStore('files', { keyPath: 'id' });
  objectStore.createIndex('title', 'title', { unique: false });
  // Add other object stores for emails, calendar events, etc.
};

request.onsuccess = (event) => {
  db = event.target.result;
  console.log('IndexedDB opened successfully');
  // You can now interact with the database
};

// Function to save a file to IndexedDB
async function saveFileOffline(fileData) {
  if (!db) {
    console.error('IndexedDB not ready.');
    return;
  }
  const transaction = db.transaction(['files'], 'readwrite');
  const objectStore = transaction.objectStore('files');
  const request = objectStore.put(fileData); // fileData should have an 'id'

  request.onsuccess = () => {
    console.log('File saved offline:', fileData.title);
  };

  request.onerror = (event) => {
    console.error('Error saving file offline:', event.target.error);
  };
}

// Function to retrieve files from IndexedDB
async function getFilesOffline() {
  return new Promise((resolve, reject) => {
    if (!db) {
      reject('IndexedDB not ready.');
      return;
    }
    const transaction = db.transaction(['files'], 'readonly');
    const objectStore = transaction.objectStore('files');
    const request = objectStore.getAll();

    request.onsuccess = () => {
      resolve(request.result);
    };

    request.onerror = (event) => {
      reject(event.target.error);
    };
  });
}

// Example: Fetch a file from Google Drive and save it offline
async function fetchAndCacheGoogleDriveFile(fileId) {
  try {
    const response = await fetch(`https://www.googleapis.com/drive/v3/files/${fileId}?alt=media`, {
      headers: {
        'Authorization': `Bearer YOUR_ACCESS_TOKEN` // OAuth 2.0 access token
      }
    });
    if (!response.ok) {
      throw new Error(`HTTP error! status: ${response.status}`);
    }
    const fileContent = await response.text(); // Or response.blob() for binary files

    // Get file metadata separately if needed
    const metadataResponse = await fetch(`https://www.googleapis.com/drive/v3/files/${fileId}`, {
        headers: { 'Authorization': `Bearer YOUR_ACCESS_TOKEN` }
    });
    const fileMetadata = await metadataResponse.json();

    await saveFileOffline({
      id: fileMetadata.id,
      title: fileMetadata.name,
      content: fileContent, // Or a URL to the blob in IndexedDB
      // ... other relevant metadata
    });
  } catch (error) {
    console.error('Error fetching and caching file:', error);
  }
}

// You'd call fetchAndCacheGoogleDriveFile when online for files you want available offline
// And getFilesOffline when the user is offline



// service-worker.js (continued)

self.addEventListener('sync', (event) => {
  if (event.tag === 'sync-pending-changes') {
    event.waitUntil(syncPendingChanges());
  }
});

async function syncPendingChanges() {
  // This function would read from IndexedDB for changes made offline
  // and send them to Google Workspace APIs when online.
  console.log('Attempting to sync pending changes...');
  try {
    const db = await getIndexedDBInstance(); // Your IndexedDB setup
    const transaction = db.transaction(['pending_uploads'], 'readwrite');
    const objectStore = transaction.objectStore('pending_uploads');
    const pendingChanges = await objectStore.getAll();

    for (const change of pendingChanges) {
      if (navigator.onLine) {
        // Example: Upload a file to Google Drive
        if (change.type === 'file_upload') {
          // Use Google Drive API to upload `change.data`
          console.log('Uploading file:', change.data.title);
          // await googleDriveApi.upload(change.data); // Replace with actual API call
        }
        // ... handle other types of changes (email sends, calendar updates)

        // Once successfully synced, remove from pending_uploads
        // await objectStore.delete(change.id);
      } else {
        console.log('Still offline, deferring sync.');
        // Re-register sync if needed or rely on next connection
        self.registration.sync.register('sync-pending-changes');
        return; // Stop processing if offline again
      }
    }
    console.log('Pending changes synced successfully.');
  } catch (error) {
    console.error('Error during sync:', error);
    // On error, re-register sync to try again later
    self.registration.sync.register('sync-pending-changes');
  }
}

// To trigger background sync when a change is made offline:
// In your main application code (main.js):
// if ('serviceWorker' in navigator && 'SyncManager' in window) {
//   navigator.serviceWorker.ready.then(reg => {
//     // Save change to IndexedDB (e.g., in a 'pending_uploads' object store)
//     // ...
//     return reg.sync.register('sync-pending-changes');
//   }).then(() => {
//     console.log('Background sync registered!');
//   }).catch(err => {
//     console.error('Background sync registration failed:', err);
//   });
// }



// server.js (Node.js example using googleapis library)
const { google } = require('googleapis');
const fs = require('fs');

// OAuth2 setup (replace with your client ID, client secret, redirect URI)
const oauth2Client = new google.auth.OAuth2(
  'YOUR_CLIENT_ID',
  'YOUR_CLIENT_SECRET',
  'YOUR_REDIRECT_URI'
);

// Set credentials (usually obtained from user authorization flow)
oauth2Client.setCredentials({
  access_token: 'USER_ACCESS_TOKEN',
  refresh_token: 'USER_REFRESH_TOKEN',
});

const drive = google.drive({ version: 'v3', auth: oauth2Client });

// Function to upload a file
async function uploadFileToDrive(filePath, fileName, mimeType) {
  try {
    const response = await drive.files.create({
      requestBody: {
        name: fileName,
        mimeType: mimeType,
      },
      media: {
        mimeType: mimeType,
        body: fs.createReadStream(filePath),
      },
    });
    console.log('File uploaded:', response.data);
    return response.data;
  } catch (error) {
    console.error('Error uploading file:', error.message);
    throw error;
  }
}

// Function to download a file
async function downloadFileFromDrive(fileId, outputPath) {
  try {
    const response = await drive.files.get(
      { fileId: fileId, alt: 'media' },
      { responseType: 'stream' }
    );

    return new Promise((resolve, reject) => {
      const dest = fs.createWriteStream(outputPath);
      response.data
        .on('end', () => {
          console.log('File downloaded to:', outputPath);
          resolve(outputPath);
        })
        .on('error', (err) => {
          console.error('Error downloading file:', err);
          reject(err);
        })
        .pipe(dest);
    });
  } catch (error) {
    console.error('Error downloading file:', error.message);
    throw error;
  }
}

// Example usage (in an API endpoint or function)
// app.post('/api/upload', async (req, res) => {
//   const { filePath, fileName, mimeType } = req.body;
//   try {
//     const uploadedFile = await uploadFileToDrive(filePath, fileName, mimeType);
//     res.status(200).json(uploadedFile);
//   } catch (error) {
//     res.status(500).send('Upload failed');
//   }
// });



Building an "advanced online/offline Google Workspace" solution with Node.js typically involves a hybrid architecture:
 * Frontend (Browser-based PWA): This is where the true "offline" capabilities reside, utilizing Service Workers and IndexedDB. Node.js is primarily used to serve this frontend application and act as a backend for API interactions.
 * Backend (Node.js Server): This handles:
   * OAuth 2.0 Flow: Securely authenticating users with Google.
   * Google API Interactions: Making requests to Google Drive, Gmail, Calendar APIs on behalf of the user. This is crucial because directly exposing sensitive API keys/secrets in the frontend is a security risk.
   * Data Synchronization Logic: Managing the sync process between client-side IndexedDB and Google Workspace APIs.
   * Real-time Updates (Optional): Using WebSockets to push changes from Google Workspace to connected clients (e.g., via Drive API change notifications).
Here's a conceptual Node.js code structure, focusing on the backend server's role in facilitating an advanced online/offline Google Workspace experience.
Prerequisites:
 * Google Cloud Project: Create a project in the Google Cloud Console.
 * Enable APIs: Enable the Google Drive API, Gmail API, and Calendar API for your project.
 * OAuth 2.0 Credentials:
   * Go to APIs & Services > Credentials.
   * Create an "OAuth client ID."
   * Select "Web application" as the application type.
   * Set Authorized JavaScript origins (e.g., http://localhost:3000 for development).
   * Set Authorized redirect URIs (e.g., http://localhost:3000/oauth2callback).
   * Download the JSON credentials file (rename it to credentials.json and place it in your Node.js project root).
 * Node.js Environment:
   * Node.js installed.
   * npm init -y in your project folder.
   * Install necessary packages: npm install express googleapis google-auth-library body-parser dotenv
Project Structure:
my-workspace-app/
├── public/                 // Your frontend PWA files (index.html, service-worker.js, main.js, etc.)
│   ├── index.html
│   ├── styles.css
│   ├── main.js             // Frontend JS for IndexedDB, UI, and API calls to your Node.js backend
│   └── service-worker.js   // Service Worker for caching and background sync
├── credentials.json        // Your Google OAuth credentials
├── .env                    // Environment variables (CLIENT_ID, CLIENT_SECRET, REDIRECT_URI)
├── server.js               // Main Node.js server file
├── package.json
└── package-lock.json

1. credentials.json (Example Structure):
(Do NOT commit this file to public repositories!)
{
  "web": {
    "client_id": "YOUR_CLIENT_ID.apps.googleusercontent.com",
    "project_id": "your-project-id",
    "auth_uri": "https://accounts.google.com/o/oauth2/auth",
    "token_uri": "https://oauth2.googleapis.com/token",
    "auth_provider_x509_cert_url": "https://www.googleapis.com/oauth2/v1/certs",
    "client_secret": "YOUR_CLIENT_SECRET",
    "redirect_uris": ["http://localhost:3000/oauth2callback"]
  }
}

2. .env (Example Structure):
(Do NOT commit this file to public repositories!)
CLIENT_ID=YOUR_CLIENT_ID.apps.googleusercontent.com
CLIENT_SECRET=YOUR_CLIENT_SECRET
REDIRECT_URI=http://localhost:3000/oauth2callback

3. server.js (Node.js Backend):
This server will handle OAuth, serve static files, and provide API endpoints for your frontend to interact with Google Workspace.
require('dotenv').config(); // Load environment variables from .env
const express = require('express');
const { google } = require('googleapis');
const fs = require('fs').promises; // Use promises version of fs
const path = require('path');
const bodyParser = require('body-parser');

const app = express();
const PORT = process.env.PORT || 3000;

// Middleware
app.use(bodyParser.json());
app.use(express.static('public')); // Serve your frontend PWA from the 'public' directory

// --- Google OAuth2 Setup ---
const credentials = require('./credentials.json').web;
const { client_id, client_secret, redirect_uris } = credentials;
const redirect_uri = process.env.REDIRECT_URI || redirect_uris[0]; // Use env var for flexibility

const oauth2Client = new google.auth.OAuth2(
  client_id,
  client_secret,
  redirect_uri
);

// Define the scopes your application needs.
// For advanced offline, you'll need comprehensive scopes.
const SCOPES = [
  'https://www.googleapis.com/auth/drive', // Full Drive access
  'https://www.googleapis.com/auth/gmail.modify', // Send, delete, and modify your email
  'https://www.googleapis.com/auth/calendar', // Manage calendars
  'https://www.googleapis.com/auth/userinfo.profile', // User profile info
  'https://www.googleapis.com/auth/userinfo.email', // User email address
  'openid'
];

// --- OAuth Routes ---

// 1. Redirect user to Google for authentication
app.get('/auth/google', (req, res) => {
  const authorizeUrl = oauth2Client.generateAuthUrl({
    access_type: 'offline', // IMPORTANT for getting a refresh token
    scope: SCOPES,
    prompt: 'consent' // Forces user to re-consent, ensuring refresh token if lost
  });
  res.redirect(authorizeUrl);
});

// 2. Google redirects back to this endpoint after user grants permission
app.get('/oauth2callback', async (req, res) => {
  const { code } = req.query;
  try {
    const { tokens } = await oauth2Client.getToken(code);
    oauth2Client.setCredentials(tokens);

    // Store tokens securely. In a real app, you'd store this in a database
    // associated with the user. For this example, we'll store it in memory.
    // For a multi-user app, you'd associate tokens with a session or user ID.
    app.set('googleTokens', tokens); // Storing in app locals for simplicity (NOT PRODUCTION SAFE)

    // Redirect back to your frontend, maybe with a success message or
    // to a dashboard page.
    res.redirect('/?authSuccess=true');
  } catch (error) {
    console.error('Error retrieving access token:', error.message);
    res.status(500).send('Authentication failed.');
  }
});

// Middleware to ensure user is authenticated for Google API calls
app.use(async (req, res, next) => {
  const tokens = app.get('googleTokens'); // Retrieve tokens
  if (!tokens) {
    return res.status(401).send('Not authenticated. Please log in first.');
  }

  oauth2Client.setCredentials(tokens);

  // Check if access token is expired and refresh if needed
  if (oauth2Client.isTokenExpiring()) {
    try {
      const { credentials } = await oauth2Client.refreshAccessToken();
      oauth2Client.setCredentials(credentials);
      app.set('googleTokens', credentials); // Update stored tokens
      console.log('Access token refreshed successfully!');
    } catch (error) {
      console.error('Error refreshing access token:', error.message);
      // If refresh fails, user needs to re-authenticate
      app.set('googleTokens', null); // Clear invalid tokens
      return res.status(401).send('Session expired. Please re-authenticate.');
    }
  }
  next(); // Continue to the API route
});

// --- Google Workspace API Endpoints (Accessed by Frontend) ---

// Drive: List Files
app.get('/api/drive/files', async (req, res) => {
  const drive = google.drive({ version: 'v3', auth: oauth2Client });
  try {
    const response = await drive.files.list({
      pageSize: 10,
      fields: 'nextPageToken, files(id, name, mimeType, modifiedTime)',
    });
    res.json(response.data.files);
  } catch (error) {
    console.error('Error listing Drive files:', error.message);
    res.status(500).send('Failed to list files.');
  }
});

// Drive: Download File Content
app.get('/api/drive/files/:fileId/download', async (req, res) => {
    const { fileId } = req.params;
    const drive = google.drive({ version: 'v3', auth: oauth2Client });
    try {
        const response = await drive.files.get(
            { fileId: fileId, alt: 'media' },
            { responseType: 'stream' }
        );

        // Set appropriate headers for download
        const fileMetadata = await drive.files.get({ fileId: fileId, fields: 'name, mimeType' });
        res.setHeader('Content-Type', fileMetadata.data.mimeType);
        res.setHeader('Content-Disposition', `attachment; filename="${fileMetadata.data.name}"`);

        response.data.pipe(res); // Pipe the file stream directly to the response
    } catch (error) {
        console.error('Error downloading Drive file:', error.message);
        res.status(500).send('Failed to download file.');
    }
});

// Drive: Upload File (from frontend blob/buffer)
app.post('/api/drive/files/upload', async (req, res) => {
  // In a real app, handle file uploads more robustly, e.g., with 'multer'
  // For simplicity, assuming req.body contains { fileName, mimeType, base64Content }
  const { fileName, mimeType, base64Content } = req.body;
  if (!fileName || !mimeType || !base64Content) {
    return res.status(400).send('Missing file data.');
  }

  const drive = google.drive({ version: 'v3', auth: oauth2Client });
  const fileBuffer = Buffer.from(base64Content, 'base64'); // Convert base64 to buffer

  try {
    const response = await drive.files.create({
      requestBody: {
        name: fileName,
        mimeType: mimeType,
      },
      media: {
        mimeType: mimeType,
        body: fileBuffer, // Use the buffer directly
      },
      fields: 'id, name, mimeType',
    });
    res.status(200).json(response.data);
  } catch (error) {
    console.error('Error uploading Drive file:', error.message);
    res.status(500).send('Failed to upload file.');
  }
});

// Gmail: List Messages
app.get('/api/gmail/messages', async (req, res) => {
  const gmail = google.gmail({ version: 'v1', auth: oauth2Client });
  try {
    const response = await gmail.users.messages.list({
      userId: 'me',
      maxResults: 10,
    });
    res.json(response.data.messages || []);
  } catch (error) {
    console.error('Error listing Gmail messages:', error.message);
    res.status(500).send('Failed to list messages.');
  }
});

// Gmail: Get Message Content (Full)
app.get('/api/gmail/messages/:messageId', async (req, res) => {
  const { messageId } = req.params;
  const gmail = google.gmail({ version: 'v1', auth: oauth2Client });
  try {
    const response = await gmail.users.messages.get({
      userId: 'me',
      id: messageId,
      format: 'full' // or 'raw', 'minimal', 'metadata'
    });
    res.json(response.data);
  } catch (error) {
    console.error('Error getting Gmail message:', error.message);
    res.status(500).send('Failed to get message content.');
  }
});

// Gmail: Send Email
app.post('/api/gmail/send', async (req, res) => {
  const { to, subject, body } = req.body;
  if (!to || !subject || !body) {
    return res.status(400).send('Missing required email fields (to, subject, body).');
  }

  const gmail = google.gmail({ version: 'v1', auth: oauth2Client });

  // Create a raw email string in RFC 2822 format
  const emailLines = [
    `To: ${to}`,
    `Subject: ${subject}`,
    'MIME-Version: 1.0',
    'Content-Type: text/plain; charset="UTF-8"',
    '',
    body,
  ];
  const email = emailLines.join('\r\n');

  // Base64Url encode the email string
  const encodedEmail = Buffer.from(email).toString('base64').replace(/\+/g, '-').replace(/\//g, '_').replace(/=+$/, '');

  try {
    const response = await gmail.users.messages.send({
      userId: 'me',
      requestBody: {
        raw: encodedEmail,
      },
    });
    res.status(200).json(response.data);
  } catch (error) {
    console.error('Error sending email:', error.message);
    res.status(500).send('Failed to send email.');
  }
});


// Calendar: List Events
app.get('/api/calendar/events', async (req, res) => {
  const calendar = google.calendar({ version: 'v3', auth: oauth2Client });
  try {
    const response = await calendar.events.list({
      calendarId: 'primary',
      timeMin: new Date().toISOString(),
      maxResults: 10,
      singleEvents: true,
      orderBy: 'startTime',
    });
    res.json(response.data.items || []);
  } catch (error) {
    console.error('Error listing Calendar events:', error.message);
    res.status(500).send('Failed to list events.');
  }
});

// Calendar: Create Event
app.post('/api/calendar/events', async (req, res) => {
  const { summary, description, start, end, attendees } = req.body;
  if (!summary || !start || !end) {
    return res.status(400).send('Missing required event fields (summary, start, end).');
  }

  const calendar = google.calendar({ version: 'v3', auth: oauth2Client });
  const event = {
    summary: summary,
    description: description,
    start: {
      dateTime: start.dateTime || start,
      timeZone: start.timeZone || 'Asia/Manila', // Default to current location timezone
    },
    end: {
      dateTime: end.dateTime || end,
      timeZone: end.timeZone || 'Asia/Manila',
    },
    attendees: attendees || [],
  };

  try {
    const response = await calendar.events.insert({
      calendarId: 'primary',
      resource: event,
    });
    res.status(201).json(response.data);
  } catch (error) {
    console.error('Error creating Calendar event:', error.message);
    res.status(500).send('Failed to create event.');
  }
});


// --- Server Start ---
app.listen(PORT, () => {
  console.log(`Server running on http://localhost:${PORT}`);
  console.log('Open http://localhost:3000/ to start the app.');
  console.log('Go to http://localhost:3000/auth/google to initiate OAuth if needed.');
});

4. public/index.html (Frontend Entry Point):
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Advanced Offline Workspace</title>
    <link rel="stylesheet" href="/styles.css">
</head>
<body>
    <header>
        <h1>My Advanced Workspace</h1>
        <div id="auth-status">
            <span id="online-status">Offline</span>
            <button id="auth-button">Login with Google</button>
            <button id="logout-button" style="display:none;">Logout</button>
        </div>
    </header>
    <main>
        <section id="drive-section">
            <h2>Google Drive Files</h2>
            <button id="refresh-drive">Refresh Online Files</button>
            <button id="offline-drive">View Offline Files</button>
            <input type="file" id="file-upload-input">
            <button id="upload-file">Upload File</button>
            <div id="drive-files">Loading...</div>
        </section>

        <section id="gmail-section">
            <h2>Gmail Messages</h2>
            <button id="refresh-gmail">Refresh Online Mail</button>
            <button id="offline-gmail">View Offline Mail</button>
            <button id="compose-email">Compose Email</button>
            <div id="gmail-messages">Loading...</div>
            <div id="email-compose-form" style="display: none;">
                <h3>Compose New Email</h3>
                <input type="text" id="email-to" placeholder="To">
                <input type="text" id="email-subject" placeholder="Subject">
                <textarea id="email-body" placeholder="Body"></textarea>
                <button id="send-email">Send</button>
                <button id="cancel-email">Cancel</button>
            </div>
        </section>

        <section id="calendar-section">
            <h2>Google Calendar Events</h2>
            <button id="refresh-calendar">Refresh Online Events</button>
            <button id="offline-calendar">View Offline Events</button>
            <button id="create-event">Create Event</button>
            <div id="calendar-events">Loading...</div>
            <div id="event-create-form" style="display: none;">
                <h3>Create New Event</h3>
                <input type="text" id="event-summary" placeholder="Summary">
                <input type="text" id="event-description" placeholder="Description">
                <label for="event-start">Start Time:</label>
                <input type="datetime-local" id="event-start">
                <label for="event-end">End Time:</label>
                <input type="datetime-local" id="event-end">
                <button id="save-event">Save Event</button>
                <button id="cancel-event">Cancel</button>
            </div>
        </section>
    </main>
    <script src="/main.js"></script>
    <script>
        // Register Service Worker
        if ('serviceWorker' in navigator) {
            window.addEventListener('load', () => {
                navigator.serviceWorker.register('/service-worker.js')
                    .then(registration => {
                        console.log('Service Worker registered with scope:', registration.scope);
                        // Optional: Request a background sync when network comes back online
                        // if ('SyncManager' in window) {
                        //     navigator.serviceWorker.ready.then(reg => {
                        //         reg.sync.register('initial-sync').catch(console.error);
                        //     });
                        // }
                    })
                    .catch(error => {
                        console.error('Service Worker registration failed:', error);
                    });
            });
        }
    </script>
</body>
</html>

5. public/styles.css (Basic Styling):
body {
    font-family: Arial, sans-serif;
    margin: 20px;
    background-color: #f4f4f4;
    color: #333;
}

header {
    display: flex;
    justify-content: space-between;
    align-items: center;
    background-color: #fff;
    padding: 15px 20px;
    border-bottom: 1px solid #eee;
    box-shadow: 0 2px 4px rgba(0,0,0,0.1);
}

h1, h2, h3 {
    color: #0056b3;
}

button {
    background-color: #007bff;
    color: white;
    padding: 8px 15px;
    border: none;
    border-radius: 4px;
    cursor: pointer;
    margin-right: 10px;
}

button:hover {
    background-color: #0056b3;
}

section {
    background-color: #fff;
    margin-top: 20px;
    padding: 20px;
    border-radius: 8px;
    box-shadow: 0 2px 4px rgba(0,0,0,0.1);
}

ul {
    list-style-type: none;
    padding: 0;
}

li {
    background-color: #f9f9f9;
    margin-bottom: 10px;
    padding: 10px;
    border-radius: 4px;
    border: 1px solid #ddd;
}

#auth-status {
    display: flex;
    align-items: center;
}

#online-status {
    margin-right: 15px;
    font-weight: bold;
    color: gray;
}

#online-status.online {
    color: green;
}

#online-status.offline {
    color: red;
}

input[type="text"],
input[type="datetime-local"],
textarea,
input[type="file"] {
    width: calc(100% - 22px);
    padding: 10px;
    margin-bottom: 10px;
    border: 1px solid #ccc;
    border-radius: 4px;
}

textarea {
    min-height: 100px;
    resize: vertical;
}

6. public/main.js (Frontend Logic - Simplified for brevity):
This file manages UI, IndexedDB for offline storage, and communicates with your Node.js backend.
// Function to handle network status updates
function updateOnlineStatus() {
    const statusEl = document.getElementById('online-status');
    if (navigator.onLine) {
        statusEl.textContent = 'Online';
        statusEl.classList.remove('offline');
        statusEl.classList.add('online');
    } else {
        statusEl.textContent = 'Offline';
        statusEl.classList.remove('online');
        statusEl.classList.add('offline');
    }
}

// Initial status check
updateOnlineStatus();
window.addEventListener('online', updateOnlineStatus);
window.addEventListener('offline', updateOnlineStatus);

// IndexedDB setup (using a helper function/library like Dexie.js in a real app)
let db;

function openIndexedDB() {
    return new Promise((resolve, reject) => {
        const request = indexedDB.open('GoogleWorkspaceData', 1);

        request.onupgradeneeded = (event) => {
            db = event.target.result;
            db.createObjectStore('driveFiles', { keyPath: 'id' });
            db.createObjectStore('gmailMessages', { keyPath: 'id' });
            db.createObjectStore('calendarEvents', { keyPath: 'id' });
            db.createObjectStore('pendingSync', { autoIncrement: true }); // For offline changes
            console.log('IndexedDB upgraded/created.');
        };

        request.onsuccess = (event) => {
            db = event.target.result;
            console.log('IndexedDB opened successfully.');
            resolve(db);
        };

        request.onerror = (event) => {
            console.error('IndexedDB error:', event.target.errorCode);
            reject(event.target.error);
        };
    });
}

// Global variable for authentication status
let isAuthenticated = false;

document.addEventListener('DOMContentLoaded', async () => {
    await openIndexedDB(); // Initialize IndexedDB when DOM is ready

    const authButton = document.getElementById('auth-button');
    const logoutButton = document.getElementById('logout-button');

    // Check for authentication success from URL parameter
    const urlParams = new URLSearchParams(window.location.search);
    if (urlParams.get('authSuccess') === 'true') {
        isAuthenticated = true;
        authButton.style.display = 'none';
        logoutButton.style.display = 'inline-block';
        console.log('Authenticated!');
        // Clear authSuccess param
        history.replaceState({}, document.title, window.location.pathname);
    }

    if (isAuthenticated) {
        loadDataOnline(); // Try to load data from online APIs
    }

    authButton.addEventListener('click', () => {
        window.location.href = '/auth/google'; // Redirect to Node.js OAuth endpoint
    });

    logoutButton.addEventListener('click', () => {
        // Invalidate token on server-side in a real app, clear local storage/session
        alert('Logging out is not fully implemented in this example (tokens on server persist).');
        isAuthenticated = false;
        authButton.style.display = 'inline-block';
        logoutButton.style.display = 'none';
        window.location.reload(); // Refresh to clear UI
    });

    // --- Data Fetching and Display Functions ---

    async function fetchData(apiEndpoint, storageName) {
        if (navigator.onLine && isAuthenticated) {
            try {
                const response = await fetch(apiEndpoint);
                if (!response.ok) {
                    throw new Error(`HTTP error! status: ${response.status}`);
                }
                const data = await response.json();
                console.log(`Fetched ${storageName} online:`, data);
                await saveToIndexedDB(storageName, data);
                displayData(storageName, data);
            } catch (error) {
                console.error(`Error fetching ${storageName} online:`, error);
                alert(`Failed to load ${storageName} online. Showing offline data if available.`);
                loadFromIndexedDB(storageName);
            }
        } else {
            console.log(`Offline or not authenticated. Loading ${storageName} from IndexedDB.`);
            loadFromIndexedDB(storageName);
        }
    }

    async function loadDataOnline() {
        if (!isAuthenticated) return;
        await fetchData('/api/drive/files', 'driveFiles');
        await fetchData('/api/gmail/messages', 'gmailMessages');
        await fetchData('/api/calendar/events', 'calendarEvents');
    }

    async function loadFromIndexedDB(storageName) {
        const transaction = db.transaction([storageName], 'readonly');
        const store = transaction.objectStore(storageName);
        const request = store.getAll();

        request.onsuccess = (event) => {
            const data = event.target.result;
            console.log(`Loaded ${storageName} from IndexedDB:`, data);
            displayData(storageName, data);
        };

        request.onerror = (event) => {
            console.error(`Error loading ${storageName} from IndexedDB:`, event.target.error);
        };
    }

    async function saveToIndexedDB(storageName, data) {
        const transaction = db.transaction([storageName], 'readwrite');
        const store = transaction.objectStore(storageName);
        for (const item of data) {
            store.put(item); // Use put for upsert (update if exists, insert if new)
        }
        await new Promise(resolve => transaction.oncomplete = resolve);
        console.log(`Saved ${data.length} items to ${storageName} in IndexedDB.`);
    }

    async function addToPendingSync(type, data) {
        const transaction = db.transaction(['pendingSync'], 'readwrite');
        const store = transaction.objectStore('pendingSync');
        store.add({ type, data, timestamp: new Date().toISOString() });
        await new Promise(resolve => transaction.oncomplete = resolve);
        console.log(`Added a ${type} operation to pending sync.`);

        // Request background sync
        if ('serviceWorker' in navigator && 'SyncManager' in window) {
            navigator.serviceWorker.ready.then(reg => {
                reg.sync.register('sync-pending-workspace-changes')
                    .then(() => console.log('Background sync registered for pending changes.'))
                    .catch(err => console.error('Background sync registration failed:', err));
            });
        } else {
            alert('Background Sync API not supported or service worker not ready. Sync will happen on next online app load.');
        }
    }


    function displayData(storageName, data) {
        const targetElement = document.getElementById(storageName.replace('s', '-')); // e.g., 'drive-files'
        if (!targetElement) return;

        targetElement.innerHTML = ''; // Clear previous content

        if (data.length === 0) {
            targetElement.innerHTML = '<p>No data found.</p>';
            return;
        }

        const ul = document.createElement('ul');
        data.forEach(item => {
            const li = document.createElement('li');
            if (storageName === 'driveFiles') {
                li.innerHTML = `<strong>${item.name}</strong> (${item.mimeType}) - Modified: ${new Date(item.modifiedTime).toLocaleDateString()}`;
                // Add a download button for Drive files
                const downloadBtn = document.createElement('button');
                downloadBtn.textContent = 'Download';
                downloadBtn.onclick = async () => {
                    if (navigator.onLine) {
                        try {
                            const response = await fetch(`/api/drive/files/${item.id}/download`);
                            if (!response.ok) throw new Error('Download failed');
                            const blob = await response.blob();
                            const url = URL.createObjectURL(blob);
                            const a = document.createElement('a');
                            a.href = url;
                            a.download = item.name;
                            document.body.appendChild(a);
                            a.click();
                            document.body.removeChild(a);
                            URL.revokeObjectURL(url);
                        } catch (e) {
                            console.error('Error downloading:', e);
                            alert('Failed to download file online. Try again later.');
                        }
                    } else {
                        alert('Cannot download file when offline.');
                        // In a real app, you might have pre-downloaded content
                    }
                };
                li.appendChild(downloadBtn);
            } else if (storageName === 'gmailMessages') {
                const subject = item.payload?.headers?.find(h => h.name === 'Subject')?.value || 'No Subject';
                const from = item.payload?.headers?.find(h => h.name === 'From')?.value || 'Unknown Sender';
                li.innerHTML = `<strong>${subject}</strong> - From: ${from}`;
            } else if (storageName === 'calendarEvents') {
                const start = new Date(item.start.dateTime || item.start.date).toLocaleString();
                const end = new Date(item.end.dateTime || item.end.date).toLocaleString();
                li.innerHTML = `<strong>${item.summary}</strong><br><em>${item.description || ''}</em><br>Starts: ${start}<br>Ends: ${end}`;
            }
            ul.appendChild(li);
        });
        targetElement.appendChild(ul);
    }

    // --- Event Listeners for UI Actions ---

    document.getElementById('refresh-drive').addEventListener('click', () => fetchData('/api/drive/files', 'driveFiles'));
    document.getElementById('offline-drive').addEventListener('click', () => loadFromIndexedDB('driveFiles'));

    document.getElementById('upload-file').addEventListener('click', async () => {
        const fileInput = document.getElementById('file-upload-input');
        const file = fileInput.files[0];
        if (!file) {
            alert('Please select a file to upload.');
            return;
        }

        const reader = new FileReader();
        reader.onload = async (event) => {
            const base64Content = event.target.result.split(',')[1]; // Get base64 string without prefix

            const fileData = {
                fileName: file.name,
                mimeType: file.type,
                base64Content: base64Content,
            };

            if (navigator.onLine && isAuthenticated) {
                try {
                    const response = await fetch('/api/drive/files/upload', {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' },
                        body: JSON.stringify(fileData),
                    });
                    if (!response.ok) throw new Error('File upload failed.');
                    const uploadedFile = await response.json();
                    alert(`File "${uploadedFile.name}" uploaded successfully!`);
                    await fetchData('/api/drive/files', 'driveFiles'); // Refresh list
                } catch (error) {
                    console.error('Online upload failed:', error);
                    alert('Online upload failed. Saving for offline sync.');
                    await addToPendingSync('file_upload', fileData);
                }
            } else {
                alert('Offline. File queued for upload when online.');
                await addToPendingSync('file_upload', fileData);
            }
        };
        reader.readAsDataURL(file); // Read file as base64
    });

    document.getElementById('refresh-gmail').addEventListener('click', () => fetchData('/api/gmail/messages', 'gmailMessages'));
    document.getElementById('offline-gmail').addEventListener('click', () => loadFromIndexedDB('gmailMessages'));

    document.getElementById('compose-email').addEventListener('click', () => {
        document.getElementById('email-compose-form').style.display = 'block';
    });
    document.getElementById('cancel-email').addEventListener('click', () => {
        document.getElementById('email-compose-form').style.display = 'none';
        document.getElementById('email-to').value = '';
        document.getElementById('email-subject').value = '';
        document.getElementById('email-body').value = '';
    });
    document.getElementById('send-email').addEventListener('click', async () => {
        const to = document.getElementById('email-to').value;
        const subject = document.getElementById('email-subject').value;
        const body = document.getElementById('email-body').value;

        const emailData = { to, subject, body };

        if (!to || !subject || !body) {
            alert('Please fill in all email fields.');
            return;
        }

        if (navigator.onLine && isAuthenticated) {
            try {
                const response = await fetch('/api/gmail/send', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(emailData),
                });
                if (!response.ok) throw new Error('Email send failed.');
                alert('Email sent successfully!');
                document.getElementById('email-compose-form').style.display = 'none';
                await fetchData('/api/gmail/messages', 'gmailMessages'); // Refresh list
            } catch (error) {
                console.error('Online email send failed:', error);
                alert('Online email send failed. Saving for offline sync.');
                await addToPendingSync('email_send', emailData);
            }
        } else {
            alert('Offline. Email queued for sending when online.');
            await addToPendingSync('email_send', emailData);
        }
    });

    document.getElementById('refresh-calendar').addEventListener('click', () => fetchData('/api/calendar/events', 'calendarEvents'));
    document.getElementById('offline-calendar').addEventListener('click', () => loadFromIndexedDB('calendarEvents'));

    document.getElementById('create-event').addEventListener('click', () => {
        document.getElementById('event-create-form').style.display = 'block';
    });
    document.getElementById('cancel-event').addEventListener('click', () => {
        document.getElementById('event-create-form').style.display = 'none';
        document.getElementById('event-summary').value = '';
        document.getElementById('event-description').value = '';
        document.getElementById('event-start').value = '';
        document.getElementById('event-end').value = '';
    });
    document.getElementById('save-event').addEventListener('click', async () => {
        const summary = document.getElementById('event-summary').value;
        const description = document.getElementById('event-description').value;
        const start = document.getElementById('event-start').value;
        const end = document.getElementById('event-end').value;

        const eventData = { summary, description, start, end };

        if (!summary || !start || !end) {
            alert('Please fill in all required event fields (summary, start, end).');
            return;
        }

        if (navigator.onLine && isAuthenticated) {
            try {
                const response = await fetch('/api/calendar/events', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(eventData),
                });
                if (!response.ok) throw new Error('Event creation failed.');
                alert('Event created successfully!');
                document.getElementById('event-create-form').style.display = 'none';
                await fetchData('/api/calendar/events', 'calendarEvents'); // Refresh list
            } catch (error) {
                console.error('Online event creation failed:', error);
                alert('Online event creation failed. Saving for offline sync.');
                await addToPendingSync('calendar_create', eventData);
            }
        } else {
            alert('Offline. Event queued for creation when online.');
            await addToPendingSync('calendar_create', eventData);
        }
    });
});

7. public/service-worker.js (Service Worker):
This manages caching and background sync for offline operations.
const CACHE_NAME = 'advanced-workspace-cache-v1';
const DATA_CACHE_NAME = 'advanced-workspace-data-cache-v1'; // For API responses (consider strategies)

const urlsToCache = [
  '/',
  '/index.html',
  '/styles.css',
  '/main.js',
];

self.addEventListener('install', (event) => {
  event.waitUntil(
    caches.open(CACHE_NAME)
      .then((cache) => {
        console.log('Service Worker: Caching app shell assets');
        return cache.addAll(urlsToCache);
      })
  );
});

self.addEventListener('activate', (event) => {
  event.waitUntil(
    caches.keys().then((cacheNames) => {
      return Promise.all(
        cacheNames.map((cacheName) => {
          if (cacheName !== CACHE_NAME && cacheName !== DATA_CACHE_NAME) {
            console.log('Service Worker: Deleting old cache:', cacheName);
            return caches.delete(cacheName);
          }
        })
      );
    })
  );
  self.clients.claim(); // Ensures the service worker controls clients immediately
});

self.addEventListener('fetch', (event) => {
  // Strategy: Cache-First for app shell, Network-First with Cache Fallback for APIs
  if (urlsToCache.includes(event.request.url.split('?')[0])) { // Cache-First for static assets
    event.respondWith(
      caches.match(event.request)
        .then((response) => {
          return response || fetch(event.request);
        })
    );
  } else if (event.request.url.startsWith(self.location.origin + '/api/')) {
    // For API calls, try network first, then fallback to cache (if data was cached before)
    // This is a simplistic approach. For real apps, you'd implement specific strategies
    // like Cache-then-Network or Stale-While-Revalidate.
    event.respondWith(
      fetch(event.request)
        .then(async (response) => {
          // If response is good, clone it and put in cache
          const responseToCache = response.clone();
          const cache = await caches.open(DATA_CACHE_NAME);
          cache.put(event.request, responseToCache);
          return response;
        })
        .catch(async () => {
          // Network failed, try to get from cache
          const cachedResponse = await caches.match(event.request);
          if (cachedResponse) {
            return cachedResponse;
          }
          // If not in cache and offline, throw error
          throw new Error('No network and no cached data.');
        })
    );
  } else {
    // Default to network-first for other requests
    event.respondWith(fetch(event.request));
  }
});

// --- Background Sync ---
self.addEventListener('sync', (event) => {
  if (event.tag === 'sync-pending-workspace-changes') {
    console.log('Service Worker: Performing background sync for pending changes...');
    event.waitUntil(syncPendingWorkspaceChanges());
  }
});

async function syncPendingWorkspaceChanges() {
    let db;
    try {
        // Re-open IndexedDB connection within the service worker context
        db = await new Promise((resolve, reject) => {
            const request = indexedDB.open('GoogleWorkspaceData', 1);
            request.onsuccess = (e) => resolve(e.target.result);
            request.onerror = (e) => reject(e.target.error);
            request.onupgradeneeded = (e) => {
                // Should not happen during sync, as DB should be established
                console.warn('IndexedDB upgrade needed during sync. This is unexpected.');
                e.target.transaction.abort();
            };
        });

        const transaction = db.transaction(['pendingSync'], 'readwrite');
        const store = transaction.objectStore('pendingSync');
        const pendingChanges = await store.getAll();

        for (const change of pendingChanges) {
            console.log('Processing pending change:', change.type, change.data);
            try {
                let apiResponse;
                switch (change.type) {
                    case 'file_upload':
                        apiResponse = await fetch('/api/drive/files/upload', {
                            method: 'POST',
                            headers: { 'Content-Type': 'application/json' },
                            body: JSON.stringify(change.data),
                        });
                        break;
                    case 'email_send':
                        apiResponse = await fetch('/api/gmail/send', {
                            method: 'POST',
                            headers: { 'Content-Type': 'application/json' },
                            body: JSON.stringify(change.data),
                        });
                        break;
                    case 'calendar_create':
                        apiResponse = await fetch('/api/calendar/events', {
                            method: 'POST',
                            headers: { 'Content-Type': 'application/json' },
                            body: JSON.stringify(change.data),
                        });
                        break;
                    // Add more cases for other types of offline operations (edit, delete, etc.)
                    default:
                        console.warn('Unknown pending change type:', change.type);
                        continue;
                }

                if (apiResponse.ok) {
                    console.log(`Successfully synced ${change.type} operation.`);
                    store.delete(change.id); // Remove from pending queue
                    // Optionally, update main app's cache of data after successful sync
                    // e.g., fetch the latest data from API and save to respective IndexedDB store
                } else {
                    const errorText = await apiResponse.text();
                    console.error(`Failed to sync ${change.type}:`, apiResponse.status, errorText);
                    // Do not delete from queue, it will be retried later
                }
            } catch (error) {
                console.error(`Network error during ${change.type} sync:`, error);
                // Do not delete from queue, it will be retried later
            }
        }
        await new Promise(resolve => transaction.oncomplete = resolve); // Ensure transaction completes
        console.log('Service Worker: Background sync completed.');
    } catch (error) {
        console.error('Service Worker: Error during background sync process:', error);
        // If DB access fails, subsequent syncs might be needed
    } finally {
        if (db) db.close(); // Close DB connection
    }
}

How to Run:
 * Set up Google Cloud Project: Follow the OAuth credential steps above.
 * Clone/Create Project: Set up the my-workspace-app directory structure.
 * Place Credentials: Put your credentials.json and .env files in the root.
 * Install Dependencies: npm install in your project root.
 * Start Server: node server.js
 * Access: Open your browser to http://localhost:3000/.
 * Authenticate: Click "Login with Google" and complete the OAuth flow.
 * Test Offline: Once authenticated and some data is loaded, go offline (e.g., turn off Wi-Fi, or in Chrome DevTools under "Application" > "Service Workers", check "Offline"). Perform actions like uploading a file or sending an email. Then go back online and observe the background sync.
Key Features Implemented (Conceptual):
 * OAuth 2.0 with Node.js Backend: Securely handles user authentication and token management (access and refresh tokens).
 * API Proxying: Node.js server acts as a proxy, making Google API calls on behalf of the client, protecting your API secrets.
 * Service Worker for Asset Caching: Ensures your PWA loads instantly even when offline.
 * IndexedDB for Offline Data Storage: Stores Google Workspace data (Drive files, Gmail messages, Calendar events) locally.
 * Offline Operation Queuing: When offline, actions like file uploads, email sends, or event creations are stored in a pendingSync IndexedDB object store.
 * Background Sync API: Leverages the browser's Background Sync API (via Service Worker) to automatically retry pending offline actions when connectivity is restored, even if the user has closed the tab.
 * Basic API Integrations: Illustrative examples for Google Drive (list, download, upload), Gmail (list, send), and Calendar (list, create).
Advanced Considerations (Beyond this Example):
 * Robust Error Handling: More sophisticated error logging, user notifications, and retry strategies.
 * Conflict Resolution: What happens if a file is edited offline and also online? You'd need a merge strategy or to alert the user.
 * Delta Sync: For Drive, use the Drive API's changes endpoint to fetch only modified files efficiently, rather than full lists.
 * Webhooks/Push Notifications: Use Google Drive change notifications (Webhooks) to instantly alert your Node.js backend when a change occurs in a user's Drive, allowing for near real-time sync.
 * Bi-directional Sync: This example focuses on pushing offline changes online. A complete solution would also pull changes from Google Workspace and update local IndexedDB.
 * User-Specific IndexedDB: In a multi-user application, ensure each user's offline data is isolated (e.g., by using a user-ID prefixed database name).
 * Streaming File Uploads/Downloads: For large files, stream data directly between the client, Node.js, and Google Drive API for better performance and memory management.
 * UI/UX: Provide clear visual cues about online/offline status, sync progress, and any pending actions.
 * Scalability: For a production app, consider using a database (e.g., MongoDB, PostgreSQL) on the backend to store user tokens, sync states, and potentially metadata.
 * Security Best Practices: Regularly review Google's security guidelines for API usage and OAuth implementation.


{
  "web": {
    "client_id": "YOUR_CLIENT_ID.apps.googleusercontent.com",
    "project_id": "your-project-id",
    "auth_uri": "https://accounts.google.com/o/oauth2/auth",
    "token_uri": "https://oauth2.googleapis.com/token",
    "auth_provider_x509_cert_url": "https://www.googleapis.com/oauth2/v1/certs",
    "client_secret": "YOUR_CLIENT_SECRET",
    "redirect_uris": ["http://localhost:3000/oauth2callback"]
  }
}



Building an "advanced online/offline Google Workspace" solution with Node.js typically involves a hybrid architecture:
 * Frontend (Browser-based PWA): This is where the true "offline" capabilities reside, utilizing Service Workers and IndexedDB. Node.js is primarily used to serve this frontend application and act as a backend for API interactions.
 * Backend (Node.js Server): This handles:
   * OAuth 2.0 Flow: Securely authenticating users with Google.
   * Google API Interactions: Making requests to Google Drive, Gmail, Calendar APIs on behalf of the user. This is crucial because directly exposing sensitive API keys/secrets in the frontend is a security risk.
   * Data Synchronization Logic: Managing the sync process between client-side IndexedDB and Google Workspace APIs.
   * Real-time Updates (Optional): Using WebSockets to push changes from Google Workspace to connected clients (e.g., via Drive API change notifications).
Here's a conceptual Node.js code structure, focusing on the backend server's role in facilitating an advanced online/offline Google Workspace experience.
Prerequisites:
 * Google Cloud Project: Create a project in the Google Cloud Console.
 * Enable APIs: Enable the Google Drive API, Gmail API, and Calendar API for your project.
 * OAuth 2.0 Credentials:
   * Go to APIs & Services > Credentials.
   * Create an "OAuth client ID."
   * Select "Web application" as the application type.
   * Set Authorized JavaScript origins (e.g., http://localhost:3000 for development).
   * Set Authorized redirect URIs (e.g., http://localhost:3000/oauth2callback).
   * Download the JSON credentials file (rename it to credentials.json and place it in your Node.js project root).
 * Node.js Environment:
   * Node.js installed.
   * npm init -y in your project folder.
   * Install necessary packages: npm install express googleapis google-auth-library body-parser dotenv
Project Structure:
my-workspace-app/
├── public/                 // Your frontend PWA files (index.html, service-worker.js, main.js, etc.)
│   ├── index.html
│   ├── styles.css
│   ├── main.js             // Frontend JS for IndexedDB, UI, and API calls to your Node.js backend
│   └── service-worker.js   // Service Worker for caching and background sync
├── credentials.json        // Your Google OAuth credentials
├── .env                    // Environment variables (CLIENT_ID, CLIENT_SECRET, REDIRECT_URI)
├── server.js               // Main Node.js server file
├── package.json
└── package-lock.json

1. credentials.json (Example Structure):
(Do NOT commit this file to public repositories!)
{
  "web": {
    "client_id": "YOUR_CLIENT_ID.apps.googleusercontent.com",
    "project_id": "your-project-id",
    "auth_uri": "https://accounts.google.com/o/oauth2/auth",
    "token_uri": "https://oauth2.googleapis.com/token",
    "auth_provider_x509_cert_url": "https://www.googleapis.com/oauth2/v1/certs",
    "client_secret": "YOUR_CLIENT_SECRET",
    "redirect_uris": ["http://localhost:3000/oauth2callback"]
  }
}

2. .env (Example Structure):
(Do NOT commit this file to public repositories!)
CLIENT_ID=YOUR_CLIENT_ID.apps.googleusercontent.com
CLIENT_SECRET=YOUR_CLIENT_SECRET
REDIRECT_URI=http://localhost:3000/oauth2callback

3. server.js (Node.js Backend):
This server will handle OAuth, serve static files, and provide API endpoints for your frontend to interact with Google Workspace.
require('dotenv').config(); // Load environment variables from .env
const express = require('express');
const { google } = require('googleapis');
const fs = require('fs').promises; // Use promises version of fs
const path = require('path');
const bodyParser = require('body-parser');

const app = express();
const PORT = process.env.PORT || 3000;

// Middleware
app.use(bodyParser.json());
app.use(express.static('public')); // Serve your frontend PWA from the 'public' directory

// --- Google OAuth2 Setup ---
const credentials = require('./credentials.json').web;
const { client_id, client_secret, redirect_uris } = credentials;
const redirect_uri = process.env.REDIRECT_URI || redirect_uris[0]; // Use env var for flexibility

const oauth2Client = new google.auth.OAuth2(
  client_id,
  client_secret,
  redirect_uri
);

// Define the scopes your application needs.
// For advanced offline, you'll need comprehensive scopes.
const SCOPES = [
  'https://www.googleapis.com/auth/drive', // Full Drive access
  'https://www.googleapis.com/auth/gmail.modify', // Send, delete, and modify your email
  'https://www.googleapis.com/auth/calendar', // Manage calendars
  'https://www.googleapis.com/auth/userinfo.profile', // User profile info
  'https://www.googleapis.com/auth/userinfo.email', // User email address
  'openid'
];

// --- OAuth Routes ---

// 1. Redirect user to Google for authentication
app.get('/auth/google', (req, res) => {
  const authorizeUrl = oauth2Client.generateAuthUrl({
    access_type: 'offline', // IMPORTANT for getting a refresh token
    scope: SCOPES,
    prompt: 'consent' // Forces user to re-consent, ensuring refresh token if lost
  });
  res.redirect(authorizeUrl);
});

// 2. Google redirects back to this endpoint after user grants permission
app.get('/oauth2callback', async (req, res) => {
  const { code } = req.query;
  try {
    const { tokens } = await oauth2Client.getToken(code);
    oauth2Client.setCredentials(tokens);

    // Store tokens securely. In a real app, you'd store this in a database
    // associated with the user. For this example, we'll store it in memory.
    // For a multi-user app, you'd associate tokens with a session or user ID.
    app.set('googleTokens', tokens); // Storing in app locals for simplicity (NOT PRODUCTION SAFE)

    // Redirect back to your frontend, maybe with a success message or
    // to a dashboard page.
    res.redirect('/?authSuccess=true');
  } catch (error) {
    console.error('Error retrieving access token:', error.message);
    res.status(500).send('Authentication failed.');
  }
});

// Middleware to ensure user is authenticated for Google API calls
app.use(async (req, res, next) => {
  const tokens = app.get('googleTokens'); // Retrieve tokens
  if (!tokens) {
    return res.status(401).send('Not authenticated. Please log in first.');
  }

  oauth2Client.setCredentials(tokens);

  // Check if access token is expired and refresh if needed
  if (oauth2Client.isTokenExpiring()) {
    try {
      const { credentials } = await oauth2Client.refreshAccessToken();
      oauth2Client.setCredentials(credentials);
      app.set('googleTokens', credentials); // Update stored tokens
      console.log('Access token refreshed successfully!');
    } catch (error) {
      console.error('Error refreshing access token:', error.message);
      // If refresh fails, user needs to re-authenticate
      app.set('googleTokens', null); // Clear invalid tokens
      return res.status(401).send('Session expired. Please re-authenticate.');
    }
  }
  next(); // Continue to the API route
});

// --- Google Workspace API Endpoints (Accessed by Frontend) ---

// Drive: List Files
app.get('/api/drive/files', async (req, res) => {
  const drive = google.drive({ version: 'v3', auth: oauth2Client });
  try {
    const response = await drive.files.list({
      pageSize: 10,
      fields: 'nextPageToken, files(id, name, mimeType, modifiedTime)',
    });
    res.json(response.data.files);
  } catch (error) {
    console.error('Error listing Drive files:', error.message);
    res.status(500).send('Failed to list files.');
  }
});

// Drive: Download File Content
app.get('/api/drive/files/:fileId/download', async (req, res) => {
    const { fileId } = req.params;
    const drive = google.drive({ version: 'v3', auth: oauth2Client });
    try {
        const response = await drive.files.get(
            { fileId: fileId, alt: 'media' },
            { responseType: 'stream' }
        );

        // Set appropriate headers for download
        const fileMetadata = await drive.files.get({ fileId: fileId, fields: 'name, mimeType' });
        res.setHeader('Content-Type', fileMetadata.data.mimeType);
        res.setHeader('Content-Disposition', `attachment; filename="${fileMetadata.data.name}"`);

        response.data.pipe(res); // Pipe the file stream directly to the response
    } catch (error) {
        console.error('Error downloading Drive file:', error.message);
        res.status(500).send('Failed to download file.');
    }
});

// Drive: Upload File (from frontend blob/buffer)
app.post('/api/drive/files/upload', async (req, res) => {
  // In a real app, handle file uploads more robustly, e.g., with 'multer'
  // For simplicity, assuming req.body contains { fileName, mimeType, base64Content }
  const { fileName, mimeType, base64Content } = req.body;
  if (!fileName || !mimeType || !base64Content) {
    return res.status(400).send('Missing file data.');
  }

  const drive = google.drive({ version: 'v3', auth: oauth2Client });
  const fileBuffer = Buffer.from(base64Content, 'base64'); // Convert base64 to buffer

  try {
    const response = await drive.files.create({
      requestBody: {
        name: fileName,
        mimeType: mimeType,
      },
      media: {
        mimeType: mimeType,
        body: fileBuffer, // Use the buffer directly
      },
      fields: 'id, name, mimeType',
    });
    res.status(200).json(response.data);
  } catch (error) {
    console.error('Error uploading Drive file:', error.message);
    res.status(500).send('Failed to upload file.');
  }
});

// Gmail: List Messages
app.get('/api/gmail/messages', async (req, res) => {
  const gmail = google.gmail({ version: 'v1', auth: oauth2Client });
  try {
    const response = await gmail.users.messages.list({
      userId: 'me',
      maxResults: 10,
    });
    res.json(response.data.messages || []);
  } catch (error) {
    console.error('Error listing Gmail messages:', error.message);
    res.status(500).send('Failed to list messages.');
  }
});

// Gmail: Get Message Content (Full)
app.get('/api/gmail/messages/:messageId', async (req, res) => {
  const { messageId } = req.params;
  const gmail = google.gmail({ version: 'v1', auth: oauth2Client });
  try {
    const response = await gmail.users.messages.get({
      userId: 'me',
      id: messageId,
      format: 'full' // or 'raw', 'minimal', 'metadata'
    });
    res.json(response.data);
  } catch (error) {
    console.error('Error getting Gmail message:', error.message);
    res.status(500).send('Failed to get message content.');
  }
});

// Gmail: Send Email
app.post('/api/gmail/send', async (req, res) => {
  const { to, subject, body } = req.body;
  if (!to || !subject || !body) {
    return res.status(400).send('Missing required email fields (to, subject, body).');
  }

  const gmail = google.gmail({ version: 'v1', auth: oauth2Client });

  // Create a raw email string in RFC 2822 format
  const emailLines = [
    `To: ${to}`,
    `Subject: ${subject}`,
    'MIME-Version: 1.0',
    'Content-Type: text/plain; charset="UTF-8"',
    '',
    body,
  ];
  const email = emailLines.join('\r\n');

  // Base64Url encode the email string
  const encodedEmail = Buffer.from(email).toString('base64').replace(/\+/g, '-').replace(/\//g, '_').replace(/=+$/, '');

  try {
    const response = await gmail.users.messages.send({
      userId: 'me',
      requestBody: {
        raw: encodedEmail,
      },
    });
    res.status(200).json(response.data);
  } catch (error) {
    console.error('Error sending email:', error.message);
    res.status(500).send('Failed to send email.');
  }
});


// Calendar: List Events
app.get('/api/calendar/events', async (req, res) => {
  const calendar = google.calendar({ version: 'v3', auth: oauth2Client });
  try {
    const response = await calendar.events.list({
      calendarId: 'primary',
      timeMin: new Date().toISOString(),
      maxResults: 10,
      singleEvents: true,
      orderBy: 'startTime',
    });
    res.json(response.data.items || []);
  } catch (error) {
    console.error('Error listing Calendar events:', error.message);
    res.status(500).send('Failed to list events.');
  }
});

// Calendar: Create Event
app.post('/api/calendar/events', async (req, res) => {
  const { summary, description, start, end, attendees } = req.body;
  if (!summary || !start || !end) {
    return res.status(400).send('Missing required event fields (summary, start, end).');
  }

  const calendar = google.calendar({ version: 'v3', auth: oauth2Client });
  const event = {
    summary: summary,
    description: description,
    start: {
      dateTime: start.dateTime || start,
      timeZone: start.timeZone || 'Asia/Manila', // Default to current location timezone
    },
    end: {
      dateTime: end.dateTime || end,
      timeZone: end.timeZone || 'Asia/Manila',
    },
    attendees: attendees || [],
  };

  try {
    const response = await calendar.events.insert({
      calendarId: 'primary',
      resource: event,
    });
    res.status(201).json(response.data);
  } catch (error) {
    console.error('Error creating Calendar event:', error.message);
    res.status(500).send('Failed to create event.');
  }
});


// --- Server Start ---
app.listen(PORT, () => {
  console.log(`Server running on http://localhost:${PORT}`);
  console.log('Open http://localhost:3000/ to start the app.');
  console.log('Go to http://localhost:3000/auth/google to initiate OAuth if needed.');
});

4. public/index.html (Frontend Entry Point):
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Advanced Offline Workspace</title>
    <link rel="stylesheet" href="/styles.css">
</head>
<body>
    <header>
        <h1>My Advanced Workspace</h1>
        <div id="auth-status">
            <span id="online-status">Offline</span>
            <button id="auth-button">Login with Google</button>
            <button id="logout-button" style="display:none;">Logout</button>
        </div>
    </header>
    <main>
        <section id="drive-section">
            <h2>Google Drive Files</h2>
            <button id="refresh-drive">Refresh Online Files</button>
            <button id="offline-drive">View Offline Files</button>
            <input type="file" id="file-upload-input">
            <button id="upload-file">Upload File</button>
            <div id="drive-files">Loading...</div>
        </section>

        <section id="gmail-section">
            <h2>Gmail Messages</h2>
            <button id="refresh-gmail">Refresh Online Mail</button>
            <button id="offline-gmail">View Offline Mail</button>
            <button id="compose-email">Compose Email</button>
            <div id="gmail-messages">Loading...</div>
            <div id="email-compose-form" style="display: none;">
                <h3>Compose New Email</h3>
                <input type="text" id="email-to" placeholder="To">
                <input type="text" id="email-subject" placeholder="Subject">
                <textarea id="email-body" placeholder="Body"></textarea>
                <button id="send-email">Send</button>
                <button id="cancel-email">Cancel</button>
            </div>
        </section>

        <section id="calendar-section">
            <h2>Google Calendar Events</h2>
            <button id="refresh-calendar">Refresh Online Events</button>
            <button id="offline-calendar">View Offline Events</button>
            <button id="create-event">Create Event</button>
            <div id="calendar-events">Loading...</div>
            <div id="event-create-form" style="display: none;">
                <h3>Create New Event</h3>
                <input type="text" id="event-summary" placeholder="Summary">
                <input type="text" id="event-description" placeholder="Description">
                <label for="event-start">Start Time:</label>
                <input type="datetime-local" id="event-start">
                <label for="event-end">End Time:</label>
                <input type="datetime-local" id="event-end">
                <button id="save-event">Save Event</button>
                <button id="cancel-event">Cancel</button>
            </div>
        </section>
    </main>
    <script src="/main.js"></script>
    <script>
        // Register Service Worker
        if ('serviceWorker' in navigator) {
            window.addEventListener('load', () => {
                navigator.serviceWorker.register('/service-worker.js')
                    .then(registration => {
                        console.log('Service Worker registered with scope:', registration.scope);
                        // Optional: Request a background sync when network comes back online
                        // if ('SyncManager' in window) {
                        //     navigator.serviceWorker.ready.then(reg => {
                        //         reg.sync.register('initial-sync').catch(console.error);
                        //     });
                        // }
                    })
                    .catch(error => {
                        console.error('Service Worker registration failed:', error);
                    });
            });
        }
    </script>
</body>
</html>

5. public/styles.css (Basic Styling):
body {
    font-family: Arial, sans-serif;
    margin: 20px;
    background-color: #f4f4f4;
    color: #333;
}

header {
    display: flex;
    justify-content: space-between;
    align-items: center;
    background-color: #fff;
    padding: 15px 20px;
    border-bottom: 1px solid #eee;
    box-shadow: 0 2px 4px rgba(0,0,0,0.1);
}

h1, h2, h3 {
    color: #0056b3;
}

button {
    background-color: #007bff;
    color: white;
    padding: 8px 15px;
    border: none;
    border-radius: 4px;
    cursor: pointer;
    margin-right: 10px;
}

button:hover {
    background-color: #0056b3;
}

section {
    background-color: #fff;
    margin-top: 20px;
    padding: 20px;
    border-radius: 8px;
    box-shadow: 0 2px 4px rgba(0,0,0,0.1);
}

ul {
    list-style-type: none;
    padding: 0;
}

li {
    background-color: #f9f9f9;
    margin-bottom: 10px;
    padding: 10px;
    border-radius: 4px;
    border: 1px solid #ddd;
}

#auth-status {
    display: flex;
    align-items: center;
}

#online-status {
    margin-right: 15px;
    font-weight: bold;
    color: gray;
}

#online-status.online {
    color: green;
}

#online-status.offline {
    color: red;
}

input[type="text"],
input[type="datetime-local"],
textarea,
input[type="file"] {
    width: calc(100% - 22px);
    padding: 10px;
    margin-bottom: 10px;
    border: 1px solid #ccc;
    border-radius: 4px;
}

textarea {
    min-height: 100px;
    resize: vertical;
}

6. public/main.js (Frontend Logic - Simplified for brevity):
This file manages UI, IndexedDB for offline storage, and communicates with your Node.js backend.
// Function to handle network status updates
function updateOnlineStatus() {
    const statusEl = document.getElementById('online-status');
    if (navigator.onLine) {
        statusEl.textContent = 'Online';
        statusEl.classList.remove('offline');
        statusEl.classList.add('online');
    } else {
        statusEl.textContent = 'Offline';
        statusEl.classList.remove('online');
        statusEl.classList.add('offline');
    }
}

// Initial status check
updateOnlineStatus();
window.addEventListener('online', updateOnlineStatus);
window.addEventListener('offline', updateOnlineStatus);

// IndexedDB setup (using a helper function/library like Dexie.js in a real app)
let db;

function openIndexedDB() {
    return new Promise((resolve, reject) => {
        const request = indexedDB.open('GoogleWorkspaceData', 1);

        request.onupgradeneeded = (event) => {
            db = event.target.result;
            db.createObjectStore('driveFiles', { keyPath: 'id' });
            db.createObjectStore('gmailMessages', { keyPath: 'id' });
            db.createObjectStore('calendarEvents', { keyPath: 'id' });
            db.createObjectStore('pendingSync', { autoIncrement: true }); // For offline changes
            console.log('IndexedDB upgraded/created.');
        };

        request.onsuccess = (event) => {
            db = event.target.result;
            console.log('IndexedDB opened successfully.');
            resolve(db);
        };

        request.onerror = (event) => {
            console.error('IndexedDB error:', event.target.errorCode);
            reject(event.target.error);
        };
    });
}

// Global variable for authentication status
let isAuthenticated = false;

document.addEventListener('DOMContentLoaded', async () => {
    await openIndexedDB(); // Initialize IndexedDB when DOM is ready

    const authButton = document.getElementById('auth-button');
    const logoutButton = document.getElementById('logout-button');

    // Check for authentication success from URL parameter
    const urlParams = new URLSearchParams(window.location.search);
    if (urlParams.get('authSuccess') === 'true') {
        isAuthenticated = true;
        authButton.style.display = 'none';
        logoutButton.style.display = 'inline-block';
        console.log('Authenticated!');
        // Clear authSuccess param
        history.replaceState({}, document.title, window.location.pathname);
    }

    if (isAuthenticated) {
        loadDataOnline(); // Try to load data from online APIs
    }

    authButton.addEventListener('click', () => {
        window.location.href = '/auth/google'; // Redirect to Node.js OAuth endpoint
    });

    logoutButton.addEventListener('click', () => {
        // Invalidate token on server-side in a real app, clear local storage/session
        alert('Logging out is not fully implemented in this example (tokens on server persist).');
        isAuthenticated = false;
        authButton.style.display = 'inline-block';
        logoutButton.style.display = 'none';
        window.location.reload(); // Refresh to clear UI
    });

    // --- Data Fetching and Display Functions ---

    async function fetchData(apiEndpoint, storageName) {
        if (navigator.onLine && isAuthenticated) {
            try {
                const response = await fetch(apiEndpoint);
                if (!response.ok) {
                    throw new Error(`HTTP error! status: ${response.status}`);
                }
                const data = await response.json();
                console.log(`Fetched ${storageName} online:`, data);
                await saveToIndexedDB(storageName, data);
                displayData(storageName, data);
            } catch (error) {
                console.error(`Error fetching ${storageName} online:`, error);
                alert(`Failed to load ${storageName} online. Showing offline data if available.`);
                loadFromIndexedDB(storageName);
            }
        } else {
            console.log(`Offline or not authenticated. Loading ${storageName} from IndexedDB.`);
            loadFromIndexedDB(storageName);
        }
    }

    async function loadDataOnline() {
        if (!isAuthenticated) return;
        await fetchData('/api/drive/files', 'driveFiles');
        await fetchData('/api/gmail/messages', 'gmailMessages');
        await fetchData('/api/calendar/events', 'calendarEvents');
    }

    async function loadFromIndexedDB(storageName) {
        const transaction = db.transaction([storageName], 'readonly');
        const store = transaction.objectStore(storageName);
        const request = store.getAll();

        request.onsuccess = (event) => {
            const data = event.target.result;
            console.log(`Loaded ${storageName} from IndexedDB:`, data);
            displayData(storageName, data);
        };

        request.onerror = (event) => {
            console.error(`Error loading ${storageName} from IndexedDB:`, event.target.error);
        };
    }

    async function saveToIndexedDB(storageName, data) {
        const transaction = db.transaction([storageName], 'readwrite');
        const store = transaction.objectStore(storageName);
        for (const item of data) {
            store.put(item); // Use put for upsert (update if exists, insert if new)
        }
        await new Promise(resolve => transaction.oncomplete = resolve);
        console.log(`Saved ${data.length} items to ${storageName} in IndexedDB.`);
    }

    async function addToPendingSync(type, data) {
        const transaction = db.transaction(['pendingSync'], 'readwrite');
        const store = transaction.objectStore('pendingSync');
        store.add({ type, data, timestamp: new Date().toISOString() });
        await new Promise(resolve => transaction.oncomplete = resolve);
        console.log(`Added a ${type} operation to pending sync.`);

        // Request background sync
        if ('serviceWorker' in navigator && 'SyncManager' in window) {
            navigator.serviceWorker.ready.then(reg => {
                reg.sync.register('sync-pending-workspace-changes')
                    .then(() => console.log('Background sync registered for pending changes.'))
                    .catch(err => console.error('Background sync registration failed:', err));
            });
        } else {
            alert('Background Sync API not supported or service worker not ready. Sync will happen on next online app load.');
        }
    }


    function displayData(storageName, data) {
        const targetElement = document.getElementById(storageName.replace('s', '-')); // e.g., 'drive-files'
        if (!targetElement) return;

        targetElement.innerHTML = ''; // Clear previous content

        if (data.length === 0) {
            targetElement.innerHTML = '<p>No data found.</p>';
            return;
        }

        const ul = document.createElement('ul');
        data.forEach(item => {
            const li = document.createElement('li');
            if (storageName === 'driveFiles') {
                li.innerHTML = `<strong>${item.name}</strong> (${item.mimeType}) - Modified: ${new Date(item.modifiedTime).toLocaleDateString()}`;
                // Add a download button for Drive files
                const downloadBtn = document.createElement('button');
                downloadBtn.textContent = 'Download';
                downloadBtn.onclick = async () => {
                    if (navigator.onLine) {
                        try {
                            const response = await fetch(`/api/drive/files/${item.id}/download`);
                            if (!response.ok) throw new Error('Download failed');
                            const blob = await response.blob();
                            const url = URL.createObjectURL(blob);
                            const a = document.createElement('a');
                            a.href = url;
                            a.download = item.name;
                            document.body.appendChild(a);
                            a.click();
                            document.body.removeChild(a);
                            URL.revokeObjectURL(url);
                        } catch (e) {
                            console.error('Error downloading:', e);
                            alert('Failed to download file online. Try again later.');
                        }
                    } else {
                        alert('Cannot download file when offline.');
                        // In a real app, you might have pre-downloaded content
                    }
                };
                li.appendChild(downloadBtn);
            } else if (storageName === 'gmailMessages') {
                const subject = item.payload?.headers?.find(h => h.name === 'Subject')?.value || 'No Subject';
                const from = item.payload?.headers?.find(h => h.name === 'From')?.value || 'Unknown Sender';
                li.innerHTML = `<strong>${subject}</strong> - From: ${from}`;
            } else if (storageName === 'calendarEvents') {
                const start = new Date(item.start.dateTime || item.start.date).toLocaleString();
                const end = new Date(item.end.dateTime || item.end.date).toLocaleString();
                li.innerHTML = `<strong>${item.summary}</strong><br><em>${item.description || ''}</em><br>Starts: ${start}<br>Ends: ${end}`;
            }
            ul.appendChild(li);
        });
        targetElement.appendChild(ul);
    }

    // --- Event Listeners for UI Actions ---

    document.getElementById('refresh-drive').addEventListener('click', () => fetchData('/api/drive/files', 'driveFiles'));
    document.getElementById('offline-drive').addEventListener('click', () => loadFromIndexedDB('driveFiles'));

    document.getElementById('upload-file').addEventListener('click', async () => {
        const fileInput = document.getElementById('file-upload-input');
        const file = fileInput.files[0];
        if (!file) {
            alert('Please select a file to upload.');
            return;
        }

        const reader = new FileReader();
        reader.onload = async (event) => {
            const base64Content = event.target.result.split(',')[1]; // Get base64 string without prefix

            const fileData = {
                fileName: file.name,
                mimeType: file.type,
                base64Content: base64Content,
            };

            if (navigator.onLine && isAuthenticated) {
                try {
                    const response = await fetch('/api/drive/files/upload', {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' },
                        body: JSON.stringify(fileData),
                    });
                    if (!response.ok) throw new Error('File upload failed.');
                    const uploadedFile = await response.json();
                    alert(`File "${uploadedFile.name}" uploaded successfully!`);
                    await fetchData('/api/drive/files', 'driveFiles'); // Refresh list
                } catch (error) {
                    console.error('Online upload failed:', error);
                    alert('Online upload failed. Saving for offline sync.');
                    await addToPendingSync('file_upload', fileData);
                }
            } else {
                alert('Offline. File queued for upload when online.');
                await addToPendingSync('file_upload', fileData);
            }
        };
        reader.readAsDataURL(file); // Read file as base64
    });

    document.getElementById('refresh-gmail').addEventListener('click', () => fetchData('/api/gmail/messages', 'gmailMessages'));
    document.getElementById('offline-gmail').addEventListener('click', () => loadFromIndexedDB('gmailMessages'));

    document.getElementById('compose-email').addEventListener('click', () => {
        document.getElementById('email-compose-form').style.display = 'block';
    });
    document.getElementById('cancel-email').addEventListener('click', () => {
        document.getElementById('email-compose-form').style.display = 'none';
        document.getElementById('email-to').value = '';
        document.getElementById('email-subject').value = '';
        document.getElementById('email-body').value = '';
    });
    document.getElementById('send-email').addEventListener('click', async () => {
        const to = document.getElementById('email-to').value;
        const subject = document.getElementById('email-subject').value;
        const body = document.getElementById('email-body').value;

        const emailData = { to, subject, body };

        if (!to || !subject || !body) {
            alert('Please fill in all email fields.');
            return;
        }

        if (navigator.onLine && isAuthenticated) {
            try {
                const response = await fetch('/api/gmail/send', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(emailData),
                });
                if (!response.ok) throw new Error('Email send failed.');
                alert('Email sent successfully!');
                document.getElementById('email-compose-form').style.display = 'none';
                await fetchData('/api/gmail/messages', 'gmailMessages'); // Refresh list
            } catch (error) {
                console.error('Online email send failed:', error);
                alert('Online email send failed. Saving for offline sync.');
                await addToPendingSync('email_send', emailData);
            }
        } else {
            alert('Offline. Email queued for sending when online.');
            await addToPendingSync('email_send', emailData);
        }
    });

    document.getElementById('refresh-calendar').addEventListener('click', () => fetchData('/api/calendar/events', 'calendarEvents'));
    document.getElementById('offline-calendar').addEventListener('click', () => loadFromIndexedDB('calendarEvents'));

    document.getElementById('create-event').addEventListener('click', () => {
        document.getElementById('event-create-form').style.display = 'block';
    });
    document.getElementById('cancel-event').addEventListener('click', () => {
        document.getElementById('event-create-form').style.display = 'none';
        document.getElementById('event-summary').value = '';
        document.getElementById('event-description').value = '';
        document.getElementById('event-start').value = '';
        document.getElementById('event-end').value = '';
    });
    document.getElementById('save-event').addEventListener('click', async () => {
        const summary = document.getElementById('event-summary').value;
        const description = document.getElementById('event-description').value;
        const start = document.getElementById('event-start').value;
        const end = document.getElementById('event-end').value;

        const eventData = { summary, description, start, end };

        if (!summary || !start || !end) {
            alert('Please fill in all required event fields (summary, start, end).');
            return;
        }

        if (navigator.onLine && isAuthenticated) {
            try {
                const response = await fetch('/api/calendar/events', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(eventData),
                });
                if (!response.ok) throw new Error('Event creation failed.');
                alert('Event created successfully!');
                document.getElementById('event-create-form').style.display = 'none';
                await fetchData('/api/calendar/events', 'calendarEvents'); // Refresh list
            } catch (error) {
                console.error('Online event creation failed:', error);
                alert('Online event creation failed. Saving for offline sync.');
                await addToPendingSync('calendar_create', eventData);
            }
        } else {
            alert('Offline. Event queued for creation when online.');
            await addToPendingSync('calendar_create', eventData);
        }
    });
});

7. public/service-worker.js (Service Worker):
This manages caching and background sync for offline operations.
const CACHE_NAME = 'advanced-workspace-cache-v1';
const DATA_CACHE_NAME = 'advanced-workspace-data-cache-v1'; // For API responses (consider strategies)

const urlsToCache = [
  '/',
  '/index.html',
  '/styles.css',
  '/main.js',
];

self.addEventListener('install', (event) => {
  event.waitUntil(
    caches.open(CACHE_NAME)
      .then((cache) => {
        console.log('Service Worker: Caching app shell assets');
        return cache.addAll(urlsToCache);
      })
  );
});

self.addEventListener('activate', (event) => {
  event.waitUntil(
    caches.keys().then((cacheNames) => {
      return Promise.all(
        cacheNames.map((cacheName) => {
          if (cacheName !== CACHE_NAME && cacheName !== DATA_CACHE_NAME) {
            console.log('Service Worker: Deleting old cache:', cacheName);
            return caches.delete(cacheName);
          }
        })
      );
    })
  );
  self.clients.claim(); // Ensures the service worker controls clients immediately
});

self.addEventListener('fetch', (event) => {
  // Strategy: Cache-First for app shell, Network-First with Cache Fallback for APIs
  if (urlsToCache.includes(event.request.url.split('?')[0])) { // Cache-First for static assets
    event.respondWith(
      caches.match(event.request)
        .then((response) => {
          return response || fetch(event.request);
        })
    );
  } else if (event.request.url.startsWith(self.location.origin + '/api/')) {
    // For API calls, try network first, then fallback to cache (if data was cached before)
    // This is a simplistic approach. For real apps, you'd implement specific strategies
    // like Cache-then-Network or Stale-While-Revalidate.
    event.respondWith(
      fetch(event.request)
        .then(async (response) => {
          // If response is good, clone it and put in cache
          const responseToCache = response.clone();
          const cache = await caches.open(DATA_CACHE_NAME);
          cache.put(event.request, responseToCache);
          return response;
        })
        .catch(async () => {
          // Network failed, try to get from cache
          const cachedResponse = await caches.match(event.request);
          if (cachedResponse) {
            return cachedResponse;
          }
          // If not in cache and offline, throw error
          throw new Error('No network and no cached data.');
        })
    );
  } else {
    // Default to network-first for other requests
    event.respondWith(fetch(event.request));
  }
});

// --- Background Sync ---
self.addEventListener('sync', (event) => {
  if (event.tag === 'sync-pending-workspace-changes') {
    console.log('Service Worker: Performing background sync for pending changes...');
    event.waitUntil(syncPendingWorkspaceChanges());
  }
});

async function syncPendingWorkspaceChanges() {
    let db;
    try {
        // Re-open IndexedDB connection within the service worker context
        db = await new Promise((resolve, reject) => {
            const request = indexedDB.open('GoogleWorkspaceData', 1);
            request.onsuccess = (e) => resolve(e.target.result);
            request.onerror = (e) => reject(e.target.error);
            request.onupgradeneeded = (e) => {
                // Should not happen during sync, as DB should be established
                console.warn('IndexedDB upgrade needed during sync. This is unexpected.');
                e.target.transaction.abort();
            };
        });

        const transaction = db.transaction(['pendingSync'], 'readwrite');
        const store = transaction.objectStore('pendingSync');
        const pendingChanges = await store.getAll();

        for (const change of pendingChanges) {
            console.log('Processing pending change:', change.type, change.data);
            try {
                let apiResponse;
                switch (change.type) {
                    case 'file_upload':
                        apiResponse = await fetch('/api/drive/files/upload', {
                            method: 'POST',
                            headers: { 'Content-Type': 'application/json' },
                            body: JSON.stringify(change.data),
                        });
                        break;
                    case 'email_send':
                        apiResponse = await fetch('/api/gmail/send', {
                            method: 'POST',
                            headers: { 'Content-Type': 'application/json' },
                            body: JSON.stringify(change.data),
                        });
                        break;
                    case 'calendar_create':
                        apiResponse = await fetch('/api/calendar/events', {
                            method: 'POST',
                            headers: { 'Content-Type': 'application/json' },
                            body: JSON.stringify(change.data),
                        });
                        break;
                    // Add more cases for other types of offline operations (edit, delete, etc.)
                    default:
                        console.warn('Unknown pending change type:', change.type);
                        continue;
                }

                if (apiResponse.ok) {
                    console.log(`Successfully synced ${change.type} operation.`);
                    store.delete(change.id); // Remove from pending queue
                    // Optionally, update main app's cache of data after successful sync
                    // e.g., fetch the latest data from API and save to respective IndexedDB store
                } else {
                    const errorText = await apiResponse.text();
                    console.error(`Failed to sync ${change.type}:`, apiResponse.status, errorText);
                    // Do not delete from queue, it will be retried later
                }
            } catch (error) {
                console.error(`Network error during ${change.type} sync:`, error);
                // Do not delete from queue, it will be retried later
            }
        }
        await new Promise(resolve => transaction.oncomplete = resolve); // Ensure transaction completes
        console.log('Service Worker: Background sync completed.');
    } catch (error) {
        console.error('Service Worker: Error during background sync process:', error);
        // If DB access fails, subsequent syncs might be needed
    } finally {
        if (db) db.close(); // Close DB connection
    }
}

How to Run:
 * Set up Google Cloud Project: Follow the OAuth credential steps above.
 * Clone/Create Project: Set up the my-workspace-app directory structure.
 * Place Credentials: Put your credentials.json and .env files in the root.
 * Install Dependencies: npm install in your project root.
 * Start Server: node server.js
 * Access: Open your browser to http://localhost:3000/.
 * Authenticate: Click "Login with Google" and complete the OAuth flow.
 * Test Offline: Once authenticated and some data is loaded, go offline (e.g., turn off Wi-Fi, or in Chrome DevTools under "Application" > "Service Workers", check "Offline"). Perform actions like uploading a file or sending an email. Then go back online and observe the background sync.
Key Features Implemented (Conceptual):
 * OAuth 2.0 with Node.js Backend: Securely handles user authentication and token management (access and refresh tokens).
 * API Proxying: Node.js server acts as a proxy, making Google API calls on behalf of the client, protecting your API secrets.
 * Service Worker for Asset Caching: Ensures your PWA loads instantly even when offline.
 * IndexedDB for Offline Data Storage: Stores Google Workspace data (Drive files, Gmail messages, Calendar events) locally.
 * Offline Operation Queuing: When offline, actions like file uploads, email sends, or event creations are stored in a pendingSync IndexedDB object store.
 * Background Sync API: Leverages the browser's Background Sync API (via Service Worker) to automatically retry pending offline actions when connectivity is restored, even if the user has closed the tab.
 * Basic API Integrations: Illustrative examples for Google Drive (list, download, upload), Gmail (list, send), and Calendar (list, create).
Advanced Considerations (Beyond this Example):
 * Robust Error Handling: More sophisticated error logging, user notifications, and retry strategies.
 * Conflict Resolution: What happens if a file is edited offline and also online? You'd need a merge strategy or to alert the user.
 * Delta Sync: For Drive, use the Drive API's changes endpoint to fetch only modified files efficiently, rather than full lists.
 * Webhooks/Push Notifications: Use Google Drive change notifications (Webhooks) to instantly alert your Node.js backend when a change occurs in a user's Drive, allowing for near real-time sync.
 * Bi-directional Sync: This example focuses on pushing offline changes online. A complete solution would also pull changes from Google Workspace and update local IndexedDB.
 * User-Specific IndexedDB: In a multi-user application, ensure each user's offline data is isolated (e.g., by using a user-ID prefixed database name).
 * Streaming File Uploads/Downloads: For large files, stream data directly between the client, Node.js, and Google Drive API for better performance and memory management.
 * UI/UX: Provide clear visual cues about online/offline status, sync progress, and any pending actions.
 * Scalability: For a production app, consider using a database (e.g., MongoDB, PostgreSQL) on the backend to store user tokens, sync states, and potentially metadata.
 * Security Best Practices: Regularly review Google's security guidelines for API usage and OAuth implementation.



require('dotenv').config(); // Load environment variables from .env
const express = require('express');
const { google } = require('googleapis');
const fs = require('fs').promises; // Use promises version of fs
const path = require('path');
const bodyParser = require('body-parser');

const app = express();
const PORT = process.env.PORT || 3000;

// Middleware
app.use(bodyParser.json());
app.use(express.static('public')); // Serve your frontend PWA from the 'public' directory

// --- Google OAuth2 Setup ---
const credentials = require('./credentials.json').web;
const { client_id, client_secret, redirect_uris } = credentials;
const redirect_uri = process.env.REDIRECT_URI || redirect_uris[0]; // Use env var for flexibility

const oauth2Client = new google.auth.OAuth2(
  client_id,
  client_secret,
  redirect_uri
);

// Define the scopes your application needs.
// For advanced offline, you'll need comprehensive scopes.
const SCOPES = [
  'https://www.googleapis.com/auth/drive', // Full Drive access
  'https://www.googleapis.com/auth/gmail.modify', // Send, delete, and modify your email
  'https://www.googleapis.com/auth/calendar', // Manage calendars
  'https://www.googleapis.com/auth/userinfo.profile', // User profile info
  'https://www.googleapis.com/auth/userinfo.email', // User email address
  'openid'
];

// --- OAuth Routes ---

// 1. Redirect user to Google for authentication
app.get('/auth/google', (req, res) => {
  const authorizeUrl = oauth2Client.generateAuthUrl({
    access_type: 'offline', // IMPORTANT for getting a refresh token
    scope: SCOPES,
    prompt: 'consent' // Forces user to re-consent, ensuring refresh token if lost
  });
  res.redirect(authorizeUrl);
});

// 2. Google redirects back to this endpoint after user grants permission
app.get('/oauth2callback', async (req, res) => {
  const { code } = req.query;
  try {
    const { tokens } = await oauth2Client.getToken(code);
    oauth2Client.setCredentials(tokens);

    // Store tokens securely. In a real app, you'd store this in a database
    // associated with the user. For this example, we'll store it in memory.
    // For a multi-user app, you'd associate tokens with a session or user ID.
    app.set('googleTokens', tokens); // Storing in app locals for simplicity (NOT PRODUCTION SAFE)

    // Redirect back to your frontend, maybe with a success message or
    // to a dashboard page.
    res.redirect('/?authSuccess=true');
  } catch (error) {
    console.error('Error retrieving access token:', error.message);
    res.status(500).send('Authentication failed.');
  }
});

// Middleware to ensure user is authenticated for Google API calls
app.use(async (req, res, next) => {
  const tokens = app.get('googleTokens'); // Retrieve tokens
  if (!tokens) {
    return res.status(401).send('Not authenticated. Please log in first.');
  }

  oauth2Client.setCredentials(tokens);

  // Check if access token is expired and refresh if needed
  if (oauth2Client.isTokenExpiring()) {
    try {
      const { credentials } = await oauth2Client.refreshAccessToken();
      oauth2Client.setCredentials(credentials);
      app.set('googleTokens', credentials); // Update stored tokens
      console.log('Access token refreshed successfully!');
    } catch (error) {
      console.error('Error refreshing access token:', error.message);
      // If refresh fails, user needs to re-authenticate
      app.set('googleTokens', null); // Clear invalid tokens
      return res.status(401).send('Session expired. Please re-authenticate.');
    }
  }
  next(); // Continue to the API route
});

// --- Google Workspace API Endpoints (Accessed by Frontend) ---

// Drive: List Files
app.get('/api/drive/files', async (req, res) => {
  const drive = google.drive({ version: 'v3', auth: oauth2Client });
  try {
    const response = await drive.files.list({
      pageSize: 10,
      fields: 'nextPageToken, files(id, name, mimeType, modifiedTime)',
    });
    res.json(response.data.files);
  } catch (error) {
    console.error('Error listing Drive files:', error.message);
    res.status(500).send('Failed to list files.');
  }
});

// Drive: Download File Content
app.get('/api/drive/files/:fileId/download', async (req, res) => {
    const { fileId } = req.params;
    const drive = google.drive({ version: 'v3', auth: oauth2Client });
    try {
        const response = await drive.files.get(
            { fileId: fileId, alt: 'media' },
            { responseType: 'stream' }
        );

        // Set appropriate headers for download
        const fileMetadata = await drive.files.get({ fileId: fileId, fields: 'name, mimeType' });
        res.setHeader('Content-Type', fileMetadata.data.mimeType);
        res.setHeader('Content-Disposition', `attachment; filename="${fileMetadata.data.name}"`);

        response.data.pipe(res); // Pipe the file stream directly to the response
    } catch (error) {
        console.error('Error downloading Drive file:', error.message);
        res.status(500).send('Failed to download file.');
    }
});

// Drive: Upload File (from frontend blob/buffer)
app.post('/api/drive/files/upload', async (req, res) => {
  // In a real app, handle file uploads more robustly, e.g., with 'multer'
  // For simplicity, assuming req.body contains { fileName, mimeType, base64Content }
  const { fileName, mimeType, base64Content } = req.body;
  if (!fileName || !mimeType || !base64Content) {
    return res.status(400).send('Missing file data.');
  }

  const drive = google.drive({ version: 'v3', auth: oauth2Client });
  const fileBuffer = Buffer.from(base64Content, 'base64'); // Convert base64 to buffer

  try {
    const response = await drive.files.create({
      requestBody: {
        name: fileName,
        mimeType: mimeType,
      },
      media: {
        mimeType: mimeType,
        body: fileBuffer, // Use the buffer directly
      },
      fields: 'id, name, mimeType',
    });
    res.status(200).json(response.data);
  } catch (error) {
    console.error('Error uploading Drive file:', error.message);
    res.status(500).send('Failed to upload file.');
  }
});

// Gmail: List Messages
app.get('/api/gmail/messages', async (req, res) => {
  const gmail = google.gmail({ version: 'v1', auth: oauth2Client });
  try {
    const response = await gmail.users.messages.list({
      userId: 'me',
      maxResults: 10,
    });
    res.json(response.data.messages || []);
  } catch (error) {
    console.error('Error listing Gmail messages:', error.message);
    res.status(500).send('Failed to list messages.');
  }
});

// Gmail: Get Message Content (Full)
app.get('/api/gmail/messages/:messageId', async (req, res) => {
  const { messageId } = req.params;
  const gmail = google.gmail({ version: 'v1', auth: oauth2Client });
  try {
    const response = await gmail.users.messages.get({
      userId: 'me',
      id: messageId,
      format: 'full' // or 'raw', 'minimal', 'metadata'
    });
    res.json(response.data);
  } catch (error) {
    console.error('Error getting Gmail message:', error.message);
    res.status(500).send('Failed to get message content.');
  }
});

// Gmail: Send Email
app.post('/api/gmail/send', async (req, res) => {
  const { to, subject, body } = req.body;
  if (!to || !subject || !body) {
    return res.status(400).send('Missing required email fields (to, subject, body).');
  }

  const gmail = google.gmail({ version: 'v1', auth: oauth2Client });

  // Create a raw email string in RFC 2822 format
  const emailLines = [
    `To: ${to}`,
    `Subject: ${subject}`,
    'MIME-Version: 1.0',
    'Content-Type: text/plain; charset="UTF-8"',
    '',
    body,
  ];
  const email = emailLines.join('\r\n');

  // Base64Url encode the email string
  const encodedEmail = Buffer.from(email).toString('base64').replace(/\+/g, '-').replace(/\//g, '_').replace(/=+$/, '');

  try {
    const response = await gmail.users.messages.send({
      userId: 'me',
      requestBody: {
        raw: encodedEmail,
      },
    });
    res.status(200).json(response.data);
  } catch (error) {
    console.error('Error sending email:', error.message);
    res.status(500).send('Failed to send email.');
  }
});


// Calendar: List Events
app.get('/api/calendar/events', async (req, res) => {
  const calendar = google.calendar({ version: 'v3', auth: oauth2Client });
  try {
    const response = await calendar.events.list({
      calendarId: 'primary',
      timeMin: new Date().toISOString(),
      maxResults: 10,
      singleEvents: true,
      orderBy: 'startTime',
    });
    res.json(response.data.items || []);
  } catch (error) {
    console.error('Error listing Calendar events:', error.message);
    res.status(500).send('Failed to list events.');
  }
});

// Calendar: Create Event
app.post('/api/calendar/events', async (req, res) => {
  const { summary, description, start, end, attendees } = req.body;
  if (!summary || !start || !end) {
    return res.status(400).send('Missing required event fields (summary, start, end).');
  }

  const calendar = google.calendar({ version: 'v3', auth: oauth2Client });
  const event = {
    summary: summary,
    description: description,
    start: {
      dateTime: start.dateTime || start,
      timeZone: start.timeZone || 'Asia/Manila', // Default to current location timezone
    },
    end: {
      dateTime: end.dateTime || end,
      timeZone: end.timeZone || 'Asia/Manila',
    },
    attendees: attendees || [],
  };

  try {
    const response = await calendar.events.insert({
      calendarId: 'primary',
      resource: event,
    });
    res.status(201).json(response.data);
  } catch (error) {
    console.error('Error creating Calendar event:', error.message);
    res.status(500).send('Failed to create event.');
  }
});


// --- Server Start ---
app.listen(PORT, () => {
  console.log(`Server running on http://localhost:${PORT}`);
  console.log('Open http://localhost:3000/ to start the app.');
  console.log('Go to http://localhost:3000/auth/google to initiate OAuth if needed.');
});



<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Advanced Offline Workspace</title>
    <link rel="stylesheet" href="/styles.css">
</head>
<body>
    <header>
        <h1>My Advanced Workspace</h1>
        <div id="auth-status">
            <span id="online-status">Offline</span>
            <button id="auth-button">Login with Google</button>
            <button id="logout-button" style="display:none;">Logout</button>
        </div>
    </header>
    <main>
        <section id="drive-section">
            <h2>Google Drive Files</h2>
            <button id="refresh-drive">Refresh Online Files</button>
            <button id="offline-drive">View Offline Files</button>
            <input type="file" id="file-upload-input">
            <button id="upload-file">Upload File</button>
            <div id="drive-files">Loading...</div>
        </section>

        <section id="gmail-section">
            <h2>Gmail Messages</h2>
            <button id="refresh-gmail">Refresh Online Mail</button>
            <button id="offline-gmail">View Offline Mail</button>
            <button id="compose-email">Compose Email</button>
            <div id="gmail-messages">Loading...</div>
            <div id="email-compose-form" style="display: none;">
                <h3>Compose New Email</h3>
                <input type="text" id="email-to" placeholder="To">
                <input type="text" id="email-subject" placeholder="Subject">
                <textarea id="email-body" placeholder="Body"></textarea>
                <button id="send-email">Send</button>
                <button id="cancel-email">Cancel</button>
            </div>
        </section>

        <section id="calendar-section">
            <h2>Google Calendar Events</h2>
            <button id="refresh-calendar">Refresh Online Events</button>
            <button id="offline-calendar">View Offline Events</button>
            <button id="create-event">Create Event</button>
            <div id="calendar-events">Loading...</div>
            <div id="event-create-form" style="display: none;">
                <h3>Create New Event</h3>
                <input type="text" id="event-summary" placeholder="Summary">
                <input type="text" id="event-description" placeholder="Description">
                <label for="event-start">Start Time:</label>
                <input type="datetime-local" id="event-start">
                <label for="event-end">End Time:</label>
                <input type="datetime-local" id="event-end">
                <button id="save-event">Save Event</button>
                <button id="cancel-event">Cancel</button>
            </div>
        </section>
    </main>
    <script src="/main.js"></script>
    <script>
        // Register Service Worker
        if ('serviceWorker' in navigator) {
            window.addEventListener('load', () => {
                navigator.serviceWorker.register('/service-worker.js')
                    .then(registration => {
                        console.log('Service Worker registered with scope:', registration.scope);
                        // Optional: Request a background sync when network comes back online
                        // if ('SyncManager' in window) {
                        //     navigator.serviceWorker.ready.then(reg => {
                        //         reg.sync.register('initial-sync').catch(console.error);
                        //     });
                        // }
                    })
                    .catch(error => {
                        console.error('Service Worker registration failed:', error);
                    });
            });
        }
    </script>
</body>
</html>



body {
    font-family: Arial, sans-serif;
    margin: 20px;
    background-color: #f4f4f4;
    color: #333;
}

header {
    display: flex;
    justify-content: space-between;
    align-items: center;
    background-color: #fff;
    padding: 15px 20px;
    border-bottom: 1px solid #eee;
    box-shadow: 0 2px 4px rgba(0,0,0,0.1);
}

h1, h2, h3 {
    color: #0056b3;
}

button {
    background-color: #007bff;
    color: white;
    padding: 8px 15px;
    border: none;
    border-radius: 4px;
    cursor: pointer;
    margin-right: 10px;
}

button:hover {
    background-color: #0056b3;
}

section {
    background-color: #fff;
    margin-top: 20px;
    padding: 20px;
    border-radius: 8px;
    box-shadow: 0 2px 4px rgba(0,0,0,0.1);
}

ul {
    list-style-type: none;
    padding: 0;
}

li {
    background-color: #f9f9f9;
    margin-bottom: 10px;
    padding: 10px;
    border-radius: 4px;
    border: 1px solid #ddd;
}

#auth-status {
    display: flex;
    align-items: center;
}

#online-status {
    margin-right: 15px;
    font-weight: bold;
    color: gray;
}

#online-status.online {
    color: green;
}

#online-status.offline {
    color: red;
}

input[type="text"],
input[type="datetime-local"],
textarea,
input[type="file"] {
    width: calc(100% - 22px);
    padding: 10px;
    margin-bottom: 10px;
    border: 1px solid #ccc;
    border-radius: 4px;
}

textarea {
    min-height: 100px;
    resize: vertical;
}



// Function to handle network status updates
function updateOnlineStatus() {
    const statusEl = document.getElementById('online-status');
    if (navigator.onLine) {
        statusEl.textContent = 'Online';
        statusEl.classList.remove('offline');
        statusEl.classList.add('online');
    } else {
        statusEl.textContent = 'Offline';
        statusEl.classList.remove('online');
        statusEl.classList.add('offline');
    }
}

// Initial status check
updateOnlineStatus();
window.addEventListener('online', updateOnlineStatus);
window.addEventListener('offline', updateOnlineStatus);

// IndexedDB setup (using a helper function/library like Dexie.js in a real app)
let db;

function openIndexedDB() {
    return new Promise((resolve, reject) => {
        const request = indexedDB.open('GoogleWorkspaceData', 1);

        request.onupgradeneeded = (event) => {
            db = event.target.result;
            db.createObjectStore('driveFiles', { keyPath: 'id' });
            db.createObjectStore('gmailMessages', { keyPath: 'id' });
            db.createObjectStore('calendarEvents', { keyPath: 'id' });
            db.createObjectStore('pendingSync', { autoIncrement: true }); // For offline changes
            console.log('IndexedDB upgraded/created.');
        };

        request.onsuccess = (event) => {
            db = event.target.result;
            console.log('IndexedDB opened successfully.');
            resolve(db);
        };

        request.onerror = (event) => {
            console.error('IndexedDB error:', event.target.errorCode);
            reject(event.target.error);
        };
    });
}

// Global variable for authentication status
let isAuthenticated = false;

document.addEventListener('DOMContentLoaded', async () => {
    await openIndexedDB(); // Initialize IndexedDB when DOM is ready

    const authButton = document.getElementById('auth-button');
    const logoutButton = document.getElementById('logout-button');

    // Check for authentication success from URL parameter
    const urlParams = new URLSearchParams(window.location.search);
    if (urlParams.get('authSuccess') === 'true') {
        isAuthenticated = true;
        authButton.style.display = 'none';
        logoutButton.style.display = 'inline-block';
        console.log('Authenticated!');
        // Clear authSuccess param
        history.replaceState({}, document.title, window.location.pathname);
    }

    if (isAuthenticated) {
        loadDataOnline(); // Try to load data from online APIs
    }

    authButton.addEventListener('click', () => {
        window.location.href = '/auth/google'; // Redirect to Node.js OAuth endpoint
    });

    logoutButton.addEventListener('click', () => {
        // Invalidate token on server-side in a real app, clear local storage/session
        alert('Logging out is not fully implemented in this example (tokens on server persist).');
        isAuthenticated = false;
        authButton.style.display = 'inline-block';
        logoutButton.style.display = 'none';
        window.location.reload(); // Refresh to clear UI
    });

    // --- Data Fetching and Display Functions ---

    async function fetchData(apiEndpoint, storageName) {
        if (navigator.onLine && isAuthenticated) {
            try {
                const response = await fetch(apiEndpoint);
                if (!response.ok) {
                    throw new Error(`HTTP error! status: ${response.status}`);
                }
                const data = await response.json();
                console.log(`Fetched ${storageName} online:`, data);
                await saveToIndexedDB(storageName, data);
                displayData(storageName, data);
            } catch (error) {
                console.error(`Error fetching ${storageName} online:`, error);
                alert(`Failed to load ${storageName} online. Showing offline data if available.`);
                loadFromIndexedDB(storageName);
            }
        } else {
            console.log(`Offline or not authenticated. Loading ${storageName} from IndexedDB.`);
            loadFromIndexedDB(storageName);
        }
    }

    async function loadDataOnline() {
        if (!isAuthenticated) return;
        await fetchData('/api/drive/files', 'driveFiles');
        await fetchData('/api/gmail/messages', 'gmailMessages');
        await fetchData('/api/calendar/events', 'calendarEvents');
    }

    async function loadFromIndexedDB(storageName) {
        const transaction = db.transaction([storageName], 'readonly');
        const store = transaction.objectStore(storageName);
        const request = store.getAll();

        request.onsuccess = (event) => {
            const data = event.target.result;
            console.log(`Loaded ${storageName} from IndexedDB:`, data);
            displayData(storageName, data);
        };

        request.onerror = (event) => {
            console.error(`Error loading ${storageName} from IndexedDB:`, event.target.error);
        };
    }

    async function saveToIndexedDB(storageName, data) {
        const transaction = db.transaction([storageName], 'readwrite');
        const store = transaction.objectStore(storageName);
        for (const item of data) {
            store.put(item); // Use put for upsert (update if exists, insert if new)
        }
        await new Promise(resolve => transaction.oncomplete = resolve);
        console.log(`Saved ${data.length} items to ${storageName} in IndexedDB.`);
    }

    async function addToPendingSync(type, data) {
        const transaction = db.transaction(['pendingSync'], 'readwrite');
        const store = transaction.objectStore('pendingSync');
        store.add({ type, data, timestamp: new Date().toISOString() });
        await new Promise(resolve => transaction.oncomplete = resolve);
        console.log(`Added a ${type} operation to pending sync.`);

        // Request background sync
        if ('serviceWorker' in navigator && 'SyncManager' in window) {
            navigator.serviceWorker.ready.then(reg => {
                reg.sync.register('sync-pending-workspace-changes')
                    .then(() => console.log('Background sync registered for pending changes.'))
                    .catch(err => console.error('Background sync registration failed:', err));
            });
        } else {
            alert('Background Sync API not supported or service worker not ready. Sync will happen on next online app load.');
        }
    }


    function displayData(storageName, data) {
        const targetElement = document.getElementById(storageName.replace('s', '-')); // e.g., 'drive-files'
        if (!targetElement) return;

        targetElement.innerHTML = ''; // Clear previous content

        if (data.length === 0) {
            targetElement.innerHTML = '<p>No data found.</p>';
            return;
        }

        const ul = document.createElement('ul');
        data.forEach(item => {
            const li = document.createElement('li');
            if (storageName === 'driveFiles') {
                li.innerHTML = `<strong>${item.name}</strong> (${item.mimeType}) - Modified: ${new Date(item.modifiedTime).toLocaleDateString()}`;
                // Add a download button for Drive files
                const downloadBtn = document.createElement('button');
                downloadBtn.textContent = 'Download';
                downloadBtn.onclick = async () => {
                    if (navigator.onLine) {
                        try {
                            const response = await fetch(`/api/drive/files/${item.id}/download`);
                            if (!response.ok) throw new Error('Download failed');
                            const blob = await response.blob();
                            const url = URL.createObjectURL(blob);
                            const a = document.createElement('a');
                            a.href = url;
                            a.download = item.name;
                            document.body.appendChild(a);
                            a.click();
                            document.body.removeChild(a);
                            URL.revokeObjectURL(url);
                        } catch (e) {
                            console.error('Error downloading:', e);
                            alert('Failed to download file online. Try again later.');
                        }
                    } else {
                        alert('Cannot download file when offline.');
                        // In a real app, you might have pre-downloaded content
                    }
                };
                li.appendChild(downloadBtn);
            } else if (storageName === 'gmailMessages') {
                const subject = item.payload?.headers?.find(h => h.name === 'Subject')?.value || 'No Subject';
                const from = item.payload?.headers?.find(h => h.name === 'From')?.value || 'Unknown Sender';
                li.innerHTML = `<strong>${subject}</strong> - From: ${from}`;
            } else if (storageName === 'calendarEvents') {
                const start = new Date(item.start.dateTime || item.start.date).toLocaleString();
                const end = new Date(item.end.dateTime || item.end.date).toLocaleString();
                li.innerHTML = `<strong>${item.summary}</strong><br><em>${item.description || ''}</em><br>Starts: ${start}<br>Ends: ${end}`;
            }
            ul.appendChild(li);
        });
        targetElement.appendChild(ul);
    }

    // --- Event Listeners for UI Actions ---

    document.getElementById('refresh-drive').addEventListener('click', () => fetchData('/api/drive/files', 'driveFiles'));
    document.getElementById('offline-drive').addEventListener('click', () => loadFromIndexedDB('driveFiles'));

    document.getElementById('upload-file').addEventListener('click', async () => {
        const fileInput = document.getElementById('file-upload-input');
        const file = fileInput.files[0];
        if (!file) {
            alert('Please select a file to upload.');
            return;
        }

        const reader = new FileReader();
        reader.onload = async (event) => {
            const base64Content = event.target.result.split(',')[1]; // Get base64 string without prefix

            const fileData = {
                fileName: file.name,
                mimeType: file.type,
                base64Content: base64Content,
            };

            if (navigator.onLine && isAuthenticated) {
                try {
                    const response = await fetch('/api/drive/files/upload', {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' },
                        body: JSON.stringify(fileData),
                    });
                    if (!response.ok) throw new Error('File upload failed.');
                    const uploadedFile = await response.json();
                    alert(`File "${uploadedFile.name}" uploaded successfully!`);
                    await fetchData('/api/drive/files', 'driveFiles'); // Refresh list
                } catch (error) {
                    console.error('Online upload failed:', error);
                    alert('Online upload failed. Saving for offline sync.');
                    await addToPendingSync('file_upload', fileData);
                }
            } else {
                alert('Offline. File queued for upload when online.');
                await addToPendingSync('file_upload', fileData);
            }
        };
        reader.readAsDataURL(file); // Read file as base64
    });

    document.getElementById('refresh-gmail').addEventListener('click', () => fetchData('/api/gmail/messages', 'gmailMessages'));
    document.getElementById('offline-gmail').addEventListener('click', () => loadFromIndexedDB('gmailMessages'));

    document.getElementById('compose-email').addEventListener('click', () => {
        document.getElementById('email-compose-form').style.display = 'block';
    });
    document.getElementById('cancel-email').addEventListener('click', () => {
        document.getElementById('email-compose-form').style.display = 'none';
        document.getElementById('email-to').value = '';
        document.getElementById('email-subject').value = '';
        document.getElementById('email-body').value = '';
    });
    document.getElementById('send-email').addEventListener('click', async () => {
        const to = document.getElementById('email-to').value;
        const subject = document.getElementById('email-subject').value;
        const body = document.getElementById('email-body').value;

        const emailData = { to, subject, body };

        if (!to || !subject || !body) {
            alert('Please fill in all email fields.');
            return;
        }

        if (navigator.onLine && isAuthenticated) {
            try {
                const response = await fetch('/api/gmail/send', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(emailData),
                });
                if (!response.ok) throw new Error('Email send failed.');
                alert('Email sent successfully!');
                document.getElementById('email-compose-form').style.display = 'none';
                await fetchData('/api/gmail/messages', 'gmailMessages'); // Refresh list
            } catch (error) {
                console.error('Online email send failed:', error);
                alert('Online email send failed. Saving for offline sync.');
                await addToPendingSync('email_send', emailData);
            }
        } else {
            alert('Offline. Email queued for sending when online.');
            await addToPendingSync('email_send', emailData);
        }
    });

    document.getElementById('refresh-calendar').addEventListener('click', () => fetchData('/api/calendar/events', 'calendarEvents'));
    document.getElementById('offline-calendar').addEventListener('click', () => loadFromIndexedDB('calendarEvents'));

    document.getElementById('create-event').addEventListener('click', () => {
        document.getElementById('event-create-form').style.display = 'block';
    });
    document.getElementById('cancel-event').addEventListener('click', () => {
        document.getElementById('event-create-form').style.display = 'none';
        document.getElementById('event-summary').value = '';
        document.getElementById('event-description').value = '';
        document.getElementById('event-start').value = '';
        document.getElementById('event-end').value = '';
    });
    document.getElementById('save-event').addEventListener('click', async () => {
        const summary = document.getElementById('event-summary').value;
        const description = document.getElementById('event-description').value;
        const start = document.getElementById('event-start').value;
        const end = document.getElementById('event-end').value;

        const eventData = { summary, description, start, end };

        if (!summary || !start || !end) {
            alert('Please fill in all required event fields (summary, start, end).');
            return;
        }

        if (navigator.onLine && isAuthenticated) {
            try {
                const response = await fetch('/api/calendar/events', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(eventData),
                });
                if (!response.ok) throw new Error('Event creation failed.');
                alert('Event created successfully!');
                document.getElementById('event-create-form').style.display = 'none';
                await fetchData('/api/calendar/events', 'calendarEvents'); // Refresh list
            } catch (error) {
                console.error('Online event creation failed:', error);
                alert('Online event creation failed. Saving for offline sync.');
                await addToPendingSync('calendar_create', eventData);
            }
        } else {
            alert('Offline. Event queued for creation when online.');
            await addToPendingSync('calendar_create', eventData);
        }
    });
});



const CACHE_NAME = 'advanced-workspace-cache-v1';
const DATA_CACHE_NAME = 'advanced-workspace-data-cache-v1'; // For API responses (consider strategies)

const urlsToCache = [
  '/',
  '/index.html',
  '/styles.css',
  '/main.js',
];

self.addEventListener('install', (event) => {
  event.waitUntil(
    caches.open(CACHE_NAME)
      .then((cache) => {
        console.log('Service Worker: Caching app shell assets');
        return cache.addAll(urlsToCache);
      })
  );
});

self.addEventListener('activate', (event) => {
  event.waitUntil(
    caches.keys().then((cacheNames) => {
      return Promise.all(
        cacheNames.map((cacheName) => {
          if (cacheName !== CACHE_NAME && cacheName !== DATA_CACHE_NAME) {
            console.log('Service Worker: Deleting old cache:', cacheName);
            return caches.delete(cacheName);
          }
        })
      );
    })
  );
  self.clients.claim(); // Ensures the service worker controls clients immediately
});

self.addEventListener('fetch', (event) => {
  // Strategy: Cache-First for app shell, Network-First with Cache Fallback for APIs
  if (urlsToCache.includes(event.request.url.split('?')[0])) { // Cache-First for static assets
    event.respondWith(
      caches.match(event.request)
        .then((response) => {
          return response || fetch(event.request);
        })
    );
  } else if (event.request.url.startsWith(self.location.origin + '/api/')) {
    // For API calls, try network first, then fallback to cache (if data was cached before)
    // This is a simplistic approach. For real apps, you'd implement specific strategies
    // like Cache-then-Network or Stale-While-Revalidate.
    event.respondWith(
      fetch(event.request)
        .then(async (response) => {
          // If response is good, clone it and put in cache
          const responseToCache = response.clone();
          const cache = await caches.open(DATA_CACHE_NAME);
          cache.put(event.request, responseToCache);
          return response;
        })
        .catch(async () => {
          // Network failed, try to get from cache
          const cachedResponse = await caches.match(event.request);
          if (cachedResponse) {
            return cachedResponse;
          }
          // If not in cache and offline, throw error
          throw new Error('No network and no cached data.');
        })
    );
  } else {
    // Default to network-first for other requests
    event.respondWith(fetch(event.request));
  }
});

// --- Background Sync ---
self.addEventListener('sync', (event) => {
  if (event.tag === 'sync-pending-workspace-changes') {
    console.log('Service Worker: Performing background sync for pending changes...');
    event.waitUntil(syncPendingWorkspaceChanges());
  }
});

async function syncPendingWorkspaceChanges() {
    let db;
    try {
        // Re-open IndexedDB connection within the service worker context
        db = await new Promise((resolve, reject) => {
            const request = indexedDB.open('GoogleWorkspaceData', 1);
            request.onsuccess = (e) => resolve(e.target.result);
            request.onerror = (e) => reject(e.target.error);
            request.onupgradeneeded = (e) => {
                // Should not happen during sync, as DB should be established
                console.warn('IndexedDB upgrade needed during sync. This is unexpected.');
                e.target.transaction.abort();
            };
        });

        const transaction = db.transaction(['pendingSync'], 'readwrite');
        const store = transaction.objectStore('pendingSync');
        const pendingChanges = await store.getAll();

        for (const change of pendingChanges) {
            console.log('Processing pending change:', change.type, change.data);
            try {
                let apiResponse;
                switch (change.type) {
                    case 'file_upload':
                        apiResponse = await fetch('/api/drive/files/upload', {
                            method: 'POST',
                            headers: { 'Content-Type': 'application/json' },
                            body: JSON.stringify(change.data),
                        });
                        break;
                    case 'email_send':
                        apiResponse = await fetch('/api/gmail/send', {
                            method: 'POST',
                            headers: { 'Content-Type': 'application/json' },
                            body: JSON.stringify(change.data),
                        });
                        break;
                    case 'calendar_create':
                        apiResponse = await fetch('/api/calendar/events', {
                            method: 'POST',
                            headers: { 'Content-Type': 'application/json' },
                            body: JSON.stringify(change.data),
                        });
                        break;
                    // Add more cases for other types of offline operations (edit, delete, etc.)
                    default:
                        console.warn('Unknown pending change type:', change.type);
                        continue;
                }

                if (apiResponse.ok) {
                    console.log(`Successfully synced ${change.type} operation.`);
                    store.delete(change.id); // Remove from pending queue
                    // Optionally, update main app's cache of data after successful sync
                    // e.g., fetch the latest data from API and save to respective IndexedDB store
                } else {
                    const errorText = await apiResponse.text();
                    console.error(`Failed to sync ${change.type}:`, apiResponse.status, errorText);
                    // Do not delete from queue, it will be retried later
                }
            } catch (error) {
                console.error(`Network error during ${change.type} sync:`, error);
                // Do not delete from queue, it will be retried later
            }
        }
        await new Promise(resolve => transaction.oncomplete = resolve); // Ensure transaction completes
        console.log('Service Worker: Background sync completed.');
    } catch (error) {
        console.error('Service Worker: Error during background sync process:', error);
        // If DB access fails, subsequent syncs might be needed
    } finally {
        if (db) db.close(); // Close DB connection
    }
}



Building an "advanced online/offline Google Workspace" solution with Python involves a slightly different architecture than with Node.js, especially when it comes to the "offline" part.
Key Differences for Python:
 * No Direct Browser-Side Offline (PWA): Python typically runs on a server or as a desktop application. It doesn't have native browser-side features like Service Workers or IndexedDB for managing browser cache or client-side storage directly for a web application.
 * Offline for Python Means Local Storage: For a Python application to be "offline," it means it needs to store data locally on the machine where the Python script is running (e.g., in SQLite database, flat files, or a custom local data store).
 * Backend Focus: Python is excellent for handling the backend logic, including OAuth, interacting with Google APIs, managing data synchronization, and potentially providing an API for a separate frontend (e.g., a web frontend built with React/Vue/Angular, or a desktop GUI with PyQt/Tkinter).
Architectural Approach (Python Backend + Local Data Store):
 * Python Backend/Script:
   * Authentication (OAuth 2.0): Manages obtaining and refreshing access tokens using the google-auth library.
   * Google API Interactions: Uses google-api-python-client to interact with Drive, Gmail, Calendar, etc.
   * Local Data Persistence: Employs a database (like SQLite) or a file system to store a local copy of Google Workspace data.
   * Synchronization Logic: Implements algorithms to compare local data with Google Workspace data and synchronize changes (both ways). This includes handling conflicts.
   * Change Tracking: Utilizes Google Drive's "Changes" API, Gmail's "History" API, and Calendar's "syncToken" for efficient incremental updates rather than full re-downloads.
   * User Interface (Optional): Could be a simple command-line interface (CLI) for a script, or it could expose a REST API for a separate frontend.
 * Local Data Store (e.g., SQLite):
   * Stores downloaded Google Workspace data (file metadata, email headers/bodies, calendar events).
   * Keeps track of pending local changes (e.g., new files to upload, emails to send) when the application is offline.
Prerequisites:
 * Google Cloud Project: Create a project in the Google Cloud Console.
 * Enable APIs: Enable Google Drive API, Gmail API, and Calendar API.
 * OAuth 2.0 Credentials (Desktop App):
   * Go to APIs & Services > Credentials.
   * Create an "OAuth client ID."
   * Select "Desktop application" as the application type. (This is generally easier for Python scripts as it simplifies the redirect URL).
   * Download the JSON credentials file (rename it to credentials.json and place it in your Python project root).
 * Python Environment:
   * Python 3.8+ installed.
   * Install necessary packages: pip install google-api-python-client google-auth-httplib2 google-auth-oauthlib beautifulsoup4 (for parsing email bodies).
Project Structure:
my-python-workspace/
├── credentials.json        # Your Google OAuth credentials
├── token.json              # Stores user tokens after first authentication (managed by google-auth)
├── workspace_db.sqlite     # SQLite database for local data storage
├── app.py                  # Main Python application logic
└── requirements.txt

1. requirements.txt:
google-api-python-client
google-auth-httplib2
google-auth-oauthlib
beautifulsoup4 # For parsing HTML email bodies

2. app.py (Python Application Logic):
This example will demonstrate:
 * OAuth 2.0 for offline access (refresh tokens).
 * Connecting to Google Drive, Gmail, and Calendar APIs.
 * Basic data fetching and saving to a local SQLite database.
 * Placeholder for offline change queuing and background sync logic.
<!-- end list -->
import os
import io
import json
import sqlite3
import datetime
from pathlib import Path
from google.auth.transport.requests import Request
from google.oauth2.credentials import Credentials
from google_auth_oauthlib.flow import InstalledAppFlow
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError
from googleapiclient.http import MediaIoBaseDownload, MediaFileUpload
from bs4 import BeautifulSoup # For parsing HTML email bodies

# --- Configuration ---
# If modifying these scopes, delete the file token.json.
SCOPES = [
    'https://www.googleapis.com/auth/drive',        # Full Drive access
    'https://www.googleapis.com/auth/gmail.modify', # Send, delete, modify email
    'https://www.googleapis.com/auth/calendar',     # Manage calendars
    'https://www.googleapis.com/auth/userinfo.profile',
    'https://www.googleapis.com/auth/userinfo.email',
]

TOKEN_FILE = 'token.json'
CREDENTIALS_FILE = 'credentials.json'
DB_FILE = 'workspace_db.sqlite'
DOWNLOAD_DIR = 'downloaded_files' # Directory to save downloaded Drive files

# Ensure download directory exists
Path(DOWNLOAD_DIR).mkdir(parents=True, exist_ok=True)

# --- SQLite Database Setup ---
def init_db():
    conn = sqlite3.connect(DB_FILE)
    cursor = conn.cursor()

    # Drive Files table
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS drive_files (
            id TEXT PRIMARY KEY,
            name TEXT,
            mime_type TEXT,
            modified_time TEXT,
            file_content_path TEXT, -- Path to locally downloaded content
            is_locally_modified INTEGER DEFAULT 0 -- 1 if modified offline, 0 otherwise
        )
    ''')

    # Gmail Messages table
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS gmail_messages (
            id TEXT PRIMARY KEY,
            thread_id TEXT,
            snippet TEXT,
            subject TEXT,
            sender TEXT,
            received_time TEXT,
            body TEXT, -- Store parsed body
            is_read INTEGER DEFAULT 0 -- 1 if read, 0 otherwise
        )
    ''')

    # Calendar Events table
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS calendar_events (
            id TEXT PRIMARY KEY,
            summary TEXT,
            description TEXT,
            start_time TEXT,
            end_time TEXT,
            location TEXT,
            status TEXT,
            is_locally_modified INTEGER DEFAULT 0
        )
    ''')

    # Pending Sync Queue for offline changes
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS pending_sync (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            operation_type TEXT, -- e.g., 'file_upload', 'email_send', 'calendar_create'
            data TEXT, -- JSON string of the data for the operation
            timestamp TEXT
        )
    ''')
    conn.commit()
    conn.close()

# --- Google Authentication ---
def authenticate_google():
    """Shows user how to authenticate with Google and returns credentials."""
    creds = None
    if os.path.exists(TOKEN_FILE):
        creds = Credentials.from_authorized_user_file(TOKEN_FILE, SCOPES)

    if not creds or not creds.valid:
        if creds and creds.expired and creds.refresh_token:
            print("Refreshing access token...")
            try:
                creds.refresh(Request())
            except Exception as e:
                print(f"Error refreshing token: {e}. Re-authenticating.")
                creds = None # Force re-authentication
        else:
            print("Initiating new Google authentication flow...")
            flow = InstalledAppFlow.from_client_secrets_file(CREDENTIALS_FILE, SCOPES)
            # Run local server to handle authentication redirect
            creds = flow.run_local_server(port=0) # port=0 finds a free port

        # Save the credentials for the next run
        with open(TOKEN_FILE, 'w') as token:
            token.write(creds.to_json())
            print("New tokens saved to token.json")
    return creds

# --- Google API Service Builders ---
def get_drive_service(creds):
    return build('drive', 'v3', credentials=creds)

def get_gmail_service(creds):
    return build('gmail', 'v1', credentials=creds)

def get_calendar_service(creds):
    return build('calendar', 'v3', credentials=creds)

# --- Drive API Functions ---
def fetch_drive_files(service):
    """Fetches and stores Drive file metadata and content locally."""
    print("Fetching Drive files from Google...")
    files = []
    page_token = None
    while True:
        try:
            response = service.files().list(
                q="mimeType != 'application/vnd.google-apps.folder'", # Exclude folders
                pageSize=10,
                fields="nextPageToken, files(id, name, mimeType, modifiedTime)",
                pageToken=page_token
            ).execute()
            files.extend(response.get('files', []))
            page_token = response.get('nextPageToken', None)
            if not page_token:
                break
        except HttpError as error:
            print(f'An error occurred: {error}')
            break

    conn = sqlite3.connect(DB_FILE)
    cursor = conn.cursor()
    for item in files:
        file_id = item['id']
        name = item['name']
        mime_type = item['mimeType']
        modified_time = item['modifiedTime']
        file_content_path = None

        # Check if the file should be downloaded for offline access (e.g., non-Google Workspace files)
        # For Google Docs/Sheets/Slides, you'd typically export them to a common format.
        if not mime_type.startswith('application/vnd.google-apps.'):
            local_path = download_drive_file(service, file_id, name)
            if local_path:
                file_content_path = str(local_path)

        cursor.execute('''
            INSERT OR REPLACE INTO drive_files
            (id, name, mime_type, modified_time, file_content_path)
            VALUES (?, ?, ?, ?, ?)
        ''', (file_id, name, mime_type, modified_time, file_content_path))
    conn.commit()
    conn.close()
    print(f"Fetched and saved {len(files)} Drive files locally.")

def download_drive_file(service, file_id, file_name):
    """Downloads a file from Google Drive."""
    request = service.files().get_media(fileId=file_id)
    file_path = Path(DOWNLOAD_DIR) / file_name
    try:
        with open(file_path, 'wb') as fh:
            downloader = MediaIoBaseDownload(fh, request)
            done = False
            while not done:
                status, done = downloader.next_chunk()
                print(f"Downloading {file_name}: {int(status.progress() * 100)}%.")
        print(f"Downloaded '{file_name}' to {file_path}")
        return file_path
    except HttpError as error:
        print(f'An error occurred during download of {file_name}: {error}')
        return None

def upload_drive_file(service, file_path, file_name, mime_type, file_id=None):
    """Uploads a file to Google Drive or updates an existing one."""
    file_metadata = {'name': file_name}
    media = MediaFileUpload(file_path, mimetype=mime_type, resumable=True)

    try:
        if file_id:
            # Update existing file
            file = service.files().update(
                fileId=file_id,
                media_body=media,
                fields='id, name'
            ).execute()
            print(f"Updated file ID: {file.get('id')}, Name: {file.get('name')}")
        else:
            # Create new file
            file = service.files().create(
                body=file_metadata,
                media_body=media,
                fields='id, name'
            ).execute()
            print(f"Created new file ID: {file.get('id')}, Name: {file.get('name')}")
        return file.get('id')
    except HttpError as error:
        print(f'An error occurred during upload: {error}')
        return None

def get_local_drive_files():
    """Retrieves locally stored Drive file metadata."""
    conn = sqlite3.connect(DB_FILE)
    cursor = conn.cursor()
    cursor.execute('SELECT id, name, mime_type, modified_time, file_content_path FROM drive_files')
    files = []
    for row in cursor.fetchall():
        files.append({
            'id': row[0],
            'name': row[1],
            'mime_type': row[2],
            'modified_time': row[3],
            'file_content_path': row[4]
        })
    conn.close()
    return files

# --- Gmail API Functions ---
def fetch_gmail_messages(service):
    """Fetches Gmail message headers and basic snippets, stores locally."""
    print("Fetching Gmail messages from Google...")
    messages = []
    try:
        # Fetch initial list of messages
        response = service.users().messages().list(userId='me', maxResults=10).execute()
        message_list = response.get('messages', [])

        conn = sqlite3.connect(DB_FILE)
        cursor = conn.cursor()

        for msg_stub in message_list:
            msg_id = msg_stub['id']
            # Fetch full message details
            message = service.users().messages().get(userId='me', id=msg_id, format='full').execute()

            headers = {h['name']: h['value'] for h in message['payload']['headers']}
            subject = headers.get('Subject', 'No Subject')
            sender = headers.get('From', 'Unknown Sender')
            received_time = datetime.datetime.fromtimestamp(int(message['internalDate']) / 1000).isoformat()
            snippet = message.get('snippet', '')

            # Extract body content (simplistic approach, handles plain text and HTML)
            body = ""
            if 'parts' in message['payload']:
                for part in message['payload']['parts']:
                    if part['mimeType'] == 'text/plain' and 'body' in part and 'data' in part['body']:
                        body = part['body']['data']
                        break
                    elif part['mimeType'] == 'text/html' and 'body' in part and 'data' in part['body']:
                        html_body = part['body']['data']
                        soup = BeautifulSoup(base64url_decode(html_body), 'html.parser')
                        body = soup.get_text() # Get plain text from HTML
                        break
            elif 'body' in message['payload'] and 'data' in message['payload']['body']:
                body = message['payload']['body']['data']

            body = base64url_decode(body) # Decode base64url if necessary

            cursor.execute('''
                INSERT OR REPLACE INTO gmail_messages
                (id, thread_id, snippet, subject, sender, received_time, body)
                VALUES (?, ?, ?, ?, ?, ?, ?)
            ''', (msg_id, message.get('threadId'), snippet, subject, sender, received_time, body))
        conn.commit()
        conn.close()
        print(f"Fetched and saved {len(message_list)} Gmail messages locally.")

    except HttpError as error:
        print(f'An error occurred with Gmail API: {error}')

def send_gmail_message(service, to, subject, body_text):
    """Sends a new Gmail message."""
    import base64
    from email.mime.text import MIMEText

    message = MIMEText(body_text)
    message['to'] = to
    message['subject'] = subject
    raw_message = base64.urlsafe_b64encode(message.as_bytes()).decode()

    try:
        sent_message = service.users().messages().send(userId='me', body={'raw': raw_message}).execute()
        print(f'Message Id: {sent_message["id"]} sent to {to}')
        return sent_message['id']
    except HttpError as error:
        print(f'An error occurred sending email: {error}')
        return None

def get_local_gmail_messages():
    """Retrieves locally stored Gmail messages."""
    conn = sqlite3.connect(DB_FILE)
    cursor = conn.cursor()
    cursor.execute('SELECT id, thread_id, snippet, subject, sender, received_time, body FROM gmail_messages ORDER BY received_time DESC')
    messages = []
    for row in cursor.fetchall():
        messages.append({
            'id': row[0],
            'thread_id': row[1],
            'snippet': row[2],
            'subject': row[3],
            'sender': row[4],
            'received_time': row[5],
            'body': row[6]
        })
    conn.close()
    return messages

def base64url_decode(data):
    """Decode base64url string."""
    missing_padding = len(data) % 4
    if missing_padding:
        data += '='* (4 - missing_padding)
    return base64.urlsafe_b64decode(data.encode('utf-8')).decode('utf-8')

# --- Calendar API Functions ---
def fetch_calendar_events(service):
    """Fetches Calendar events and stores them locally."""
    print("Fetching Calendar events from Google...")
    events = []
    now = datetime.datetime.utcnow().isoformat() + 'Z' # 'Z' indicates UTC time

    try:
        events_result = service.events().list(
            calendarId='primary',
            timeMin=now,
            maxResults=10,
            singleEvents=True,
            orderBy='startTime'
        ).execute()
        events.extend(events_result.get('items', []))

        conn = sqlite3.connect(DB_FILE)
        cursor = conn.cursor()
        for event in events:
            event_id = event['id']
            summary = event.get('summary', 'No Title')
            description = event.get('description', '')
            start_time = event['start'].get('dateTime', event['start'].get('date'))
            end_time = event['end'].get('dateTime', event['end'].get('date'))
            location = event.get('location', '')
            status = event.get('status', '')

            cursor.execute('''
                INSERT OR REPLACE INTO calendar_events
                (id, summary, description, start_time, end_time, location, status)
                VALUES (?, ?, ?, ?, ?, ?, ?)
            ''', (event_id, summary, description, start_time, end_time, location, status))
        conn.commit()
        conn.close()
        print(f"Fetched and saved {len(events)} Calendar events locally.")

    except HttpError as error:
        print(f'An error occurred with Calendar API: {error}')

def create_calendar_event(service, summary, description, start_dt, end_dt, location=''):
    """Creates a new calendar event."""
    event = {
        'summary': summary,
        'description': description,
        'start': {
            'dateTime': start_dt.isoformat(),
            'timeZone': 'Asia/Manila', # Current location timezone
        },
        'end': {
            'dateTime': end_dt.isoformat(),
            'timeZone': 'Asia/Manila',
        },
        'location': location,
    }
    try:
        event = service.events().insert(calendarId='primary', body=event).execute()
        print(f"Event created: {event.get('htmlLink')}")
        return event.get('id')
    except HttpError as error:
        print(f'An error occurred creating event: {error}')
        return None

def get_local_calendar_events():
    """Retrieves locally stored Calendar events."""
    conn = sqlite3.connect(DB_FILE)
    cursor = conn.cursor()
    cursor.execute('SELECT id, summary, description, start_time, end_time, location, status FROM calendar_events ORDER BY start_time')
    events = []
    for row in cursor.fetchall():
        events.append({
            'id': row[0],
            'summary': row[1],
            'description': row[2],
            'start_time': row[3],
            'end_time': row[4],
            'location': row[5],
            'status': row[6]
        })
    conn.close()
    return events

# --- Offline Synchronization Logic (Conceptual) ---
def queue_offline_change(operation_type, data):
    """Adds an operation to the pending sync queue."""
    conn = sqlite3.connect(DB_FILE)
    cursor = conn.cursor()
    cursor.execute(
        'INSERT INTO pending_sync (operation_type, data, timestamp) VALUES (?, ?, ?)',
        (operation_type, json.dumps(data), datetime.datetime.now().isoformat())
    )
    conn.commit()
    conn.close()
    print(f"Queued offline change: {operation_type}")

def process_pending_sync(creds):
    """Processes pending offline changes and syncs them to Google Workspace."""
    print("\n--- Attempting to sync pending offline changes ---")
    conn = sqlite3.connect(DB_FILE)
    cursor = conn.cursor()
    cursor.execute('SELECT id, operation_type, data FROM pending_sync ORDER BY timestamp ASC')
    pending_items = cursor.fetchall()

    if not pending_items:
        print("No pending changes to sync.")
        conn.close()
        return

    drive_service = get_drive_service(creds)
    gmail_service = get_gmail_service(creds)
    calendar_service = get_calendar_service(creds)

    for item_id, op_type, data_json in pending_items:
        data = json.loads(data_json)
        success = False
        try:
            if op_type == 'file_upload':
                # For file upload, `data` should contain `file_path`, `file_name`, `mime_type`
                # In a real scenario, you might need to store the actual file content
                # in a temp directory or directly in the DB as a blob if small.
                # For this example, assuming file_path is valid.
                file_path = data.get('file_path')
                if os.path.exists(file_path):
                    uploaded_id = upload_drive_file(drive_service, file_path, data['file_name'], data['mime_type'])
                    if uploaded_id:
                        print(f"Synced file upload: {data['file_name']}")
                        # Optionally update local DB with Google-assigned ID
                        success = True
                else:
                    print(f"File not found for upload: {file_path}. Skipping.")
                    success = True # Consider it processed if file missing locally
            elif op_type == 'email_send':
                sent_id = send_gmail_message(gmail_service, data['to'], data['subject'], data['body'])
                if sent_id:
                    print(f"Synced email send to {data['to']}")
                    success = True
            elif op_type == 'calendar_create':
                start_dt = datetime.datetime.fromisoformat(data['start'])
                end_dt = datetime.datetime.fromisoformat(data['end'])
                event_id = create_calendar_event(calendar_service, data['summary'], data['description'], start_dt, end_dt, data['location'])
                if event_id:
                    print(f"Synced calendar event: {data['summary']}")
                    success = True
            # Add more operation types (e.g., 'file_edit', 'email_reply', 'calendar_update')
            else:
                print(f"Unknown operation type in queue: {op_type}")
                success = True # Remove unknown operations to avoid blocking

            if success:
                cursor.execute('DELETE FROM pending_sync WHERE id = ?', (item_id,))
                conn.commit()
            else:
                print(f"Failed to sync {op_type} for item_id {item_id}. Will retry later.")
        except Exception as e:
            print(f"Error processing {op_type} (item_id {item_id}): {e}. Will retry.")
            # Do not delete from queue, it will be retried on next run if still pending

    conn.close()
    print("--- Finished processing pending offline changes ---")


# --- Main Application Loop/CLI ---
def main():
    init_db()
    creds = authenticate_google()

    if not creds:
        print("Authentication failed. Exiting.")
        return

    # Try to process any pending offline changes first
    # In a long-running app, this would be a background thread/process
    process_pending_sync(creds)

    drive_service = get_drive_service(creds)
    gmail_service = get_gmail_service(creds)
    calendar_service = get_calendar_service(creds)

    while True:
        print("\n--- Google Workspace Offline App ---")
        print("1. Sync from Google (Online)")
        print("2. View Local Drive Files")
        print("3. Upload File (Demonstrate Offline Queue)")
        print("4. View Local Gmail Messages")
        print("5. Send Email (Demonstrate Offline Queue)")
        print("6. View Local Calendar Events")
        print("7. Create Calendar Event (Demonstrate Offline Queue)")
        print("8. Process Pending Sync (Manual Trigger)")
        print("9. Exit")

        choice = input("Enter your choice: ")

        if choice == '1':
            print("Syncing data from Google...")
            fetch_drive_files(drive_service)
            fetch_gmail_messages(gmail_service)
            fetch_calendar_events(calendar_service)
            print("Sync completed.")
        elif choice == '2':
            files = get_local_drive_files()
            if files:
                print("\n--- Local Drive Files ---")
                for f in files:
                    print(f"ID: {f['id']}, Name: {f['name']}, Type: {f['mime_type']}, Path: {f['file_content_path']}")
            else:
                print("No local Drive files found. Sync from Google first.")
        elif choice == '3':
            # This demonstrates queuing an upload. The actual file would need to exist locally.
            dummy_file_name = "offline_upload_test.txt"
            dummy_file_path = Path(DOWNLOAD_DIR) / dummy_file_name
            with open(dummy_file_path, 'w') as f:
                f.write("This file was created offline and should be uploaded.")
            
            queue_offline_change('file_upload', {
                'file_path': str(dummy_file_path),
                'file_name': dummy_file_name,
                'mime_type': 'text/plain'
            })
            print(f"Dummy file '{dummy_file_name}' created and queued for upload.")

        elif choice == '4':
            messages = get_local_gmail_messages()
            if messages:
                print("\n--- Local Gmail Messages ---")
                for msg in messages:
                    print(f"From: {msg['sender']}, Subject: {msg['subject']}, Snippet: {msg['snippet'][:50]}...")
            else:
                print("No local Gmail messages found. Sync from Google first.")
        elif choice == '5':
            to = input("To: ")
            subject = input("Subject: ")
            body = input("Body: ")
            queue_offline_change('email_send', {'to': to, 'subject': subject, 'body': body})
            print("Email queued for sending when online.")
        elif choice == '6':
            events = get_local_calendar_events()
            if events:
                print("\n--- Local Calendar Events ---")
                for event in events:
                    print(f"Summary: {event['summary']}, Start: {event['start_time']}, End: {event['end_time']}")
            else:
                print("No local Calendar events found. Sync from Google first.")
        elif choice == '7':
            summary = input("Event Summary: ")
            description = input("Event Description (optional): ")
            start_str = input("Start Date/Time (YYYY-MM-DDTHH:MM:SS, e.g., 2025-07-15T10:00:00): ")
            end_str = input("End Date/Time (YYYY-MM-DDTHH:MM:SS): ")
            location = input("Location (optional): ")
            try:
                start_dt = datetime.datetime.fromisoformat(start_str)
                end_dt = datetime.datetime.fromisoformat(end_str)
                queue_offline_change('calendar_create', {
                    'summary': summary,
                    'description': description,
                    'start': start_str,
                    'end': end_str,
                    'location': location
                })
                print("Calendar event queued for creation when online.")
            except ValueError:
                print("Invalid date/time format. Please use YYYY-MM-DDTHH:MM:SS.")
        elif choice == '8':
            process_pending_sync(creds)
        elif choice == '9':
            print("Exiting application.")
            break
        else:
            print("Invalid choice. Please try again.")

if __name__ == '__main__':
    main()

How to Run This Python Code:
 * Set up Google Cloud Project:
   * Go to the Google Cloud Console.
   * Create a new project or select an existing one.
   * Navigate to "APIs & Services" > "Enabled APIs & services".
   * Click "Enable APIs and Services" and search for and enable:
     * Google Drive API
     * Gmail API
     * Google Calendar API
   * Go to "APIs & Services" > "Credentials".
   * Click "Create Credentials" > "OAuth client ID".
   * Select "Desktop application" as the Application type. Give it a name.
   * Click "Create".
   * Download the JSON file. Rename it to credentials.json and place it in the same directory as your app.py script.
 * Set up Python Environment:
   * Create a virtual environment (recommended):
     python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

   * Install dependencies:
     pip install -r requirements.txt

 * Run the Application:
   python app.py

First Run / Authentication:
 * The first time you run app.py, it will open a browser window and ask you to log in to your Google account and grant permissions to your application.
 * After successful authentication, a token.json file will be created in your project directory. This file stores your refresh token, allowing the application to maintain "offline access" without re-prompting you every time.
Testing Offline Capabilities:
 * Online Sync: Run the script, choose 1 to "Sync from Google (Online)". This will pull some Drive, Gmail, and Calendar data to your local SQLite database.
 * Go Offline: Disconnect your internet (e.g., turn off Wi-Fi).
 * Perform Offline Actions:
   * Choose 3 to "Upload File". It will create a dummy file and queue it.
   * Choose 5 to "Send Email". It will prompt for details and queue the email.
   * Choose 7 to "Create Calendar Event". It will prompt for details and queue the event.
   * You can still View Local Drive Files, View Local Gmail Messages, View Local Calendar Events (choices 2, 4, 6) because the data is stored locally.
 * Go Online: Reconnect your internet.
 * Process Pending Sync: Choose 8 to "Process Pending Sync (Manual Trigger)". You should see messages indicating that the queued operations are being sent to Google Workspace.
 * Verify: Check your Google Drive, Gmail sent folder, and Google Calendar to see the changes made offline.
Advanced Considerations for a Robust Python Solution:
 * Concurrency/Background Tasks: For a more "advanced" application (especially a server-side one), you'd use libraries like Celery (with a message broker like Redis or RabbitMQ) or APScheduler for scheduled tasks to run process_pending_sync in the background, rather than requiring manual triggering.
 * Error Handling and Retries: Implement more robust try-except blocks around API calls and database operations, with retry logic (e.g., exponential backoff) for transient network or API errors.
 * Conflict Resolution: This example doesn't handle conflicts (e.g., if a file is edited both locally and on Google Drive). A real application would need to:
   * Track etag or modifiedTime for files/resources.
   * Implement "last-write wins," or a more complex merging strategy, or prompt the user for resolution.
 * Incremental Sync (Delta Sync):
   * Google Drive: Use the drive.changes().list() method to get only changes since the last sync token, significantly more efficient than re-listing all files.
   * Gmail: Use history.list() with a historyId to get incremental changes.
   * Calendar: Use the syncToken parameter with events.list() to get changes.
   * Your local database needs to store these syncTokens or historyIds.
 * File Content Management: For Drive, you might want to selectively download content (only for certain file types or if the user explicitly marks them for offline). Storing large binary files directly in SQLite can be inefficient; consider storing them on the local filesystem and just paths in the DB.
 * UI Integration: If this is a desktop app, integrate with a GUI framework (PyQt, Tkinter, Kivy). If it's a backend for a web app, implement a proper REST API using a framework like Flask or FastAPI.
 * Notifications: For a desktop app, you might want desktop notifications when syncs complete or fail.
 * Logging: Use Python's logging module for better debuggability and operational monitoring.
 * Security: Ensure token.json and credentials.json are not exposed. For a multi-user server, tokens must be stored securely (encrypted database) and associated with specific users.



Building an "advanced online/offline Google Workspace" solution with Python involves a slightly different architecture than with Node.js, especially when it comes to the "offline" part.
Key Differences for Python:
 * No Direct Browser-Side Offline (PWA): Python typically runs on a server or as a desktop application. It doesn't have native browser-side features like Service Workers or IndexedDB for managing browser cache or client-side storage directly for a web application.
 * Offline for Python Means Local Storage: For a Python application to be "offline," it means it needs to store data locally on the machine where the Python script is running (e.g., in SQLite database, flat files, or a custom local data store).
 * Backend Focus: Python is excellent for handling the backend logic, including OAuth, interacting with Google APIs, managing data synchronization, and potentially providing an API for a separate frontend (e.g., a web frontend built with React/Vue/Angular, or a desktop GUI with PyQt/Tkinter).
Architectural Approach (Python Backend + Local Data Store):
 * Python Backend/Script:
   * Authentication (OAuth 2.0): Manages obtaining and refreshing access tokens using the google-auth library.
   * Google API Interactions: Uses google-api-python-client to interact with Drive, Gmail, Calendar, etc.
   * Local Data Persistence: Employs a database (like SQLite) or a file system to store a local copy of Google Workspace data.
   * Synchronization Logic: Implements algorithms to compare local data with Google Workspace data and synchronize changes (both ways). This includes handling conflicts.
   * Change Tracking: Utilizes Google Drive's "Changes" API, Gmail's "History" API, and Calendar's "syncToken" for efficient incremental updates rather than full re-downloads.
   * User Interface (Optional): Could be a simple command-line interface (CLI) for a script, or it could expose a REST API for a separate frontend.
 * Local Data Store (e.g., SQLite):
   * Stores downloaded Google Workspace data (file metadata, email headers/bodies, calendar events).
   * Keeps track of pending local changes (e.g., new files to upload, emails to send) when the application is offline.
Prerequisites:
 * Google Cloud Project: Create a project in the Google Cloud Console.
 * Enable APIs: Enable Google Drive API, Gmail API, and Calendar API.
 * OAuth 2.0 Credentials (Desktop App):
   * Go to APIs & Services > Credentials.
   * Create an "OAuth client ID."
   * Select "Desktop application" as the application type. (This is generally easier for Python scripts as it simplifies the redirect URL).
   * Download the JSON credentials file (rename it to credentials.json and place it in your Python project root).
 * Python Environment:
   * Python 3.8+ installed.
   * Install necessary packages: pip install google-api-python-client google-auth-httplib2 google-auth-oauthlib beautifulsoup4 (for parsing email bodies).
Project Structure:
my-python-workspace/
├── credentials.json        # Your Google OAuth credentials
├── token.json              # Stores user tokens after first authentication (managed by google-auth)
├── workspace_db.sqlite     # SQLite database for local data storage
├── app.py                  # Main Python application logic
└── requirements.txt

1. requirements.txt:
google-api-python-client
google-auth-httplib2
google-auth-oauthlib
beautifulsoup4 # For parsing HTML email bodies

2. app.py (Python Application Logic):
This example will demonstrate:
 * OAuth 2.0 for offline access (refresh tokens).
 * Connecting to Google Drive, Gmail, and Calendar APIs.
 * Basic data fetching and saving to a local SQLite database.
 * Placeholder for offline change queuing and background sync logic.
<!-- end list -->
import os
import io
import json
import sqlite3
import datetime
from pathlib import Path
from google.auth.transport.requests import Request
from google.oauth2.credentials import Credentials
from google_auth_oauthlib.flow import InstalledAppFlow
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError
from googleapiclient.http import MediaIoBaseDownload, MediaFileUpload
from bs4 import BeautifulSoup # For parsing HTML email bodies

# --- Configuration ---
# If modifying these scopes, delete the file token.json.
SCOPES = [
    'https://www.googleapis.com/auth/drive',        # Full Drive access
    'https://www.googleapis.com/auth/gmail.modify', # Send, delete, modify email
    'https://www.googleapis.com/auth/calendar',     # Manage calendars
    'https://www.googleapis.com/auth/userinfo.profile',
    'https://www.googleapis.com/auth/userinfo.email',
]

TOKEN_FILE = 'token.json'
CREDENTIALS_FILE = 'credentials.json'
DB_FILE = 'workspace_db.sqlite'
DOWNLOAD_DIR = 'downloaded_files' # Directory to save downloaded Drive files

# Ensure download directory exists
Path(DOWNLOAD_DIR).mkdir(parents=True, exist_ok=True)

# --- SQLite Database Setup ---
def init_db():
    conn = sqlite3.connect(DB_FILE)
    cursor = conn.cursor()

    # Drive Files table
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS drive_files (
            id TEXT PRIMARY KEY,
            name TEXT,
            mime_type TEXT,
            modified_time TEXT,
            file_content_path TEXT, -- Path to locally downloaded content
            is_locally_modified INTEGER DEFAULT 0 -- 1 if modified offline, 0 otherwise
        )
    ''')

    # Gmail Messages table
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS gmail_messages (
            id TEXT PRIMARY KEY,
            thread_id TEXT,
            snippet TEXT,
            subject TEXT,
            sender TEXT,
            received_time TEXT,
            body TEXT, -- Store parsed body
            is_read INTEGER DEFAULT 0 -- 1 if read, 0 otherwise
        )
    ''')

    # Calendar Events table
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS calendar_events (
            id TEXT PRIMARY KEY,
            summary TEXT,
            description TEXT,
            start_time TEXT,
            end_time TEXT,
            location TEXT,
            status TEXT,
            is_locally_modified INTEGER DEFAULT 0
        )
    ''')

    # Pending Sync Queue for offline changes
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS pending_sync (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            operation_type TEXT, -- e.g., 'file_upload', 'email_send', 'calendar_create'
            data TEXT, -- JSON string of the data for the operation
            timestamp TEXT
        )
    ''')
    conn.commit()
    conn.close()

# --- Google Authentication ---
def authenticate_google():
    """Shows user how to authenticate with Google and returns credentials."""
    creds = None
    if os.path.exists(TOKEN_FILE):
        creds = Credentials.from_authorized_user_file(TOKEN_FILE, SCOPES)

    if not creds or not creds.valid:
        if creds and creds.expired and creds.refresh_token:
            print("Refreshing access token...")
            try:
                creds.refresh(Request())
            except Exception as e:
                print(f"Error refreshing token: {e}. Re-authenticating.")
                creds = None # Force re-authentication
        else:
            print("Initiating new Google authentication flow...")
            flow = InstalledAppFlow.from_client_secrets_file(CREDENTIALS_FILE, SCOPES)
            # Run local server to handle authentication redirect
            creds = flow.run_local_server(port=0) # port=0 finds a free port

        # Save the credentials for the next run
        with open(TOKEN_FILE, 'w') as token:
            token.write(creds.to_json())
            print("New tokens saved to token.json")
    return creds

# --- Google API Service Builders ---
def get_drive_service(creds):
    return build('drive', 'v3', credentials=creds)

def get_gmail_service(creds):
    return build('gmail', 'v1', credentials=creds)

def get_calendar_service(creds):
    return build('calendar', 'v3', credentials=creds)

# --- Drive API Functions ---
def fetch_drive_files(service):
    """Fetches and stores Drive file metadata and content locally."""
    print("Fetching Drive files from Google...")
    files = []
    page_token = None
    while True:
        try:
            response = service.files().list(
                q="mimeType != 'application/vnd.google-apps.folder'", # Exclude folders
                pageSize=10,
                fields="nextPageToken, files(id, name, mimeType, modifiedTime)",
                pageToken=page_token
            ).execute()
            files.extend(response.get('files', []))
            page_token = response.get('nextPageToken', None)
            if not page_token:
                break
        except HttpError as error:
            print(f'An error occurred: {error}')
            break

    conn = sqlite3.connect(DB_FILE)
    cursor = conn.cursor()
    for item in files:
        file_id = item['id']
        name = item['name']
        mime_type = item['mimeType']
        modified_time = item['modifiedTime']
        file_content_path = None

        # Check if the file should be downloaded for offline access (e.g., non-Google Workspace files)
        # For Google Docs/Sheets/Slides, you'd typically export them to a common format.
        if not mime_type.startswith('application/vnd.google-apps.'):
            local_path = download_drive_file(service, file_id, name)
            if local_path:
                file_content_path = str(local_path)

        cursor.execute('''
            INSERT OR REPLACE INTO drive_files
            (id, name, mime_type, modified_time, file_content_path)
            VALUES (?, ?, ?, ?, ?)
        ''', (file_id, name, mime_type, modified_time, file_content_path))
    conn.commit()
    conn.close()
    print(f"Fetched and saved {len(files)} Drive files locally.")

def download_drive_file(service, file_id, file_name):
    """Downloads a file from Google Drive."""
    request = service.files().get_media(fileId=file_id)
    file_path = Path(DOWNLOAD_DIR) / file_name
    try:
        with open(file_path, 'wb') as fh:
            downloader = MediaIoBaseDownload(fh, request)
            done = False
            while not done:
                status, done = downloader.next_chunk()
                print(f"Downloading {file_name}: {int(status.progress() * 100)}%.")
        print(f"Downloaded '{file_name}' to {file_path}")
        return file_path
    except HttpError as error:
        print(f'An error occurred during download of {file_name}: {error}')
        return None

def upload_drive_file(service, file_path, file_name, mime_type, file_id=None):
    """Uploads a file to Google Drive or updates an existing one."""
    file_metadata = {'name': file_name}
    media = MediaFileUpload(file_path, mimetype=mime_type, resumable=True)

    try:
        if file_id:
            # Update existing file
            file = service.files().update(
                fileId=file_id,
                media_body=media,
                fields='id, name'
            ).execute()
            print(f"Updated file ID: {file.get('id')}, Name: {file.get('name')}")
        else:
            # Create new file
            file = service.files().create(
                body=file_metadata,
                media_body=media,
                fields='id, name'
            ).execute()
            print(f"Created new file ID: {file.get('id')}, Name: {file.get('name')}")
        return file.get('id')
    except HttpError as error:
        print(f'An error occurred during upload: {error}')
        return None

def get_local_drive_files():
    """Retrieves locally stored Drive file metadata."""
    conn = sqlite3.connect(DB_FILE)
    cursor = conn.cursor()
    cursor.execute('SELECT id, name, mime_type, modified_time, file_content_path FROM drive_files')
    files = []
    for row in cursor.fetchall():
        files.append({
            'id': row[0],
            'name': row[1],
            'mime_type': row[2],
            'modified_time': row[3],
            'file_content_path': row[4]
        })
    conn.close()
    return files

# --- Gmail API Functions ---
def fetch_gmail_messages(service):
    """Fetches Gmail message headers and basic snippets, stores locally."""
    print("Fetching Gmail messages from Google...")
    messages = []
    try:
        # Fetch initial list of messages
        response = service.users().messages().list(userId='me', maxResults=10).execute()
        message_list = response.get('messages', [])

        conn = sqlite3.connect(DB_FILE)
        cursor = conn.cursor()

        for msg_stub in message_list:
            msg_id = msg_stub['id']
            # Fetch full message details
            message = service.users().messages().get(userId='me', id=msg_id, format='full').execute()

            headers = {h['name']: h['value'] for h in message['payload']['headers']}
            subject = headers.get('Subject', 'No Subject')
            sender = headers.get('From', 'Unknown Sender')
            received_time = datetime.datetime.fromtimestamp(int(message['internalDate']) / 1000).isoformat()
            snippet = message.get('snippet', '')

            # Extract body content (simplistic approach, handles plain text and HTML)
            body = ""
            if 'parts' in message['payload']:
                for part in message['payload']['parts']:
                    if part['mimeType'] == 'text/plain' and 'body' in part and 'data' in part['body']:
                        body = part['body']['data']
                        break
                    elif part['mimeType'] == 'text/html' and 'body' in part and 'data' in part['body']:
                        html_body = part['body']['data']
                        soup = BeautifulSoup(base64url_decode(html_body), 'html.parser')
                        body = soup.get_text() # Get plain text from HTML
                        break
            elif 'body' in message['payload'] and 'data' in message['payload']['body']:
                body = message['payload']['body']['data']

            body = base64url_decode(body) # Decode base64url if necessary

            cursor.execute('''
                INSERT OR REPLACE INTO gmail_messages
                (id, thread_id, snippet, subject, sender, received_time, body)
                VALUES (?, ?, ?, ?, ?, ?, ?)
            ''', (msg_id, message.get('threadId'), snippet, subject, sender, received_time, body))
        conn.commit()
        conn.close()
        print(f"Fetched and saved {len(message_list)} Gmail messages locally.")

    except HttpError as error:
        print(f'An error occurred with Gmail API: {error}')

def send_gmail_message(service, to, subject, body_text):
    """Sends a new Gmail message."""
    import base64
    from email.mime.text import MIMEText

    message = MIMEText(body_text)
    message['to'] = to
    message['subject'] = subject
    raw_message = base64.urlsafe_b64encode(message.as_bytes()).decode()

    try:
        sent_message = service.users().messages().send(userId='me', body={'raw': raw_message}).execute()
        print(f'Message Id: {sent_message["id"]} sent to {to}')
        return sent_message['id']
    except HttpError as error:
        print(f'An error occurred sending email: {error}')
        return None

def get_local_gmail_messages():
    """Retrieves locally stored Gmail messages."""
    conn = sqlite3.connect(DB_FILE)
    cursor = conn.cursor()
    cursor.execute('SELECT id, thread_id, snippet, subject, sender, received_time, body FROM gmail_messages ORDER BY received_time DESC')
    messages = []
    for row in cursor.fetchall():
        messages.append({
            'id': row[0],
            'thread_id': row[1],
            'snippet': row[2],
            'subject': row[3],
            'sender': row[4],
            'received_time': row[5],
            'body': row[6]
        })
    conn.close()
    return messages

def base64url_decode(data):
    """Decode base64url string."""
    missing_padding = len(data) % 4
    if missing_padding:
        data += '='* (4 - missing_padding)
    return base64.urlsafe_b64decode(data.encode('utf-8')).decode('utf-8')

# --- Calendar API Functions ---
def fetch_calendar_events(service):
    """Fetches Calendar events and stores them locally."""
    print("Fetching Calendar events from Google...")
    events = []
    now = datetime.datetime.utcnow().isoformat() + 'Z' # 'Z' indicates UTC time

    try:
        events_result = service.events().list(
            calendarId='primary',
            timeMin=now,
            maxResults=10,
            singleEvents=True,
            orderBy='startTime'
        ).execute()
        events.extend(events_result.get('items', []))

        conn = sqlite3.connect(DB_FILE)
        cursor = conn.cursor()
        for event in events:
            event_id = event['id']
            summary = event.get('summary', 'No Title')
            description = event.get('description', '')
            start_time = event['start'].get('dateTime', event['start'].get('date'))
            end_time = event['end'].get('dateTime', event['end'].get('date'))
            location = event.get('location', '')
            status = event.get('status', '')

            cursor.execute('''
                INSERT OR REPLACE INTO calendar_events
                (id, summary, description, start_time, end_time, location, status)
                VALUES (?, ?, ?, ?, ?, ?, ?)
            ''', (event_id, summary, description, start_time, end_time, location, status))
        conn.commit()
        conn.close()
        print(f"Fetched and saved {len(events)} Calendar events locally.")

    except HttpError as error:
        print(f'An error occurred with Calendar API: {error}')

def create_calendar_event(service, summary, description, start_dt, end_dt, location=''):
    """Creates a new calendar event."""
    event = {
        'summary': summary,
        'description': description,
        'start': {
            'dateTime': start_dt.isoformat(),
            'timeZone': 'Asia/Manila', # Current location timezone
        },
        'end': {
            'dateTime': end_dt.isoformat(),
            'timeZone': 'Asia/Manila',
        },
        'location': location,
    }
    try:
        event = service.events().insert(calendarId='primary', body=event).execute()
        print(f"Event created: {event.get('htmlLink')}")
        return event.get('id')
    except HttpError as error:
        print(f'An error occurred creating event: {error}')
        return None

def get_local_calendar_events():
    """Retrieves locally stored Calendar events."""
    conn = sqlite3.connect(DB_FILE)
    cursor = conn.cursor()
    cursor.execute('SELECT id, summary, description, start_time, end_time, location, status FROM calendar_events ORDER BY start_time')
    events = []
    for row in cursor.fetchall():
        events.append({
            'id': row[0],
            'summary': row[1],
            'description': row[2],
            'start_time': row[3],
            'end_time': row[4],
            'location': row[5],
            'status': row[6]
        })
    conn.close()
    return events

# --- Offline Synchronization Logic (Conceptual) ---
def queue_offline_change(operation_type, data):
    """Adds an operation to the pending sync queue."""
    conn = sqlite3.connect(DB_FILE)
    cursor = conn.cursor()
    cursor.execute(
        'INSERT INTO pending_sync (operation_type, data, timestamp) VALUES (?, ?, ?)',
        (operation_type, json.dumps(data), datetime.datetime.now().isoformat())
    )
    conn.commit()
    conn.close()
    print(f"Queued offline change: {operation_type}")

def process_pending_sync(creds):
    """Processes pending offline changes and syncs them to Google Workspace."""
    print("\n--- Attempting to sync pending offline changes ---")
    conn = sqlite3.connect(DB_FILE)
    cursor = conn.cursor()
    cursor.execute('SELECT id, operation_type, data FROM pending_sync ORDER BY timestamp ASC')
    pending_items = cursor.fetchall()

    if not pending_items:
        print("No pending changes to sync.")
        conn.close()
        return

    drive_service = get_drive_service(creds)
    gmail_service = get_gmail_service(creds)
    calendar_service = get_calendar_service(creds)

    for item_id, op_type, data_json in pending_items:
        data = json.loads(data_json)
        success = False
        try:
            if op_type == 'file_upload':
                # For file upload, `data` should contain `file_path`, `file_name`, `mime_type`
                # In a real scenario, you might need to store the actual file content
                # in a temp directory or directly in the DB as a blob if small.
                # For this example, assuming file_path is valid.
                file_path = data.get('file_path')
                if os.path.exists(file_path):
                    uploaded_id = upload_drive_file(drive_service, file_path, data['file_name'], data['mime_type'])
                    if uploaded_id:
                        print(f"Synced file upload: {data['file_name']}")
                        # Optionally update local DB with Google-assigned ID
                        success = True
                else:
                    print(f"File not found for upload: {file_path}. Skipping.")
                    success = True # Consider it processed if file missing locally
            elif op_type == 'email_send':
                sent_id = send_gmail_message(gmail_service, data['to'], data['subject'], data['body'])
                if sent_id:
                    print(f"Synced email send to {data['to']}")
                    success = True
            elif op_type == 'calendar_create':
                start_dt = datetime.datetime.fromisoformat(data['start'])
                end_dt = datetime.datetime.fromisoformat(data['end'])
                event_id = create_calendar_event(calendar_service, data['summary'], data['description'], start_dt, end_dt, data['location'])
                if event_id:
                    print(f"Synced calendar event: {data['summary']}")
                    success = True
            # Add more operation types (e.g., 'file_edit', 'email_reply', 'calendar_update')
            else:
                print(f"Unknown operation type in queue: {op_type}")
                success = True # Remove unknown operations to avoid blocking

            if success:
                cursor.execute('DELETE FROM pending_sync WHERE id = ?', (item_id,))
                conn.commit()
            else:
                print(f"Failed to sync {op_type} for item_id {item_id}. Will retry later.")
        except Exception as e:
            print(f"Error processing {op_type} (item_id {item_id}): {e}. Will retry.")
            # Do not delete from queue, it will be retried on next run if still pending

    conn.close()
    print("--- Finished processing pending offline changes ---")


# --- Main Application Loop/CLI ---
def main():
    init_db()
    creds = authenticate_google()

    if not creds:
        print("Authentication failed. Exiting.")
        return

    # Try to process any pending offline changes first
    # In a long-running app, this would be a background thread/process
    process_pending_sync(creds)

    drive_service = get_drive_service(creds)
    gmail_service = get_gmail_service(creds)
    calendar_service = get_calendar_service(creds)

    while True:
        print("\n--- Google Workspace Offline App ---")
        print("1. Sync from Google (Online)")
        print("2. View Local Drive Files")
        print("3. Upload File (Demonstrate Offline Queue)")
        print("4. View Local Gmail Messages")
        print("5. Send Email (Demonstrate Offline Queue)")
        print("6. View Local Calendar Events")
        print("7. Create Calendar Event (Demonstrate Offline Queue)")
        print("8. Process Pending Sync (Manual Trigger)")
        print("9. Exit")

        choice = input("Enter your choice: ")

        if choice == '1':
            print("Syncing data from Google...")
            fetch_drive_files(drive_service)
            fetch_gmail_messages(gmail_service)
            fetch_calendar_events(calendar_service)
            print("Sync completed.")
        elif choice == '2':
            files = get_local_drive_files()
            if files:
                print("\n--- Local Drive Files ---")
                for f in files:
                    print(f"ID: {f['id']}, Name: {f['name']}, Type: {f['mime_type']}, Path: {f['file_content_path']}")
            else:
                print("No local Drive files found. Sync from Google first.")
        elif choice == '3':
            # This demonstrates queuing an upload. The actual file would need to exist locally.
            dummy_file_name = "offline_upload_test.txt"
            dummy_file_path = Path(DOWNLOAD_DIR) / dummy_file_name
            with open(dummy_file_path, 'w') as f:
                f.write("This file was created offline and should be uploaded.")
            
            queue_offline_change('file_upload', {
                'file_path': str(dummy_file_path),
                'file_name': dummy_file_name,
                'mime_type': 'text/plain'
            })
            print(f"Dummy file '{dummy_file_name}' created and queued for upload.")

        elif choice == '4':
            messages = get_local_gmail_messages()
            if messages:
                print("\n--- Local Gmail Messages ---")
                for msg in messages:
                    print(f"From: {msg['sender']}, Subject: {msg['subject']}, Snippet: {msg['snippet'][:50]}...")
            else:
                print("No local Gmail messages found. Sync from Google first.")
        elif choice == '5':
            to = input("To: ")
            subject = input("Subject: ")
            body = input("Body: ")
            queue_offline_change('email_send', {'to': to, 'subject': subject, 'body': body})
            print("Email queued for sending when online.")
        elif choice == '6':
            events = get_local_calendar_events()
            if events:
                print("\n--- Local Calendar Events ---")
                for event in events:
                    print(f"Summary: {event['summary']}, Start: {event['start_time']}, End: {event['end_time']}")
            else:
                print("No local Calendar events found. Sync from Google first.")
        elif choice == '7':
            summary = input("Event Summary: ")
            description = input("Event Description (optional): ")
            start_str = input("Start Date/Time (YYYY-MM-DDTHH:MM:SS, e.g., 2025-07-15T10:00:00): ")
            end_str = input("End Date/Time (YYYY-MM-DDTHH:MM:SS): ")
            location = input("Location (optional): ")
            try:
                start_dt = datetime.datetime.fromisoformat(start_str)
                end_dt = datetime.datetime.fromisoformat(end_str)
                queue_offline_change('calendar_create', {
                    'summary': summary,
                    'description': description,
                    'start': start_str,
                    'end': end_str,
                    'location': location
                })
                print("Calendar event queued for creation when online.")
            except ValueError:
                print("Invalid date/time format. Please use YYYY-MM-DDTHH:MM:SS.")
        elif choice == '8':
            process_pending_sync(creds)
        elif choice == '9':
            print("Exiting application.")
            break
        else:
            print("Invalid choice. Please try again.")

if __name__ == '__main__':
    main()

How to Run This Python Code:
 * Set up Google Cloud Project:
   * Go to the Google Cloud Console.
   * Create a new project or select an existing one.
   * Navigate to "APIs & Services" > "Enabled APIs & services".
   * Click "Enable APIs and Services" and search for and enable:
     * Google Drive API
     * Gmail API
     * Google Calendar API
   * Go to "APIs & Services" > "Credentials".
   * Click "Create Credentials" > "OAuth client ID".
   * Select "Desktop application" as the Application type. Give it a name.
   * Click "Create".
   * Download the JSON file. Rename it to credentials.json and place it in the same directory as your app.py script.
 * Set up Python Environment:
   * Create a virtual environment (recommended):
     python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

   * Install dependencies:
     pip install -r requirements.txt

 * Run the Application:
   python app.py

First Run / Authentication:
 * The first time you run app.py, it will open a browser window and ask you to log in to your Google account and grant permissions to your application.
 * After successful authentication, a token.json file will be created in your project directory. This file stores your refresh token, allowing the application to maintain "offline access" without re-prompting you every time.
Testing Offline Capabilities:
 * Online Sync: Run the script, choose 1 to "Sync from Google (Online)". This will pull some Drive, Gmail, and Calendar data to your local SQLite database.
 * Go Offline: Disconnect your internet (e.g., turn off Wi-Fi).
 * Perform Offline Actions:
   * Choose 3 to "Upload File". It will create a dummy file and queue it.
   * Choose 5 to "Send Email". It will prompt for details and queue the email.
   * Choose 7 to "Create Calendar Event". It will prompt for details and queue the event.
   * You can still View Local Drive Files, View Local Gmail Messages, View Local Calendar Events (choices 2, 4, 6) because the data is stored locally.
 * Go Online: Reconnect your internet.
 * Process Pending Sync: Choose 8 to "Process Pending Sync (Manual Trigger)". You should see messages indicating that the queued operations are being sent to Google Workspace.
 * Verify: Check your Google Drive, Gmail sent folder, and Google Calendar to see the changes made offline.
Advanced Considerations for a Robust Python Solution:
 * Concurrency/Background Tasks: For a more "advanced" application (especially a server-side one), you'd use libraries like Celery (with a message broker like Redis or RabbitMQ) or APScheduler for scheduled tasks to run process_pending_sync in the background, rather than requiring manual triggering.
 * Error Handling and Retries: Implement more robust try-except blocks around API calls and database operations, with retry logic (e.g., exponential backoff) for transient network or API errors.
 * Conflict Resolution: This example doesn't handle conflicts (e.g., if a file is edited both locally and on Google Drive). A real application would need to:
   * Track etag or modifiedTime for files/resources.
   * Implement "last-write wins," or a more complex merging strategy, or prompt the user for resolution.
 * Incremental Sync (Delta Sync):
   * Google Drive: Use the drive.changes().list() method to get only changes since the last sync token, significantly more efficient than re-listing all files.
   * Gmail: Use history.list() with a historyId to get incremental changes.
   * Calendar: Use the syncToken parameter with events.list() to get changes.
   * Your local database needs to store these syncTokens or historyIds.
 * File Content Management: For Drive, you might want to selectively download content (only for certain file types or if the user explicitly marks them for offline). Storing large binary files directly in SQLite can be inefficient; consider storing them on the local filesystem and just paths in the DB.
 * UI Integration: If this is a desktop app, integrate with a GUI framework (PyQt, Tkinter, Kivy). If it's a backend for a web app, implement a proper REST API using a framework like Flask or FastAPI.
 * Notifications: For a desktop app, you might want desktop notifications when syncs complete or fail.
 * Logging: Use Python's logging module for better debuggability and operational monitoring.
 * Security: Ensure token.json and credentials.json are not exposed. For a multi-user server, tokens must be stored securely (encrypted database) and associated with specific users.



import os
import io
import json
import sqlite3
import datetime
from pathlib import Path
from google.auth.transport.requests import Request
from google.oauth2.credentials import Credentials
from google_auth_oauthlib.flow import InstalledAppFlow
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError
from googleapiclient.http import MediaIoBaseDownload, MediaFileUpload
from bs4 import BeautifulSoup # For parsing HTML email bodies

# --- Configuration ---
# If modifying these scopes, delete the file token.json.
SCOPES = [
    'https://www.googleapis.com/auth/drive',        # Full Drive access
    'https://www.googleapis.com/auth/gmail.modify', # Send, delete, modify email
    'https://www.googleapis.com/auth/calendar',     # Manage calendars
    'https://www.googleapis.com/auth/userinfo.profile',
    'https://www.googleapis.com/auth/userinfo.email',
]

TOKEN_FILE = 'token.json'
CREDENTIALS_FILE = 'credentials.json'
DB_FILE = 'workspace_db.sqlite'
DOWNLOAD_DIR = 'downloaded_files' # Directory to save downloaded Drive files

# Ensure download directory exists
Path(DOWNLOAD_DIR).mkdir(parents=True, exist_ok=True)

# --- SQLite Database Setup ---
def init_db():
    conn = sqlite3.connect(DB_FILE)
    cursor = conn.cursor()

    # Drive Files table
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS drive_files (
            id TEXT PRIMARY KEY,
            name TEXT,
            mime_type TEXT,
            modified_time TEXT,
            file_content_path TEXT, -- Path to locally downloaded content
            is_locally_modified INTEGER DEFAULT 0 -- 1 if modified offline, 0 otherwise
        )
    ''')

    # Gmail Messages table
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS gmail_messages (
            id TEXT PRIMARY KEY,
            thread_id TEXT,
            snippet TEXT,
            subject TEXT,
            sender TEXT,
            received_time TEXT,
            body TEXT, -- Store parsed body
            is_read INTEGER DEFAULT 0 -- 1 if read, 0 otherwise
        )
    ''')

    # Calendar Events table
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS calendar_events (
            id TEXT PRIMARY KEY,
            summary TEXT,
            description TEXT,
            start_time TEXT,
            end_time TEXT,
            location TEXT,
            status TEXT,
            is_locally_modified INTEGER DEFAULT 0
        )
    ''')

    # Pending Sync Queue for offline changes
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS pending_sync (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            operation_type TEXT, -- e.g., 'file_upload', 'email_send', 'calendar_create'
            data TEXT, -- JSON string of the data for the operation
            timestamp TEXT
        )
    ''')
    conn.commit()
    conn.close()

# --- Google Authentication ---
def authenticate_google():
    """Shows user how to authenticate with Google and returns credentials."""
    creds = None
    if os.path.exists(TOKEN_FILE):
        creds = Credentials.from_authorized_user_file(TOKEN_FILE, SCOPES)

    if not creds or not creds.valid:
        if creds and creds.expired and creds.refresh_token:
            print("Refreshing access token...")
            try:
                creds.refresh(Request())
            except Exception as e:
                print(f"Error refreshing token: {e}. Re-authenticating.")
                creds = None # Force re-authentication
        else:
            print("Initiating new Google authentication flow...")
            flow = InstalledAppFlow.from_client_secrets_file(CREDENTIALS_FILE, SCOPES)
            # Run local server to handle authentication redirect
            creds = flow.run_local_server(port=0) # port=0 finds a free port

        # Save the credentials for the next run
        with open(TOKEN_FILE, 'w') as token:
            token.write(creds.to_json())
            print("New tokens saved to token.json")
    return creds

# --- Google API Service Builders ---
def get_drive_service(creds):
    return build('drive', 'v3', credentials=creds)

def get_gmail_service(creds):
    return build('gmail', 'v1', credentials=creds)

def get_calendar_service(creds):
    return build('calendar', 'v3', credentials=creds)

# --- Drive API Functions ---
def fetch_drive_files(service):
    """Fetches and stores Drive file metadata and content locally."""
    print("Fetching Drive files from Google...")
    files = []
    page_token = None
    while True:
        try:
            response = service.files().list(
                q="mimeType != 'application/vnd.google-apps.folder'", # Exclude folders
                pageSize=10,
                fields="nextPageToken, files(id, name, mimeType, modifiedTime)",
                pageToken=page_token
            ).execute()
            files.extend(response.get('files', []))
            page_token = response.get('nextPageToken', None)
            if not page_token:
                break
        except HttpError as error:
            print(f'An error occurred: {error}')
            break

    conn = sqlite3.connect(DB_FILE)
    cursor = conn.cursor()
    for item in files:
        file_id = item['id']
        name = item['name']
        mime_type = item['mimeType']
        modified_time = item['modifiedTime']
        file_content_path = None

        # Check if the file should be downloaded for offline access (e.g., non-Google Workspace files)
        # For Google Docs/Sheets/Slides, you'd typically export them to a common format.
        if not mime_type.startswith('application/vnd.google-apps.'):
            local_path = download_drive_file(service, file_id, name)
            if local_path:
                file_content_path = str(local_path)

        cursor.execute('''
            INSERT OR REPLACE INTO drive_files
            (id, name, mime_type, modified_time, file_content_path)
            VALUES (?, ?, ?, ?, ?)
        ''', (file_id, name, mime_type, modified_time, file_content_path))
    conn.commit()
    conn.close()
    print(f"Fetched and saved {len(files)} Drive files locally.")

def download_drive_file(service, file_id, file_name):
    """Downloads a file from Google Drive."""
    request = service.files().get_media(fileId=file_id)
    file_path = Path(DOWNLOAD_DIR) / file_name
    try:
        with open(file_path, 'wb') as fh:
            downloader = MediaIoBaseDownload(fh, request)
            done = False
            while not done:
                status, done = downloader.next_chunk()
                print(f"Downloading {file_name}: {int(status.progress() * 100)}%.")
        print(f"Downloaded '{file_name}' to {file_path}")
        return file_path
    except HttpError as error:
        print(f'An error occurred during download of {file_name}: {error}')
        return None

def upload_drive_file(service, file_path, file_name, mime_type, file_id=None):
    """Uploads a file to Google Drive or updates an existing one."""
    file_metadata = {'name': file_name}
    media = MediaFileUpload(file_path, mimetype=mime_type, resumable=True)

    try:
        if file_id:
            # Update existing file
            file = service.files().update(
                fileId=file_id,
                media_body=media,
                fields='id, name'
            ).execute()
            print(f"Updated file ID: {file.get('id')}, Name: {file.get('name')}")
        else:
            # Create new file
            file = service.files().create(
                body=file_metadata,
                media_body=media,
                fields='id, name'
            ).execute()
            print(f"Created new file ID: {file.get('id')}, Name: {file.get('name')}")
        return file.get('id')
    except HttpError as error:
        print(f'An error occurred during upload: {error}')
        return None

def get_local_drive_files():
    """Retrieves locally stored Drive file metadata."""
    conn = sqlite3.connect(DB_FILE)
    cursor = conn.cursor()
    cursor.execute('SELECT id, name, mime_type, modified_time, file_content_path FROM drive_files')
    files = []
    for row in cursor.fetchall():
        files.append({
            'id': row[0],
            'name': row[1],
            'mime_type': row[2],
            'modified_time': row[3],
            'file_content_path': row[4]
        })
    conn.close()
    return files

# --- Gmail API Functions ---
def fetch_gmail_messages(service):
    """Fetches Gmail message headers and basic snippets, stores locally."""
    print("Fetching Gmail messages from Google...")
    messages = []
    try:
        # Fetch initial list of messages
        response = service.users().messages().list(userId='me', maxResults=10).execute()
        message_list = response.get('messages', [])

        conn = sqlite3.connect(DB_FILE)
        cursor = conn.cursor()

        for msg_stub in message_list:
            msg_id = msg_stub['id']
            # Fetch full message details
            message = service.users().messages().get(userId='me', id=msg_id, format='full').execute()

            headers = {h['name']: h['value'] for h in message['payload']['headers']}
            subject = headers.get('Subject', 'No Subject')
            sender = headers.get('From', 'Unknown Sender')
            received_time = datetime.datetime.fromtimestamp(int(message['internalDate']) / 1000).isoformat()
            snippet = message.get('snippet', '')

            # Extract body content (simplistic approach, handles plain text and HTML)
            body = ""
            if 'parts' in message['payload']:
                for part in message['payload']['parts']:
                    if part['mimeType'] == 'text/plain' and 'body' in part and 'data' in part['body']:
                        body = part['body']['data']
                        break
                    elif part['mimeType'] == 'text/html' and 'body' in part and 'data' in part['body']:
                        html_body = part['body']['data']
                        soup = BeautifulSoup(base64url_decode(html_body), 'html.parser')
                        body = soup.get_text() # Get plain text from HTML
                        break
            elif 'body' in message['payload'] and 'data' in message['payload']['body']:
                body = message['payload']['body']['data']

            body = base64url_decode(body) # Decode base64url if necessary

            cursor.execute('''
                INSERT OR REPLACE INTO gmail_messages
                (id, thread_id, snippet, subject, sender, received_time, body)
                VALUES (?, ?, ?, ?, ?, ?, ?)
            ''', (msg_id, message.get('threadId'), snippet, subject, sender, received_time, body))
        conn.commit()
        conn.close()
        print(f"Fetched and saved {len(message_list)} Gmail messages locally.")

    except HttpError as error:
        print(f'An error occurred with Gmail API: {error}')

def send_gmail_message(service, to, subject, body_text):
    """Sends a new Gmail message."""
    import base64
    from email.mime.text import MIMEText

    message = MIMEText(body_text)
    message['to'] = to
    message['subject'] = subject
    raw_message = base64.urlsafe_b64encode(message.as_bytes()).decode()

    try:
        sent_message = service.users().messages().send(userId='me', body={'raw': raw_message}).execute()
        print(f'Message Id: {sent_message["id"]} sent to {to}')
        return sent_message['id']
    except HttpError as error:
        print(f'An error occurred sending email: {error}')
        return None

def get_local_gmail_messages():
    """Retrieves locally stored Gmail messages."""
    conn = sqlite3.connect(DB_FILE)
    cursor = conn.cursor()
    cursor.execute('SELECT id, thread_id, snippet, subject, sender, received_time, body FROM gmail_messages ORDER BY received_time DESC')
    messages = []
    for row in cursor.fetchall():
        messages.append({
            'id': row[0],
            'thread_id': row[1],
            'snippet': row[2],
            'subject': row[3],
            'sender': row[4],
            'received_time': row[5],
            'body': row[6]
        })
    conn.close()
    return messages

def base64url_decode(data):
    """Decode base64url string."""
    missing_padding = len(data) % 4
    if missing_padding:
        data += '='* (4 - missing_padding)
    return base64.urlsafe_b64decode(data.encode('utf-8')).decode('utf-8')

# --- Calendar API Functions ---
def fetch_calendar_events(service):
    """Fetches Calendar events and stores them locally."""
    print("Fetching Calendar events from Google...")
    events = []
    now = datetime.datetime.utcnow().isoformat() + 'Z' # 'Z' indicates UTC time

    try:
        events_result = service.events().list(
            calendarId='primary',
            timeMin=now,
            maxResults=10,
            singleEvents=True,
            orderBy='startTime'
        ).execute()
        events.extend(events_result.get('items', []))

        conn = sqlite3.connect(DB_FILE)
        cursor = conn.cursor()
        for event in events:
            event_id = event['id']
            summary = event.get('summary', 'No Title')
            description = event.get('description', '')
            start_time = event['start'].get('dateTime', event['start'].get('date'))
            end_time = event['end'].get('dateTime', event['end'].get('date'))
            location = event.get('location', '')
            status = event.get('status', '')

            cursor.execute('''
                INSERT OR REPLACE INTO calendar_events
                (id, summary, description, start_time, end_time, location, status)
                VALUES (?, ?, ?, ?, ?, ?, ?)
            ''', (event_id, summary, description, start_time, end_time, location, status))
        conn.commit()
        conn.close()
        print(f"Fetched and saved {len(events)} Calendar events locally.")

    except HttpError as error:
        print(f'An error occurred with Calendar API: {error}')

def create_calendar_event(service, summary, description, start_dt, end_dt, location=''):
    """Creates a new calendar event."""
    event = {
        'summary': summary,
        'description': description,
        'start': {
            'dateTime': start_dt.isoformat(),
            'timeZone': 'Asia/Manila', # Current location timezone
        },
        'end': {
            'dateTime': end_dt.isoformat(),
            'timeZone': 'Asia/Manila',
        },
        'location': location,
    }
    try:
        event = service.events().insert(calendarId='primary', body=event).execute()
        print(f"Event created: {event.get('htmlLink')}")
        return event.get('id')
    except HttpError as error:
        print(f'An error occurred creating event: {error}')
        return None

def get_local_calendar_events():
    """Retrieves locally stored Calendar events."""
    conn = sqlite3.connect(DB_FILE)
    cursor = conn.cursor()
    cursor.execute('SELECT id, summary, description, start_time, end_time, location, status FROM calendar_events ORDER BY start_time')
    events = []
    for row in cursor.fetchall():
        events.append({
            'id': row[0],
            'summary': row[1],
            'description': row[2],
            'start_time': row[3],
            'end_time': row[4],
            'location': row[5],
            'status': row[6]
        })
    conn.close()
    return events

# --- Offline Synchronization Logic (Conceptual) ---
def queue_offline_change(operation_type, data):
    """Adds an operation to the pending sync queue."""
    conn = sqlite3.connect(DB_FILE)
    cursor = conn.cursor()
    cursor.execute(
        'INSERT INTO pending_sync (operation_type, data, timestamp) VALUES (?, ?, ?)',
        (operation_type, json.dumps(data), datetime.datetime.now().isoformat())
    )
    conn.commit()
    conn.close()
    print(f"Queued offline change: {operation_type}")

def process_pending_sync(creds):
    """Processes pending offline changes and syncs them to Google Workspace."""
    print("\n--- Attempting to sync pending offline changes ---")
    conn = sqlite3.connect(DB_FILE)
    cursor = conn.cursor()
    cursor.execute('SELECT id, operation_type, data FROM pending_sync ORDER BY timestamp ASC')
    pending_items = cursor.fetchall()

    if not pending_items:
        print("No pending changes to sync.")
        conn.close()
        return

    drive_service = get_drive_service(creds)
    gmail_service = get_gmail_service(creds)
    calendar_service = get_calendar_service(creds)

    for item_id, op_type, data_json in pending_items:
        data = json.loads(data_json)
        success = False
        try:
            if op_type == 'file_upload':
                # For file upload, `data` should contain `file_path`, `file_name`, `mime_type`
                # In a real scenario, you might need to store the actual file content
                # in a temp directory or directly in the DB as a blob if small.
                # For this example, assuming file_path is valid.
                file_path = data.get('file_path')
                if os.path.exists(file_path):
                    uploaded_id = upload_drive_file(drive_service, file_path, data['file_name'], data['mime_type'])
                    if uploaded_id:
                        print(f"Synced file upload: {data['file_name']}")
                        # Optionally update local DB with Google-assigned ID
                        success = True
                else:
                    print(f"File not found for upload: {file_path}. Skipping.")
                    success = True # Consider it processed if file missing locally
            elif op_type == 'email_send':
                sent_id = send_gmail_message(gmail_service, data['to'], data['subject'], data['body'])
                if sent_id:
                    print(f"Synced email send to {data['to']}")
                    success = True
            elif op_type == 'calendar_create':
                start_dt = datetime.datetime.fromisoformat(data['start'])
                end_dt = datetime.datetime.fromisoformat(data['end'])
                event_id = create_calendar_event(calendar_service, data['summary'], data['description'], start_dt, end_dt, data['location'])
                if event_id:
                    print(f"Synced calendar event: {data['summary']}")
                    success = True
            # Add more operation types (e.g., 'file_edit', 'email_reply', 'calendar_update')
            else:
                print(f"Unknown operation type in queue: {op_type}")
                success = True # Remove unknown operations to avoid blocking

            if success:
                cursor.execute('DELETE FROM pending_sync WHERE id = ?', (item_id,))
                conn.commit()
            else:
                print(f"Failed to sync {op_type} for item_id {item_id}. Will retry later.")
        except Exception as e:
            print(f"Error processing {op_type} (item_id {item_id}): {e}. Will retry.")
            # Do not delete from queue, it will be retried on next run if still pending

    conn.close()
    print("--- Finished processing pending offline changes ---")


# --- Main Application Loop/CLI ---
def main():
    init_db()
    creds = authenticate_google()

    if not creds:
        print("Authentication failed. Exiting.")
        return

    # Try to process any pending offline changes first
    # In a long-running app, this would be a background thread/process
    process_pending_sync(creds)

    drive_service = get_drive_service(creds)
    gmail_service = get_gmail_service(creds)
    calendar_service = get_calendar_service(creds)

    while True:
        print("\n--- Google Workspace Offline App ---")
        print("1. Sync from Google (Online)")
        print("2. View Local Drive Files")
        print("3. Upload File (Demonstrate Offline Queue)")
        print("4. View Local Gmail Messages")
        print("5. Send Email (Demonstrate Offline Queue)")
        print("6. View Local Calendar Events")
        print("7. Create Calendar Event (Demonstrate Offline Queue)")
        print("8. Process Pending Sync (Manual Trigger)")
        print("9. Exit")

        choice = input("Enter your choice: ")

        if choice == '1':
            print("Syncing data from Google...")
            fetch_drive_files(drive_service)
            fetch_gmail_messages(gmail_service)
            fetch_calendar_events(calendar_service)
            print("Sync completed.")
        elif choice == '2':
            files = get_local_drive_files()
            if files:
                print("\n--- Local Drive Files ---")
                for f in files:
                    print(f"ID: {f['id']}, Name: {f['name']}, Type: {f['mime_type']}, Path: {f['file_content_path']}")
            else:
                print("No local Drive files found. Sync from Google first.")
        elif choice == '3':
            # This demonstrates queuing an upload. The actual file would need to exist locally.
            dummy_file_name = "offline_upload_test.txt"
            dummy_file_path = Path(DOWNLOAD_DIR) / dummy_file_name
            with open(dummy_file_path, 'w') as f:
                f.write("This file was created offline and should be uploaded.")
            
            queue_offline_change('file_upload', {
                'file_path': str(dummy_file_path),
                'file_name': dummy_file_name,
                'mime_type': 'text/plain'
            })
            print(f"Dummy file '{dummy_file_name}' created and queued for upload.")

        elif choice == '4':
            messages = get_local_gmail_messages()
            if messages:
                print("\n--- Local Gmail Messages ---")
                for msg in messages:
                    print(f"From: {msg['sender']}, Subject: {msg['subject']}, Snippet: {msg['snippet'][:50]}...")
            else:
                print("No local Gmail messages found. Sync from Google first.")
        elif choice == '5':
            to = input("To: ")
            subject = input("Subject: ")
            body = input("Body: ")
            queue_offline_change('email_send', {'to': to, 'subject': subject, 'body': body})
            print("Email queued for sending when online.")
        elif choice == '6':
            events = get_local_calendar_events()
            if events:
                print("\n--- Local Calendar Events ---")
                for event in events:
                    print(f"Summary: {event['summary']}, Start: {event['start_time']}, End: {event['end_time']}")
            else:
                print("No local Calendar events found. Sync from Google first.")
        elif choice == '7':
            summary = input("Event Summary: ")
            description = input("Event Description (optional): ")
            start_str = input("Start Date/Time (YYYY-MM-DDTHH:MM:SS, e.g., 2025-07-15T10:00:00): ")
            end_str = input("End Date/Time (YYYY-MM-DDTHH:MM:SS): ")
            location = input("Location (optional): ")
            try:
                start_dt = datetime.datetime.fromisoformat(start_str)
                end_dt = datetime.datetime.fromisoformat(end_str)
                queue_offline_change('calendar_create', {
                    'summary': summary,
                    'description': description,
                    'start': start_str,
                    'end': end_str,
                    'location': location
                })
                print("Calendar event queued for creation when online.")
            except ValueError:
                print("Invalid date/time format. Please use YYYY-MM-DDTHH:MM:SS.")
        elif choice == '8':
            process_pending_sync(creds)
        elif choice == '9':
            print("Exiting application.")
            break
        else:
            print("Invalid choice. Please try again.")

if __name__ == '__main__':
    main()



python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate



pip install -r requirements.txt



python app.py



I can't provide the current date.
Building an "advanced online/offline Google Workspace" with React involves creating a Progressive Web Application (PWA) that leverages modern browser APIs for offline capabilities, while interacting with a backend (like the Node.js or Python server we discussed) to communicate with Google Workspace APIs.
Key Technologies for a React PWA:
 * React: For building the user interface.
 * Create React App (CRA) or Vite: For bootstrapping the React project and handling build processes. CRA (or a custom setup) often includes a service worker by default.
 * Service Workers: The core technology for intercepting network requests, caching assets (HTML, CSS, JS, images), and serving content from the cache when offline. They also enable background sync.
 * IndexedDB (with a wrapper like localForage or Dexie.js): For persistent client-side storage of application data (Google Drive file metadata, email bodies, calendar events, pending offline changes).
 * Background Sync API: Allows the browser to defer network requests (like submitting an email or uploading a file) until connectivity is restored, even if the user closes the tab.
 * Network Detection: JavaScript's navigator.onLine and window.addEventListener('online')/'offline') for real-time network status.
 * Google OAuth 2.0 (Implicit Flow or Authorization Code Flow via Backend): For user authentication. For PWAs, using the Authorization Code Flow with a backend is generally more secure, as it keeps your client secret off the client side.
Architectural Overview for React PWA:
Frontend (React PWA)                      Backend (Node.js/Python)          Google APIs
┌─────────────────────┐                   ┌───────────────────────┐         ┌───────────┐
│ React Components    │                   │ OAuth 2.0 Management  │         │           │
│  - UI rendering     │◀─────────────────▶│ Google API Proxy      │◀───────▶│ Google    │
│  - User interaction │                   │ (Drive, Gmail, Calendar)│         │ Workspace │
├─────────────────────┤                   ├───────────────────────┤         │           │
│ Service Worker      │                   │ Data Sync Logic       │         │           │
│  - Asset Caching    │                   │ (Optional: Real-time) │         │           │
│  - Network Intercept│                   └───────────────────────┘         └───────────┘
│  - Background Sync  │
├─────────────────────┤
│ IndexedDB           │
│  - Offline Data     │
│  - Pending Changes  │
└─────────────────────┘

React Code Structure (Illustrative):
This example will focus on key React components and the integration with Service Worker/IndexedDB for offline capabilities. It assumes you have a Node.js or Python backend providing the /api/... endpoints for Google Workspace interaction.
1. Project Setup (using Vite for simplicity):
# Create React project
npm create vite@latest my-react-workspace -- --template react-ts # or react for JavaScript

cd my-react-workspace

# Install dependencies
npm install localforage # For IndexedDB wrapper
npm install @types/localforage # If using TypeScript

# Create public/service-worker.js, src/index.css, src/App.tsx, src/components/

2. public/service-worker.js (Crucial for Offline):
This is essentially the same as the one provided in the Node.js example, but repeated here for completeness in the React context.
const CACHE_NAME = 'react-workspace-app-cache-v1';
const DATA_CACHE_NAME = 'react-workspace-data-cache-v1';

const urlsToCache = [
  '/',
  '/index.html',
  '/vite.svg', // Vite default icon
  // '/logo192.png', // CRA default icons
  // '/logo512.png',
  // Add other static assets served by your build tool
];

// In a real app, you'd dynamically add more assets via a build step
// For Vite, main.js and index.css are often fingerprinted and not explicitly listed here
// but handled by the network strategy.

self.addEventListener('install', (event) => {
  event.waitUntil(
    caches.open(CACHE_NAME)
      .then((cache) => {
        console.log('Service Worker: Caching app shell assets');
        return cache.addAll(urlsToCache);
      })
  );
});

self.addEventListener('activate', (event) => {
  event.waitUntil(
    caches.keys().then((cacheNames) => {
      return Promise.all(
        cacheNames.map((cacheName) => {
          if (cacheName !== CACHE_NAME && cacheName !== DATA_CACHE_NAME) {
            console.log('Service Worker: Deleting old cache:', cacheName);
            return caches.delete(cacheName);
          }
        })
      );
    })
  );
  self.clients.claim(); // Ensures the service worker controls clients immediately
});

self.addEventListener('fetch', (event) => {
  const requestUrl = new URL(event.request.url);

  // Serve from cache first for same-origin static assets (app shell)
  if (requestUrl.origin === location.origin && urlsToCache.includes(requestUrl.pathname)) {
    event.respondWith(
      caches.match(event.request).then((response) => {
        return response || fetch(event.request);
      })
    );
    return; // Stop further processing for this request
  }

  // Network-first with cache fallback for API calls to your backend
  if (requestUrl.origin === location.origin && requestUrl.pathname.startsWith('/api/')) {
    event.respondWith(
      fetch(event.request)
        .then(async (response) => {
          // If response is good, clone it and put in data cache
          const responseToCache = response.clone();
          const cache = await caches.open(DATA_CACHE_NAME);
          cache.put(event.request, responseToCache);
          return response;
        })
        .catch(async () => {
          // Network failed, try to get from data cache
          const cachedResponse = await caches.match(event.request);
          if (cachedResponse) {
            console.log(`Service Worker: Serving API response for ${requestUrl.pathname} from cache.`);
            return cachedResponse;
          }
          // If not in cache and offline, throw error
          throw new Error('No network and no cached API data.');
        })
    );
    return; // Stop further processing for this request
  }

  // Default: Network-only or Network-first strategy for other requests (e.g., third-party APIs not explicitly cached)
  event.respondWith(fetch(event.request));
});

// --- Background Sync ---
self.addEventListener('sync', (event) => {
  if (event.tag === 'sync-pending-workspace-changes') {
    console.log('Service Worker: Performing background sync for pending changes...');
    event.waitUntil(syncPendingWorkspaceChanges());
  }
});

async function syncPendingWorkspaceChanges() {
    let db;
    try {
        // Re-open IndexedDB connection within the service worker context
        db = await new Promise((resolve, reject) => {
            const request = indexedDB.open('reactWorkspaceData', 1); // Ensure this matches your localForage instance name
            request.onsuccess = (e) => resolve(e.target.result);
            request.onerror = (e) => reject(e.target.error);
            request.onupgradeneeded = (e) => {
                // This scenario indicates a problem as DB structure should be stable
                console.warn('IndexedDB upgrade needed during sync. This is unexpected.');
                e.target.transaction.abort(); // Prevent potential data loss
            };
        });

        // Use localForage to interact with IndexedDB from Service Worker if you configure it.
        // For simplicity, directly using IndexedDB API here.
        const transaction = db.transaction(['pendingSync'], 'readwrite');
        const store = transaction.objectStore('pendingSync');
        const pendingChanges = await new Promise((resolve, reject) => {
            const req = store.getAll();
            req.onsuccess = () => resolve(req.result);
            req.onerror = () => reject(req.error);
        });


        for (const change of pendingChanges) {
            console.log('Processing pending change:', change.type, change.data);
            try {
                let apiResponse;
                switch (change.type) {
                    case 'file_upload':
                        // Note: For file uploads, the `data` should contain raw file content (e.g., Base64 or Blob)
                        // not just a local file path, as Service Worker can't access local file system directly.
                        apiResponse = await fetch('/api/drive/files/upload', {
                            method: 'POST',
                            headers: { 'Content-Type': 'application/json' },
                            body: JSON.stringify(change.data),
                        });
                        break;
                    case 'email_send':
                        apiResponse = await fetch('/api/gmail/send', {
                            method: 'POST',
                            headers: { 'Content-Type': 'application/json' },
                            body: JSON.stringify(change.data),
                        });
                        break;
                    case 'calendar_create':
                        apiResponse = await fetch('/api/calendar/events', {
                            method: 'POST',
                            headers: { 'Content-Type': 'application/json' },
                            body: JSON.stringify(change.data),
                        });
                        break;
                    default:
                        console.warn('Unknown pending change type:', change.type);
                        continue;
                }

                if (apiResponse.ok) {
                    console.log(`Successfully synced ${change.type} operation.`);
                    await new Promise((resolve, reject) => {
                        const deleteReq = store.delete(change.id);
                        deleteReq.onsuccess = resolve;
                        deleteReq.onerror = reject;
                    });
                    // Optionally: Send a message to the client to refresh its UI/data
                    self.clients.matchAll().then(clients => {
                        clients.forEach(client => client.postMessage({ type: 'SYNC_COMPLETE', payload: { syncedType: change.type } }));
                    });
                } else {
                    const errorText = await apiResponse.text();
                    console.error(`Failed to sync ${change.type}:`, apiResponse.status, errorText);
                    // Do not delete from queue; it will be retried later by the SyncManager
                }
            } catch (error) {
                console.error(`Network error during ${change.type} sync:`, error);
                // Do not delete from queue; it will be retried later
            }
        }
        await new Promise(resolve => transaction.oncomplete = resolve); // Ensure transaction completes
        console.log('Service Worker: Background sync completed.');
    } catch (error) {
        console.error('Service Worker: Error during background sync process:', error);
    } finally {
        if (db) db.close(); // Close DB connection
    }
}

3. src/main.tsx (or main.jsx) - Entry point:
import React from 'react';
import ReactDOM from 'react-dom/client';
import App from './App.tsx';
import './index.css';

ReactDOM.createRoot(document.getElementById('root')!).render(
  <React.StrictMode>
    <App />
  </React.StrictMode>,
);

// Service Worker Registration
if ('serviceWorker' in navigator) {
  window.addEventListener('load', () => {
    navigator.serviceWorker.register('/service-worker.js')
      .then(registration => {
        console.log('Service Worker registered with scope:', registration.scope);

        // Listen for messages from the Service Worker (e.g., sync complete notifications)
        navigator.serviceWorker.addEventListener('message', event => {
          if (event.data && event.data.type === 'SYNC_COMPLETE') {
            console.log('Received SYNC_COMPLETE from SW:', event.data.payload);
            // You might trigger a data refresh in your React app here
            // e.g., using a global state manager or context API
          }
        });
      })
      .catch(error => {
        console.error('Service Worker registration failed:', error);
      });
  });
}

4. src/App.tsx (Main Application Component):
This component will manage authentication status, network status, and orchestrate data fetching and display.
import React, { useState, useEffect, useCallback } from 'react';
import localforage from 'localforage';
import './App.css'; // Your main CSS file
import DriveSection from './components/DriveSection';
import GmailSection from './components/GmailSection';
import CalendarSection from './components/CalendarSection';

// Configure localForage for IndexedDB
localforage.config({
  name: 'reactWorkspaceData', // Database name
  storeName: 'offlineStore', // Store for general data
});

// Configure separate store for pending sync operations
const pendingSyncStore = localforage.createInstance({
  name: 'reactWorkspaceData',
  storeName: 'pendingSync',
});

function App() {
  const [isAuthenticated, setIsAuthenticated] = useState(false);
  const [isOnline, setIsOnline] = useState(navigator.onLine);

  useEffect(() => {
    // Check for authentication success from URL parameter (after OAuth redirect)
    const urlParams = new URLSearchParams(window.location.search);
    if (urlParams.get('authSuccess') === 'true') {
      setIsAuthenticated(true);
      console.log('Authenticated successfully!');
      // Clean up the URL
      window.history.replaceState({}, document.title, window.location.pathname);
    }

    // Set up network status listeners
    const handleOnline = () => setIsOnline(true);
    const handleOffline = () => setIsOnline(false);

    window.addEventListener('online', handleOnline);
    window.addEventListener('offline', handleOffline);

    // Initial check (in a real app, you'd check a server-side session or a token in localStorage)
    const checkAuthStatus = async () => {
        try {
            // Attempt a simple authenticated API call to check token validity
            // This is a proxy for checking if the backend has a valid session/token
            const response = await fetch('/api/drive/files', { method: 'HEAD' }); // HEAD is lighter than GET
            if (response.ok) {
                setIsAuthenticated(true);
            } else {
                setIsAuthenticated(false);
                console.log('Backend reports no valid session or authentication needed.');
            }
        } catch (error) {
            console.error('Error checking auth status:', error);
            setIsAuthenticated(false);
        }
    };
    checkAuthStatus();


    return () => {
      window.removeEventListener('online', handleOnline);
      window.removeEventListener('offline', handleOffline);
    };
  }, []);

  const handleAuthRedirect = () => {
    window.location.href = '/auth/google'; // Redirect to your Node.js/Python OAuth endpoint
  };

  const handleLogout = async () => {
    // In a real app, you'd hit a backend logout endpoint to revoke tokens
    // For this example, just clear local state (tokens are still on server for this demo)
    setIsAuthenticated(false);
    // You might also clear IndexedDB data relevant to the user here
    // await localforage.clear(); // Clear all data
    console.log('Logged out (client-side only for this demo)');
    window.location.reload(); // Simple refresh for state cleanup
  };

  // Function to add an operation to the pending sync queue in IndexedDB
  const addToPendingSync = useCallback(async (type: string, data: any) => {
    try {
      await pendingSyncStore.setItem(Date.now().toString(), { // Use timestamp as key for unique ID
        type,
        data,
        timestamp: new Date().toISOString()
      });
      console.log(`Queued offline change: ${type}`);

      // Request background sync
      if ('serviceWorker' in navigator && 'SyncManager' in window) {
        navigator.serviceWorker.ready.then(reg => {
          reg.sync.register('sync-pending-workspace-changes')
            .then(() => console.log('Background sync registered!'))
            .catch(err => console.error('Background sync registration failed:', err));
        }).catch(err => {
          console.error('Service Worker not ready for sync:', err);
        });
      } else {
        console.warn('Background Sync API not supported or service worker not ready. Sync will happen on next online app load.');
      }
    } catch (error) {
      console.error('Error adding to pending sync:', error);
      alert('Failed to save offline change. Data might be lost if not synced.');
    }
  }, []);


  return (
    <div className="App">
      <header className="App-header">
        <h1>My Advanced Workspace</h1>
        <div className="auth-status">
          <span className={`online-status ${isOnline ? 'online' : 'offline'}`}>
            {isOnline ? 'Online' : 'Offline'}
          </span>
          {!isAuthenticated ? (
            <button onClick={handleAuthRedirect}>Login with Google</button>
          ) : (
            <button onClick={handleLogout}>Logout</button>
          )}
        </div>
      </header>
      <main>
        {!isAuthenticated ? (
          <p>Please log in to access your Google Workspace data.</p>
        ) : (
          <>
            <DriveSection isOnline={isOnline} addToPendingSync={addToPendingSync} />
            <GmailSection isOnline={isOnline} addToPendingSync={addToPendingSync} />
            <CalendarSection isOnline={isOnline} addToPendingSync={addToPendingSync} />
          </>
        )}
      </main>
    </div>
  );
}

export default App;

5. src/components/DriveSection.tsx (Example Component for Drive):
You'd create similar components for GmailSection and CalendarSection.
import React, { useState, useEffect, useCallback } from 'react';
import localforage from 'localforage';

interface DriveFile {
  id: string;
  name: string;
  mimeType: string;
  modifiedTime: string;
  // Add other properties you need
}

interface DriveSectionProps {
  isOnline: boolean;
  addToPendingSync: (type: string, data: any) => Promise<void>;
}

// Configure localForage instance for Drive data
const driveStore = localforage.createInstance({
  name: 'reactWorkspaceData',
  storeName: 'driveFiles',
});

const DriveSection: React.FC<DriveSectionProps> = ({ isOnline, addToPendingSync }) => {
  const [files, setFiles] = useState<DriveFile[]>([]);
  const [loading, setLoading] = useState(false);
  const [error, setError] = useState<string | null>(null);
  const [selectedFile, setSelectedFile] = useState<File | null>(null);

  const fetchFiles = useCallback(async (source: 'online' | 'offline') => {
    setLoading(true);
    setError(null);
    try {
      let fetchedFiles: DriveFile[] = [];
      if (source === 'online' && isOnline) {
        console.log('Fetching Drive files online...');
        const response = await fetch('/api/drive/files');
        if (!response.ok) {
          throw new Error(`HTTP error! status: ${response.status}`);
        }
        fetchedFiles = await response.json();
        // Save to IndexedDB
        await driveStore.clear(); // Clear old data (for simplicity)
        for (const file of fetchedFiles) {
          await driveStore.setItem(file.id, file);
        }
        console.log(`Saved ${fetchedFiles.length} Drive files to IndexedDB.`);
      } else {
        console.log('Fetching Drive files from IndexedDB...');
        await driveStore.iterate((value: DriveFile) => {
          fetchedFiles.push(value);
        });
      }
      setFiles(fetchedFiles);
    } catch (err: any) {
      console.error('Error fetching Drive files:', err);
      setError(`Failed to load Drive files from ${source}. ${err.message}`);
      // Fallback to offline data if online fetch failed
      if (source === 'online' && isOnline) {
        alert('Online fetch failed. Displaying offline data.');
        fetchFiles('offline'); // Try to load from cache
      }
    } finally {
      setLoading(false);
    }
  }, [isOnline]);

  useEffect(() => {
    fetchFiles('online'); // Initial fetch
  }, [fetchFiles]);

  const handleFileChange = (event: React.ChangeEvent<HTMLInputElement>) => {
    if (event.target.files && event.target.files[0]) {
      setSelectedFile(event.target.files[0]);
    }
  };

  const handleUploadFile = async () => {
    if (!selectedFile) {
      alert('Please select a file to upload.');
      return;
    }

    const reader = new FileReader();
    reader.onloadend = async () => {
      if (reader.result) {
        const base64Content = (reader.result as string).split(',')[1]; // Get base64 string without prefix
        const fileData = {
          fileName: selectedFile.name,
          mimeType: selectedFile.type,
          base64Content: base64Content,
        };

        if (isOnline) {
          try {
            const response = await fetch('/api/drive/files/upload', {
              method: 'POST',
              headers: { 'Content-Type': 'application/json' },
              body: JSON.stringify(fileData),
            });
            if (!response.ok) {
              throw new Error(`Upload failed with status: ${response.status}`);
            }
            alert('File uploaded successfully!');
            fetchFiles('online'); // Refresh list
          } catch (err: any) {
            console.error('Online upload failed:', err);
            alert(`Online upload failed. Saving for offline sync. Error: ${err.message}`);
            await addToPendingSync('file_upload', fileData);
          }
        } else {
          alert('Offline. File queued for upload when online.');
          await addToPendingSync('file_upload', fileData);
        }
        setSelectedFile(null); // Clear selected file
        if (document.getElementById('file-upload-input')) {
            (document.getElementById('file-upload-input') as HTMLInputElement).value = ''; // Clear input
        }
      }
    };
    reader.readAsDataURL(selectedFile); // Read file as Base64
  };

  const handleDownloadFile = async (fileId: string, fileName: string) => {
    if (!isOnline) {
        alert('Cannot download file when offline. Try when online.');
        return;
    }
    try {
        const response = await fetch(`/api/drive/files/${fileId}/download`);
        if (!response.ok) throw new Error('Download failed');
        const blob = await response.blob();
        const url = URL.createObjectURL(blob);
        const a = document.createElement('a');
        a.href = url;
        a.download = fileName;
        document.body.appendChild(a);
        a.click();
        document.body.removeChild(a);
        URL.revokeObjectURL(url);
    } catch (e: any) {
        console.error('Error downloading:', e);
        alert(`Failed to download file online. Error: ${e.message}`);
    }
  };


  return (
    <section>
      <h2>Google Drive Files</h2>
      <button onClick={() => fetchFiles('online')} disabled={!isOnline || loading}>
        {loading && isOnline ? 'Refreshing...' : 'Refresh Online Files'}
      </button>
      <button onClick={() => fetchFiles('offline')} disabled={loading}>
        {loading && !isOnline ? 'Loading Offline...' : 'View Offline Files'}
      </button>

      <div style={{ marginTop: '10px', padding: '10px', border: '1px solid #eee' }}>
        <h3>Upload New File</h3>
        <input type="file" id="file-upload-input" onChange={handleFileChange} />
        <button onClick={handleUploadFile} disabled={!selectedFile}>
          {isOnline ? 'Upload File' : 'Queue Upload Offline'}
        </button>
        {selectedFile && <p>Selected: {selectedFile.name}</p>}
      </div>

      {loading && <p>Loading files...</p>}
      {error && <p className="error">{error}</p>}
      <ul>
        {files.length === 0 && !loading && !error && <p>No files found.</p>}
        {files.map((file) => (
          <li key={file.id}>
            <strong>{file.name}</strong> ({file.mimeType}) - Modified: {new Date(file.modifiedTime).toLocaleDateString()}
            <button onClick={() => handleDownloadFile(file.id, file.name)} style={{ marginLeft: '10px' }}>Download</button>
          </li>
        ))}
      </ul>
    </section>
  );
};

export default DriveSection;

6. src/components/GmailSection.tsx (Example Component for Gmail):
import React, { useState, useEffect, useCallback } from 'react';
import localforage from 'localforage';

interface GmailMessage {
  id: string;
  snippet: string;
  subject: string;
  sender: string;
  received_time: string;
  body: string; // The full email body
  // Add other properties you need
}

interface GmailSectionProps {
  isOnline: boolean;
  addToPendingSync: (type: string, data: any) => Promise<void>;
}

const gmailStore = localforage.createInstance({
  name: 'reactWorkspaceData',
  storeName: 'gmailMessages',
});

const GmailSection: React.FC<GmailSectionProps> = ({ isOnline, addToPendingSync }) => {
  const [messages, setMessages] = useState<GmailMessage[]>([]);
  const [loading, setLoading] = useState(false);
  const [error, setError] = useState<string | null>(null);
  const [showCompose, setShowCompose] = useState(false);
  const [emailTo, setEmailTo] = useState('');
  const [emailSubject, setEmailSubject] = useState('');
  const [emailBody, setEmailBody] = useState('');

  const fetchMessages = useCallback(async (source: 'online' | 'offline') => {
    setLoading(true);
    setError(null);
    try {
      let fetchedMessages: GmailMessage[] = [];
      if (source === 'online' && isOnline) {
        console.log('Fetching Gmail messages online...');
        const response = await fetch('/api/gmail/messages');
        if (!response.ok) {
          throw new Error(`HTTP error! status: ${response.status}`);
        }
        const messageStubs = await response.json();

        // For each message stub, fetch full content and save
        const fullMessagesPromises = messageStubs.map(async (stub: { id: string }) => {
            const detailResponse = await fetch(`/api/gmail/messages/${stub.id}`);
            if (!detailResponse.ok) {
                console.warn(`Failed to fetch full message for ID: ${stub.id}`);
                return null;
            }
            const fullMessage = await detailResponse.json();
            // Basic parsing for display
            const headers = fullMessage.payload?.headers?.reduce((acc: any, h: any) => {
                acc[h.name] = h.value;
                return acc;
            }, {});
            let bodyContent = '';
            // Simplified body extraction (might need more robust parsing for complex emails)
            if (fullMessage.payload?.parts) {
                const part = fullMessage.payload.parts.find((p: any) => p.mimeType === 'text/plain' || p.mimeType === 'text/html');
                if (part?.body?.data) {
                    bodyContent = atob(part.body.data.replace(/-/g, '+').replace(/_/g, '/'));
                    // If HTML, you might want to strip HTML tags here
                }
            } else if (fullMessage.payload?.body?.data) {
                 bodyContent = atob(fullMessage.payload.body.data.replace(/-/g, '+').replace(/_/g, '/'));
            }


            const msgData: GmailMessage = {
                id: fullMessage.id,
                snippet: fullMessage.snippet || '',
                subject: headers?.Subject || 'No Subject',
                sender: headers?.From || 'Unknown Sender',
                received_time: new Date(parseInt(fullMessage.internalDate)).toISOString(),
                body: bodyContent,
            };
            return msgData;
        });

        const resolvedMessages = (await Promise.all(fullMessagesPromises)).filter(Boolean) as GmailMessage[];
        fetchedMessages = resolvedMessages;

        // Save to IndexedDB
        await gmailStore.clear();
        for (const msg of fetchedMessages) {
          await gmailStore.setItem(msg.id, msg);
        }
        console.log(`Saved ${fetchedMessages.length} Gmail messages to IndexedDB.`);
      } else {
        console.log('Fetching Gmail messages from IndexedDB...');
        await gmailStore.iterate((value: GmailMessage) => {
          fetchedMessages.push(value);
        });
      }
      setMessages(fetchedMessages.sort((a,b) => new Date(b.received_time).getTime() - new Date(a.received_time).getTime())); // Sort by time
    } catch (err: any) {
      console.error('Error fetching Gmail messages:', err);
      setError(`Failed to load Gmail messages from ${source}. ${err.message}`);
      if (source === 'online' && isOnline) {
        alert('Online fetch failed. Displaying offline data.');
        fetchMessages('offline');
      }
    } finally {
      setLoading(false);
    }
  }, [isOnline]);

  useEffect(() => {
    fetchMessages('online');
  }, [fetchMessages]);

  const handleSendEmail = async () => {
    if (!emailTo || !emailSubject || !emailBody) {
      alert('Please fill in all email fields.');
      return;
    }

    const emailData = {
      to: emailTo,
      subject: emailSubject,
      body: emailBody,
    };

    if (isOnline) {
      try {
        const response = await fetch('/api/gmail/send', {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify(emailData),
        });
        if (!response.ok) {
          throw new Error(`Send failed with status: ${response.status}`);
        }
        alert('Email sent successfully!');
        setShowCompose(false);
        setEmailTo('');
        setEmailSubject('');
        setEmailBody('');
        fetchMessages('online'); // Refresh list
      } catch (err: any) {
        console.error('Online email send failed:', err);
        alert(`Online email send failed. Saving for offline sync. Error: ${err.message}`);
        await addToPendingSync('email_send', emailData);
      }
    } else {
      alert('Offline. Email queued for sending when online.');
      await addToPendingSync('email_send', emailData);
      setShowCompose(false); // Close compose form
      setEmailTo('');
      setEmailSubject('');
      setEmailBody('');
    }
  };

  return (
    <section>
      <h2>Gmail Messages</h2>
      <button onClick={() => fetchMessages('online')} disabled={!isOnline || loading}>
        {loading && isOnline ? 'Refreshing...' : 'Refresh Online Mail'}
      </button>
      <button onClick={() => fetchMessages('offline')} disabled={loading}>
        {loading && !isOnline ? 'Loading Offline...' : 'View Offline Mail'}
      </button>
      <button onClick={() => setShowCompose(true)} disabled={showCompose}>Compose Email</button>

      {showCompose && (
        <div style={{ marginTop: '10px', padding: '10px', border: '1px solid #eee' }}>
          <h3>Compose New Email</h3>
          <input
            type="text"
            placeholder="To"
            value={emailTo}
            onChange={(e) => setEmailTo(e.target.value)}
          />
          <input
            type="text"
            placeholder="Subject"
            value={emailSubject}
            onChange={(e) => setEmailSubject(e.target.value)}
          />
          <textarea
            placeholder="Body"
            value={emailBody}
            onChange={(e) => setEmailBody(e.target.value)}
          ></textarea>
          <button onClick={handleSendEmail}>
            {isOnline ? 'Send' : 'Queue Send Offline'}
          </button>
          <button onClick={() => setShowCompose(false)}>Cancel</button>
        </div>
      )}

      {loading && <p>Loading messages...</p>}
      {error && <p className="error">{error}</p>}
      <ul>
        {messages.length === 0 && !loading && !error && <p>No messages found.</p>}
        {messages.map((msg) => (
          <li key={msg.id}>
            <strong>Subject: {msg.subject}</strong><br/>
            From: {msg.sender}<br/>
            Snippet: {msg.snippet}<br/>
            Received: {new Date(msg.received_time).toLocaleString()}
          </li>
        ))}
      </ul>
    </section>
  );
};

export default GmailSection;

7. src/components/CalendarSection.tsx (Example Component for Calendar):
import React, { useState, useEffect, useCallback } from 'react';
import localforage from 'localforage';

interface CalendarEvent {
  id: string;
  summary: string;
  description?: string;
  start_time: string; // ISO string
  end_time: string; // ISO string
  location?: string;
  status: string;
}

interface CalendarSectionProps {
  isOnline: boolean;
  addToPendingSync: (type: string, data: any) => Promise<void>;
}

const calendarStore = localforage.createInstance({
  name: 'reactWorkspaceData',
  storeName: 'calendarEvents',
});

const CalendarSection: React.FC<CalendarSectionProps> = ({ isOnline, addToPendingSync }) => {
  const [events, setEvents] = useState<CalendarEvent[]>([]);
  const [loading, setLoading] = useState(false);
  const [error, setError] = useState<string | null>(null);
  const [showCreateForm, setShowCreateForm] = useState(false);
  const [eventSummary, setEventSummary] = useState('');
  const [eventDescription, setEventDescription] = useState('');
  const [eventStart, setEventStart] = useState('');
  const [eventEnd, setEventEnd] = useState('');
  const [eventLocation, setEventLocation] = useState('');


  const fetchEvents = useCallback(async (source: 'online' | 'offline') => {
    setLoading(true);
    setError(null);
    try {
      let fetchedEvents: CalendarEvent[] = [];
      if (source === 'online' && isOnline) {
        console.log('Fetching Calendar events online...');
        const response = await fetch('/api/calendar/events');
        if (!response.ok) {
          throw new Error(`HTTP error! status: ${response.status}`);
        }
        const apiEvents = await response.json();

        // Map API response to your local CalendarEvent interface
        fetchedEvents = apiEvents.map((event: any) => ({
            id: event.id,
            summary: event.summary,
            description: event.description || '',
            start_time: event.start.dateTime || event.start.date,
            end_time: event.end.dateTime || event.end.date,
            location: event.location || '',
            status: event.status,
        }));

        // Save to IndexedDB
        await calendarStore.clear();
        for (const event of fetchedEvents) {
          await calendarStore.setItem(event.id, event);
        }
        console.log(`Saved ${fetchedEvents.length} Calendar events to IndexedDB.`);
      } else {
        console.log('Fetching Calendar events from IndexedDB...');
        await calendarStore.iterate((value: CalendarEvent) => {
          fetchedEvents.push(value);
        });
      }
      setEvents(fetchedEvents.sort((a,b) => new Date(a.start_time).getTime() - new Date(b.start_time).getTime())); // Sort by start time
    } catch (err: any) {
      console.error('Error fetching Calendar events:', err);
      setError(`Failed to load Calendar events from ${source}. ${err.message}`);
      if (source === 'online' && isOnline) {
        alert('Online fetch failed. Displaying offline data.');
        fetchEvents('offline');
      }
    } finally {
      setLoading(false);
    }
  }, [isOnline]);

  useEffect(() => {
    fetchEvents('online');
  }, [fetchEvents]);

  const handleCreateEvent = async () => {
    if (!eventSummary || !eventStart || !eventEnd) {
      alert('Please fill in Summary, Start, and End fields.');
      return;
    }

    const eventData = {
      summary: eventSummary,
      description: eventDescription,
      start: eventStart, // ISO string
      end: eventEnd,     // ISO string
      location: eventLocation,
    };

    if (isOnline) {
      try {
        const response = await fetch('/api/calendar/events', {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify(eventData),
        });
        if (!response.ok) {
          throw new Error(`Create event failed with status: ${response.status}`);
        }
        alert('Event created successfully!');
        setShowCreateForm(false);
        setEventSummary('');
        setEventDescription('');
        setEventStart('');
        setEventEnd('');
        setEventLocation('');
        fetchEvents('online'); // Refresh list
      } catch (err: any) {
        console.error('Online event creation failed:', err);
        alert(`Online event creation failed. Saving for offline sync. Error: ${err.message}`);
        await addToPendingSync('calendar_create', eventData);
      }
    } else {
      alert('Offline. Event queued for creation when online.');
      await addToPendingSync('calendar_create', eventData);
      setShowCreateForm(false); // Close form
      setEventSummary('');
      setEventDescription('');
      setEventStart('');
      setEventEnd('');
      setEventLocation('');
    }
  };

  return (
    <section>
      <h2>Google Calendar Events</h2>
      <button onClick={() => fetchEvents('online')} disabled={!isOnline || loading}>
        {loading && isOnline ? 'Refreshing...' : 'Refresh Online Events'}
      </button>
      <button onClick={() => fetchEvents('offline')} disabled={loading}>
        {loading && !isOnline ? 'Loading Offline...' : 'View Offline Events'}
      </button>
      <button onClick={() => setShowCreateForm(true)} disabled={showCreateForm}>Create Event</button>

      {showCreateForm && (
        <div style={{ marginTop: '10px', padding: '10px', border: '1px solid #eee' }}>
          <h3>Create New Event</h3>
          <input
            type="text"
            placeholder="Summary"
            value={eventSummary}
            onChange={(e) => setEventSummary(e.target.value)}
          />
          <input
            type="text"
            placeholder="Description (optional)"
            value={eventDescription}
            onChange={(e) => setEventDescription(e.target.value)}
          />
          <label>Start Time:</label>
          <input
            type="datetime-local"
            value={eventStart}
            onChange={(e) => setEventStart(e.target.value)}
          />
          <label>End Time:</label>
          <input
            type="datetime-local"
            value={eventEnd}
            onChange={(e) => setEventEnd(e.target.value)}
          />
          <input
            type="text"
            placeholder="Location (optional)"
            value={eventLocation}
            onChange={(e) => setEventLocation(e.target.value)}
          />
          <button onClick={handleCreateEvent}>
            {isOnline ? 'Create Event' : 'Queue Create Offline'}
          </button>
          <button onClick={() => setShowCreateForm(false)}>Cancel</button>
        </div>
      )}

      {loading && <p>Loading events...</p>}
      {error && <p className="error">{error}</p>}
      <ul>
        {events.length === 0 && !loading && !error && <p>No events found.</p>}
        {events.map((event) => (
          <li key={event.id}>
            <strong>{event.summary}</strong><br/>
            {event.description && <p><em>{event.description}</em></p>}
            Starts: {new Date(event.start_time).toLocaleString()}<br/>
            Ends: {new Date(event.end_time).toLocaleString()}<br/>
            {event.location && `Location: ${event.location}`}
          </li>
        ))}
      </ul>
    </section>
  );
};

export default CalendarSection;

7. src/index.css and src/App.css (Minimal Styling for readability):
src/index.css:
body {
  margin: 0;
  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Roboto', 'Oxygen',
    'Ubuntu', 'Cantarell', 'Fira Sans', 'Droid Sans', 'Helvetica Neue',
    sans-serif;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  background-color: #f4f7f6;
  color: #333;
}

code {
  font-family: source-code-pro, Menlo, Monaco, Consolas, 'Courier New',
    monospace;
}

src/App.css:
.App {
  text-align: center;
  max-width: 1000px;
  margin: 0 auto;
  padding: 20px;
}

.App-header {
  background-color: #ffffff;
  padding: 20px;
  border-bottom: 1px solid #e0e0e0;
  box-shadow: 0 2px 5px rgba(0, 0, 0, 0.05);
  display: flex;
  justify-content: space-between;
  align-items: center;
  margin-bottom: 30px;
  border-radius: 8px;
}

.App-header h1 {
  margin: 0;
  color: #2196f3;
}

.auth-status {
  display: flex;
  align-items: center;
}

.online-status {
  font-weight: bold;
  margin-right: 15px;
  padding: 5px 10px;
  border-radius: 4px;
}

.online-status.online {
  color: #4caf50; /* Green */
  background-color: #e8f5e9;
}

.online-status.offline {
  color: #f44336; /* Red */
  background-color: #ffebee;
}

button {
  background-color: #2196f3;
  color: white;
  padding: 10px 18px;
  border: none;
  border-radius: 5px;
  cursor: pointer;
  font-size: 1rem;
  transition: background-color 0.3s ease;
  margin-left: 10px;
}

button:hover {
  background-color: #1976d2;
}

button:disabled {
  background-color: #90caf9;
  cursor: not-allowed;
}

main {
  text-align: left;
}

section {
  background-color: #ffffff;
  padding: 25px;
  margin-bottom: 25px;
  border-radius: 8px;
  box-shadow: 0 2px 5px rgba(0, 0, 0, 0.05);
}

section h2 {
  color: #3f51b5;
  margin-top: 0;
  margin-bottom: 20px;
}

section h3 {
  color: #607d8b;
  margin-top: 20px;
  margin-bottom: 15px;
}

ul {
  list-style: none;
  padding: 0;
}

li {
  background-color: #f9f9f9;
  border: 1px solid #e0e0e0;
  padding: 15px;
  margin-bottom: 10px;
  border-radius: 5px;
  display: flex;
  flex-direction: column;
  gap: 5px;
}

input[type="text"],
input[type="datetime-local"],
textarea,
input[type="file"] {
  width: calc(100% - 20px);
  padding: 10px;
  margin-bottom: 15px;
  border: 1px solid #ccc;
  border-radius: 4px;
  box-sizing: border-box;
}

label {
    display: block;
    margin-bottom: 5px;
    font-weight: bold;
    color: #555;
}

textarea {
  min-height: 80px;
  resize: vertical;
}

.error {
    color: #d32f2f;
    background-color: #ffebee;
    border: 1px solid #d32f2f;
    padding: 10px;
    border-radius: 4px;
    margin-top: 15px;
}

How to Run This React App:
 * Backend Running: Ensure your Node.js or Python backend (from previous answers) is running on http://localhost:3000 and correctly handles OAuth and API requests.
 * React Project Setup:
   * npm create vite@latest my-react-workspace -- --template react-ts
   * cd my-react-workspace
   * npm install localforage
   * Copy the public/service-worker.js file into your my-react-workspace/public directory.
   * Copy the src/App.tsx, src/index.css, src/App.css and src/components/DriveSection.tsx, src/components/GmailSection.tsx, src/components/CalendarSection.tsx files into their respective locations.
 * Start React Dev Server:
   npm run dev

   Vite typically runs on http://localhost:5173/ by default. You might need to adjust your backend's Authorized JavaScript origins and Authorized redirect URIs in the Google Cloud Console to match Vite's development server URL (e.g., http://localhost:5173).
 * Test:
   * Open http://localhost:5173/ in your browser.
   * Click "Login with Google" to initiate the OAuth flow via your backend.
   * Once authenticated, try refreshing data (which pulls from Google APIs via your backend).
   * Go offline (e.g., Chrome DevTools -> Application -> Service Workers -> check "Offline" checkbox, or disable Wi-Fi).
   * Perform an "Upload File", "Send Email", or "Create Event". Observe the console logs; they should indicate the action is "queued for offline sync."
   * Go back online. The Service Worker's background sync should automatically trigger (or you can force it in DevTools by going to "Application" -> "Service Workers" -> click "Sync" next to your service worker).
   * Verify the changes appeared in your actual Google Drive, Gmail, and Calendar.
This React PWA structure provides a solid foundation for an advanced online/offline Google Workspace experience, allowing users to remain productive even without a continuous internet connection.



# Create React project
npm create vite@latest my-react-workspace -- --template react-ts # or react for JavaScript

cd my-react-workspace

# Install dependencies
npm install localforage # For IndexedDB wrapper
npm install @types/localforage # If using TypeScript

# Create public/service-worker.js, src/index.css, src/App.tsx, src/components/



const CACHE_NAME = 'react-workspace-app-cache-v1';
const DATA_CACHE_NAME = 'react-workspace-data-cache-v1';

const urlsToCache = [
  '/',
  '/index.html',
  '/vite.svg', // Vite default icon
  // '/logo192.png', // CRA default icons
  // '/logo512.png',
  // Add other static assets served by your build tool
];

// In a real app, you'd dynamically add more assets via a build step
// For Vite, main.js and index.css are often fingerprinted and not explicitly listed here
// but handled by the network strategy.

self.addEventListener('install', (event) => {
  event.waitUntil(
    caches.open(CACHE_NAME)
      .then((cache) => {
        console.log('Service Worker: Caching app shell assets');
        return cache.addAll(urlsToCache);
      })
  );
});

self.addEventListener('activate', (event) => {
  event.waitUntil(
    caches.keys().then((cacheNames) => {
      return Promise.all(
        cacheNames.map((cacheName) => {
          if (cacheName !== CACHE_NAME && cacheName !== DATA_CACHE_NAME) {
            console.log('Service Worker: Deleting old cache:', cacheName);
            return caches.delete(cacheName);
          }
        })
      );
    })
  );
  self.clients.claim(); // Ensures the service worker controls clients immediately
});

self.addEventListener('fetch', (event) => {
  const requestUrl = new URL(event.request.url);

  // Serve from cache first for same-origin static assets (app shell)
  if (requestUrl.origin === location.origin && urlsToCache.includes(requestUrl.pathname)) {
    event.respondWith(
      caches.match(event.request).then((response) => {
        return response || fetch(event.request);
      })
    );
    return; // Stop further processing for this request
  }

  // Network-first with cache fallback for API calls to your backend
  if (requestUrl.origin === location.origin && requestUrl.pathname.startsWith('/api/')) {
    event.respondWith(
      fetch(event.request)
        .then(async (response) => {
          // If response is good, clone it and put in data cache
          const responseToCache = response.clone();
          const cache = await caches.open(DATA_CACHE_NAME);
          cache.put(event.request, responseToCache);
          return response;
        })
        .catch(async () => {
          // Network failed, try to get from data cache
          const cachedResponse = await caches.match(event.request);
          if (cachedResponse) {
            console.log(`Service Worker: Serving API response for ${requestUrl.pathname} from cache.`);
            return cachedResponse;
          }
          // If not in cache and offline, throw error
          throw new Error('No network and no cached API data.');
        })
    );
    return; // Stop further processing for this request
  }

  // Default: Network-only or Network-first strategy for other requests (e.g., third-party APIs not explicitly cached)
  event.respondWith(fetch(event.request));
});

// --- Background Sync ---
self.addEventListener('sync', (event) => {
  if (event.tag === 'sync-pending-workspace-changes') {
    console.log('Service Worker: Performing background sync for pending changes...');
    event.waitUntil(syncPendingWorkspaceChanges());
  }
});

async function syncPendingWorkspaceChanges() {
    let db;
    try {
        // Re-open IndexedDB connection within the service worker context
        db = await new Promise((resolve, reject) => {
            const request = indexedDB.open('reactWorkspaceData', 1); // Ensure this matches your localForage instance name
            request.onsuccess = (e) => resolve(e.target.result);
            request.onerror = (e) => reject(e.target.error);
            request.onupgradeneeded = (e) => {
                // This scenario indicates a problem as DB structure should be stable
                console.warn('IndexedDB upgrade needed during sync. This is unexpected.');
                e.target.transaction.abort(); // Prevent potential data loss
            };
        });

        // Use localForage to interact with IndexedDB from Service Worker if you configure it.
        // For simplicity, directly using IndexedDB API here.
        const transaction = db.transaction(['pendingSync'], 'readwrite');
        const store = transaction.objectStore('pendingSync');
        const pendingChanges = await new Promise((resolve, reject) => {
            const req = store.getAll();
            req.onsuccess = () => resolve(req.result);
            req.onerror = () => reject(req.error);
        });


        for (const change of pendingChanges) {
            console.log('Processing pending change:', change.type, change.data);
            try {
                let apiResponse;
                switch (change.type) {
                    case 'file_upload':
                        // Note: For file uploads, the `data` should contain raw file content (e.g., Base64 or Blob)
                        // not just a local file path, as Service Worker can't access local file system directly.
                        apiResponse = await fetch('/api/drive/files/upload', {
                            method: 'POST',
                            headers: { 'Content-Type': 'application/json' },
                            body: JSON.stringify(change.data),
                        });
                        break;
                    case 'email_send':
                        apiResponse = await fetch('/api/gmail/send', {
                            method: 'POST',
                            headers: { 'Content-Type': 'application/json' },
                            body: JSON.stringify(change.data),
                        });
                        break;
                    case 'calendar_create':
                        apiResponse = await fetch('/api/calendar/events', {
                            method: 'POST',
                            headers: { 'Content-Type': 'application/json' },
                            body: JSON.stringify(change.data),
                        });
                        break;
                    default:
                        console.warn('Unknown pending change type:', change.type);
                        continue;
                }

                if (apiResponse.ok) {
                    console.log(`Successfully synced ${change.type} operation.`);
                    await new Promise((resolve, reject) => {
                        const deleteReq = store.delete(change.id);
                        deleteReq.onsuccess = resolve;
                        deleteReq.onerror = reject;
                    });
                    // Optionally: Send a message to the client to refresh its UI/data
                    self.clients.matchAll().then(clients => {
                        clients.forEach(client => client.postMessage({ type: 'SYNC_COMPLETE', payload: { syncedType: change.type } }));
                    });
                } else {
                    const errorText = await apiResponse.text();
                    console.error(`Failed to sync ${change.type}:`, apiResponse.status, errorText);
                    // Do not delete from queue; it will be retried later by the SyncManager
                }
            } catch (error) {
                console.error(`Network error during ${change.type} sync:`, error);
                // Do not delete from queue; it will be retried later
            }
        }
        await new Promise(resolve => transaction.oncomplete = resolve); // Ensure transaction completes
        console.log('Service Worker: Background sync completed.');
    } catch (error) {
        console.error('Service Worker: Error during background sync process:', error);
    } finally {
        if (db) db.close(); // Close DB connection
    }
}



import React from 'react';
import ReactDOM from 'react-dom/client';
import App from './App.tsx';
import './index.css';

ReactDOM.createRoot(document.getElementById('root')!).render(
  <React.StrictMode>
    <App />
  </React.StrictMode>,
);

// Service Worker Registration
if ('serviceWorker' in navigator) {
  window.addEventListener('load', () => {
    navigator.serviceWorker.register('/service-worker.js')
      .then(registration => {
        console.log('Service Worker registered with scope:', registration.scope);

        // Listen for messages from the Service Worker (e.g., sync complete notifications)
        navigator.serviceWorker.addEventListener('message', event => {
          if (event.data && event.data.type === 'SYNC_COMPLETE') {
            console.log('Received SYNC_COMPLETE from SW:', event.data.payload);
            // You might trigger a data refresh in your React app here
            // e.g., using a global state manager or context API
          }
        });
      })
      .catch(error => {
        console.error('Service Worker registration failed:', error);
      });
  });
}



import React, { useState, useEffect, useCallback } from 'react';
import localforage from 'localforage';
import './App.css'; // Your main CSS file
import DriveSection from './components/DriveSection';
import GmailSection from './components/GmailSection';
import CalendarSection from './components/CalendarSection';

// Configure localForage for IndexedDB
localforage.config({
  name: 'reactWorkspaceData', // Database name
  storeName: 'offlineStore', // Store for general data
});

// Configure separate store for pending sync operations
const pendingSyncStore = localforage.createInstance({
  name: 'reactWorkspaceData',
  storeName: 'pendingSync',
});

function App() {
  const [isAuthenticated, setIsAuthenticated] = useState(false);
  const [isOnline, setIsOnline] = useState(navigator.onLine);

  useEffect(() => {
    // Check for authentication success from URL parameter (after OAuth redirect)
    const urlParams = new URLSearchParams(window.location.search);
    if (urlParams.get('authSuccess') === 'true') {
      setIsAuthenticated(true);
      console.log('Authenticated successfully!');
      // Clean up the URL
      window.history.replaceState({}, document.title, window.location.pathname);
    }

    // Set up network status listeners
    const handleOnline = () => setIsOnline(true);
    const handleOffline = () => setIsOnline(false);

    window.addEventListener('online', handleOnline);
    window.addEventListener('offline', handleOffline);

    // Initial check (in a real app, you'd check a server-side session or a token in localStorage)
    const checkAuthStatus = async () => {
        try {
            // Attempt a simple authenticated API call to check token validity
            // This is a proxy for checking if the backend has a valid session/token
            const response = await fetch('/api/drive/files', { method: 'HEAD' }); // HEAD is lighter than GET
            if (response.ok) {
                setIsAuthenticated(true);
            } else {
                setIsAuthenticated(false);
                console.log('Backend reports no valid session or authentication needed.');
            }
        } catch (error) {
            console.error('Error checking auth status:', error);
            setIsAuthenticated(false);
        }
    };
    checkAuthStatus();


    return () => {
      window.removeEventListener('online', handleOnline);
      window.removeEventListener('offline', handleOffline);
    };
  }, []);

  const handleAuthRedirect = () => {
    window.location.href = '/auth/google'; // Redirect to your Node.js/Python OAuth endpoint
  };

  const handleLogout = async () => {
    // In a real app, you'd hit a backend logout endpoint to revoke tokens
    // For this example, just clear local state (tokens are still on server for this demo)
    setIsAuthenticated(false);
    // You might also clear IndexedDB data relevant to the user here
    // await localforage.clear(); // Clear all data
    console.log('Logged out (client-side only for this demo)');
    window.location.reload(); // Simple refresh for state cleanup
  };

  // Function to add an operation to the pending sync queue in IndexedDB
  const addToPendingSync = useCallback(async (type: string, data: any) => {
    try {
      await pendingSyncStore.setItem(Date.now().toString(), { // Use timestamp as key for unique ID
        type,
        data,
        timestamp: new Date().toISOString()
      });
      console.log(`Queued offline change: ${type}`);

      // Request background sync
      if ('serviceWorker' in navigator && 'SyncManager' in window) {
        navigator.serviceWorker.ready.then(reg => {
          reg.sync.register('sync-pending-workspace-changes')
            .then(() => console.log('Background sync registered!'))
            .catch(err => console.error('Background sync registration failed:', err));
        }).catch(err => {
          console.error('Service Worker not ready for sync:', err);
        });
      } else {
        console.warn('Background Sync API not supported or service worker not ready. Sync will happen on next online app load.');
      }
    } catch (error) {
      console.error('Error adding to pending sync:', error);
      alert('Failed to save offline change. Data might be lost if not synced.');
    }
  }, []);


  return (
    <div className="App">
      <header className="App-header">
        <h1>My Advanced Workspace</h1>
        <div className="auth-status">
          <span className={`online-status ${isOnline ? 'online' : 'offline'}`}>
            {isOnline ? 'Online' : 'Offline'}
          </span>
          {!isAuthenticated ? (
            <button onClick={handleAuthRedirect}>Login with Google</button>
          ) : (
            <button onClick={handleLogout}>Logout</button>
          )}
        </div>
      </header>
      <main>
        {!isAuthenticated ? (
          <p>Please log in to access your Google Workspace data.</p>
        ) : (
          <>
            <DriveSection isOnline={isOnline} addToPendingSync={addToPendingSync} />
            <GmailSection isOnline={isOnline} addToPendingSync={addToPendingSync} />
            <CalendarSection isOnline={isOnline} addToPendingSync={addToPendingSync} />
          </>
        )}
      </main>
    </div>
  );
}

export default App;



import React, { useState, useEffect, useCallback } from 'react';
import localforage from 'localforage';

interface DriveFile {
  id: string;
  name: string;
  mimeType: string;
  modifiedTime: string;
  // Add other properties you need
}

interface DriveSectionProps {
  isOnline: boolean;
  addToPendingSync: (type: string, data: any) => Promise<void>;
}

// Configure localForage instance for Drive data
const driveStore = localforage.createInstance({
  name: 'reactWorkspaceData',
  storeName: 'driveFiles',
});

const DriveSection: React.FC<DriveSectionProps> = ({ isOnline, addToPendingSync }) => {
  const [files, setFiles] = useState<DriveFile[]>([]);
  const [loading, setLoading] = useState(false);
  const [error, setError] = useState<string | null>(null);
  const [selectedFile, setSelectedFile] = useState<File | null>(null);

  const fetchFiles = useCallback(async (source: 'online' | 'offline') => {
    setLoading(true);
    setError(null);
    try {
      let fetchedFiles: DriveFile[] = [];
      if (source === 'online' && isOnline) {
        console.log('Fetching Drive files online...');
        const response = await fetch('/api/drive/files');
        if (!response.ok) {
          throw new Error(`HTTP error! status: ${response.status}`);
        }
        fetchedFiles = await response.json();
        // Save to IndexedDB
        await driveStore.clear(); // Clear old data (for simplicity)
        for (const file of fetchedFiles) {
          await driveStore.setItem(file.id, file);
        }
        console.log(`Saved ${fetchedFiles.length} Drive files to IndexedDB.`);
      } else {
        console.log('Fetching Drive files from IndexedDB...');
        await driveStore.iterate((value: DriveFile) => {
          fetchedFiles.push(value);
        });
      }
      setFiles(fetchedFiles);
    } catch (err: any) {
      console.error('Error fetching Drive files:', err);
      setError(`Failed to load Drive files from ${source}. ${err.message}`);
      // Fallback to offline data if online fetch failed
      if (source === 'online' && isOnline) {
        alert('Online fetch failed. Displaying offline data.');
        fetchFiles('offline'); // Try to load from cache
      }
    } finally {
      setLoading(false);
    }
  }, [isOnline]);

  useEffect(() => {
    fetchFiles('online'); // Initial fetch
  }, [fetchFiles]);

  const handleFileChange = (event: React.ChangeEvent<HTMLInputElement>) => {
    if (event.target.files && event.target.files[0]) {
      setSelectedFile(event.target.files[0]);
    }
  };

  const handleUploadFile = async () => {
    if (!selectedFile) {
      alert('Please select a file to upload.');
      return;
    }

    const reader = new FileReader();
    reader.onloadend = async () => {
      if (reader.result) {
        const base64Content = (reader.result as string).split(',')[1]; // Get base64 string without prefix
        const fileData = {
          fileName: selectedFile.name,
          mimeType: selectedFile.type,
          base64Content: base64Content,
        };

        if (isOnline) {
          try {
            const response = await fetch('/api/drive/files/upload', {
              method: 'POST',
              headers: { 'Content-Type': 'application/json' },
              body: JSON.stringify(fileData),
            });
            if (!response.ok) {
              throw new Error(`Upload failed with status: ${response.status}`);
            }
            alert('File uploaded successfully!');
            fetchFiles('online'); // Refresh list
          } catch (err: any) {
            console.error('Online upload failed:', err);
            alert(`Online upload failed. Saving for offline sync. Error: ${err.message}`);
            await addToPendingSync('file_upload', fileData);
          }
        } else {
          alert('Offline. File queued for upload when online.');
          await addToPendingSync('file_upload', fileData);
        }
        setSelectedFile(null); // Clear selected file
        if (document.getElementById('file-upload-input')) {
            (document.getElementById('file-upload-input') as HTMLInputElement).value = ''; // Clear input
        }
      }
    };
    reader.readAsDataURL(selectedFile); // Read file as Base64
  };

  const handleDownloadFile = async (fileId: string, fileName: string) => {
    if (!isOnline) {
        alert('Cannot download file when offline. Try when online.');
        return;
    }
    try {
        const response = await fetch(`/api/drive/files/${fileId}/download`);
        if (!response.ok) throw new Error('Download failed');
        const blob = await response.blob();
        const url = URL.createObjectURL(blob);
        const a = document.createElement('a');
        a.href = url;
        a.download = fileName;
        document.body.appendChild(a);
        a.click();
        document.body.removeChild(a);
        URL.revokeObjectURL(url);
    } catch (e: any) {
        console.error('Error downloading:', e);
        alert(`Failed to download file online. Error: ${e.message}`);
    }
  };


  return (
    <section>
      <h2>Google Drive Files</h2>
      <button onClick={() => fetchFiles('online')} disabled={!isOnline || loading}>
        {loading && isOnline ? 'Refreshing...' : 'Refresh Online Files'}
      </button>
      <button onClick={() => fetchFiles('offline')} disabled={loading}>
        {loading && !isOnline ? 'Loading Offline...' : 'View Offline Files'}
      </button>

      <div style={{ marginTop: '10px', padding: '10px', border: '1px solid #eee' }}>
        <h3>Upload New File</h3>
        <input type="file" id="file-upload-input" onChange={handleFileChange} />
        <button onClick={handleUploadFile} disabled={!selectedFile}>
          {isOnline ? 'Upload File' : 'Queue Upload Offline'}
        </button>
        {selectedFile && <p>Selected: {selectedFile.name}</p>}
      </div>

      {loading && <p>Loading files...</p>}
      {error && <p className="error">{error}</p>}
      <ul>
        {files.length === 0 && !loading && !error && <p>No files found.</p>}
        {files.map((file) => (
          <li key={file.id}>
            <strong>{file.name}</strong> ({file.mimeType}) - Modified: {new Date(file.modifiedTime).toLocaleDateString()}
            <button onClick={() => handleDownloadFile(file.id, file.name)} style={{ marginLeft: '10px' }}>Download</button>
          </li>
        ))}
      </ul>
    </section>
  );
};

export default DriveSection;



import React, { useState, useEffect, useCallback } from 'react';
import localforage from 'localforage';

interface GmailMessage {
  id: string;
  snippet: string;
  subject: string;
  sender: string;
  received_time: string;
  body: string; // The full email body
  // Add other properties you need
}

interface GmailSectionProps {
  isOnline: boolean;
  addToPendingSync: (type: string, data: any) => Promise<void>;
}

const gmailStore = localforage.createInstance({
  name: 'reactWorkspaceData',
  storeName: 'gmailMessages',
});

const GmailSection: React.FC<GmailSectionProps> = ({ isOnline, addToPendingSync }) => {
  const [messages, setMessages] = useState<GmailMessage[]>([]);
  const [loading, setLoading] = useState(false);
  const [error, setError] = useState<string | null>(null);
  const [showCompose, setShowCompose] = useState(false);
  const [emailTo, setEmailTo] = useState('');
  const [emailSubject, setEmailSubject] = useState('');
  const [emailBody, setEmailBody] = useState('');

  const fetchMessages = useCallback(async (source: 'online' | 'offline') => {
    setLoading(true);
    setError(null);
    try {
      let fetchedMessages: GmailMessage[] = [];
      if (source === 'online' && isOnline) {
        console.log('Fetching Gmail messages online...');
        const response = await fetch('/api/gmail/messages');
        if (!response.ok) {
          throw new Error(`HTTP error! status: ${response.status}`);
        }
        const messageStubs = await response.json();

        // For each message stub, fetch full content and save
        const fullMessagesPromises = messageStubs.map(async (stub: { id: string }) => {
            const detailResponse = await fetch(`/api/gmail/messages/${stub.id}`);
            if (!detailResponse.ok) {
                console.warn(`Failed to fetch full message for ID: ${stub.id}`);
                return null;
            }
            const fullMessage = await detailResponse.json();
            // Basic parsing for display
            const headers = fullMessage.payload?.headers?.reduce((acc: any, h: any) => {
                acc[h.name] = h.value;
                return acc;
            }, {});
            let bodyContent = '';
            // Simplified body extraction (might need more robust parsing for complex emails)
            if (fullMessage.payload?.parts) {
                const part = fullMessage.payload.parts.find((p: any) => p.mimeType === 'text/plain' || p.mimeType === 'text/html');
                if (part?.body?.data) {
                    bodyContent = atob(part.body.data.replace(/-/g, '+').replace(/_/g, '/'));
                    // If HTML, you might want to strip HTML tags here
                }
            } else if (fullMessage.payload?.body?.data) {
                 bodyContent = atob(fullMessage.payload.body.data.replace(/-/g, '+').replace(/_/g, '/'));
            }


            const msgData: GmailMessage = {
                id: fullMessage.id,
                snippet: fullMessage.snippet || '',
                subject: headers?.Subject || 'No Subject',
                sender: headers?.From || 'Unknown Sender',
                received_time: new Date(parseInt(fullMessage.internalDate)).toISOString(),
                body: bodyContent,
            };
            return msgData;
        });

        const resolvedMessages = (await Promise.all(fullMessagesPromises)).filter(Boolean) as GmailMessage[];
        fetchedMessages = resolvedMessages;

        // Save to IndexedDB
        await gmailStore.clear();
        for (const msg of fetchedMessages) {
          await gmailStore.setItem(msg.id, msg);
        }
        console.log(`Saved ${fetchedMessages.length} Gmail messages to IndexedDB.`);
      } else {
        console.log('Fetching Gmail messages from IndexedDB...');
        await gmailStore.iterate((value: GmailMessage) => {
          fetchedMessages.push(value);
        });
      }
      setMessages(fetchedMessages.sort((a,b) => new Date(b.received_time).getTime() - new Date(a.received_time).getTime())); // Sort by time
    } catch (err: any) {
      console.error('Error fetching Gmail messages:', err);
      setError(`Failed to load Gmail messages from ${source}. ${err.message}`);
      if (source === 'online' && isOnline) {
        alert('Online fetch failed. Displaying offline data.');
        fetchMessages('offline');
      }
    } finally {
      setLoading(false);
    }
  }, [isOnline]);

  useEffect(() => {
    fetchMessages('online');
  }, [fetchMessages]);

  const handleSendEmail = async () => {
    if (!emailTo || !emailSubject || !emailBody) {
      alert('Please fill in all email fields.');
      return;
    }

    const emailData = {
      to: emailTo,
      subject: emailSubject,
      body: emailBody,
    };

    if (isOnline) {
      try {
        const response = await fetch('/api/gmail/send', {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify(emailData),
        });
        if (!response.ok) {
          throw new Error(`Send failed with status: ${response.status}`);
        }
        alert('Email sent successfully!');
        setShowCompose(false);
        setEmailTo('');
        setEmailSubject('');
        setEmailBody('');
        fetchMessages('online'); // Refresh list
      } catch (err: any) {
        console.error('Online email send failed:', err);
        alert(`Online email send failed. Saving for offline sync. Error: ${err.message}`);
        await addToPendingSync('email_send', emailData);
      }
    } else {
      alert('Offline. Email queued for sending when online.');
      await addToPendingSync('email_send', emailData);
      setShowCompose(false); // Close compose form
      setEmailTo('');
      setEmailSubject('');
      setEmailBody('');
    }
  };

  return (
    <section>
      <h2>Gmail Messages</h2>
      <button onClick={() => fetchMessages('online')} disabled={!isOnline || loading}>
        {loading && isOnline ? 'Refreshing...' : 'Refresh Online Mail'}
      </button>
      <button onClick={() => fetchMessages('offline')} disabled={loading}>
        {loading && !isOnline ? 'Loading Offline...' : 'View Offline Mail'}
      </button>
      <button onClick={() => setShowCompose(true)} disabled={showCompose}>Compose Email</button>

      {showCompose && (
        <div style={{ marginTop: '10px', padding: '10px', border: '1px solid #eee' }}>
          <h3>Compose New Email</h3>
          <input
            type="text"
            placeholder="To"
            value={emailTo}
            onChange={(e) => setEmailTo(e.target.value)}
          />
          <input
            type="text"
            placeholder="Subject"
            value={emailSubject}
            onChange={(e) => setEmailSubject(e.target.value)}
          />
          <textarea
            placeholder="Body"
            value={emailBody}
            onChange={(e) => setEmailBody(e.target.value)}
          ></textarea>
          <button onClick={handleSendEmail}>
            {isOnline ? 'Send' : 'Queue Send Offline'}
          </button>
          <button onClick={() => setShowCompose(false)}>Cancel</button>
        </div>
      )}

      {loading && <p>Loading messages...</p>}
      {error && <p className="error">{error}</p>}
      <ul>
        {messages.length === 0 && !loading && !error && <p>No messages found.</p>}
        {messages.map((msg) => (
          <li key={msg.id}>
            <strong>Subject: {msg.subject}</strong><br/>
            From: {msg.sender}<br/>
            Snippet: {msg.snippet}<br/>
            Received: {new Date(msg.received_time).toLocaleString()}
          </li>
        ))}
      </ul>
    </section>
  );
};

export default GmailSection;



import React, { useState, useEffect, useCallback } from 'react';
import localforage from 'localforage';

interface CalendarEvent {
  id: string;
  summary: string;
  description?: string;
  start_time: string; // ISO string
  end_time: string; // ISO string
  location?: string;
  status: string;
}

interface CalendarSectionProps {
  isOnline: boolean;
  addToPendingSync: (type: string, data: any) => Promise<void>;
}

const calendarStore = localforage.createInstance({
  name: 'reactWorkspaceData',
  storeName: 'calendarEvents',
});

const CalendarSection: React.FC<CalendarSectionProps> = ({ isOnline, addToPendingSync }) => {
  const [events, setEvents] = useState<CalendarEvent[]>([]);
  const [loading, setLoading] = useState(false);
  const [error, setError] = useState<string | null>(null);
  const [showCreateForm, setShowCreateForm] = useState(false);
  const [eventSummary, setEventSummary] = useState('');
  const [eventDescription, setEventDescription] = useState('');
  const [eventStart, setEventStart] = useState('');
  const [eventEnd, setEventEnd] = useState('');
  const [eventLocation, setEventLocation] = useState('');


  const fetchEvents = useCallback(async (source: 'online' | 'offline') => {
    setLoading(true);
    setError(null);
    try {
      let fetchedEvents: CalendarEvent[] = [];
      if (source === 'online' && isOnline) {
        console.log('Fetching Calendar events online...');
        const response = await fetch('/api/calendar/events');
        if (!response.ok) {
          throw new Error(`HTTP error! status: ${response.status}`);
        }
        const apiEvents = await response.json();

        // Map API response to your local CalendarEvent interface
        fetchedEvents = apiEvents.map((event: any) => ({
            id: event.id,
            summary: event.summary,
            description: event.description || '',
            start_time: event.start.dateTime || event.start.date,
            end_time: event.end.dateTime || event.end.date,
            location: event.location || '',
            status: event.status,
        }));

        // Save to IndexedDB
        await calendarStore.clear();
        for (const event of fetchedEvents) {
          await calendarStore.setItem(event.id, event);
        }
        console.log(`Saved ${fetchedEvents.length} Calendar events to IndexedDB.`);
      } else {
        console.log('Fetching Calendar events from IndexedDB...');
        await calendarStore.iterate((value: CalendarEvent) => {
          fetchedEvents.push(value);
        });
      }
      setEvents(fetchedEvents.sort((a,b) => new Date(a.start_time).getTime() - new Date(b.start_time).getTime())); // Sort by start time
    } catch (err: any) {
      console.error('Error fetching Calendar events:', err);
      setError(`Failed to load Calendar events from ${source}. ${err.message}`);
      if (source === 'online' && isOnline) {
        alert('Online fetch failed. Displaying offline data.');
        fetchEvents('offline');
      }
    } finally {
      setLoading(false);
    }
  }, [isOnline]);

  useEffect(() => {
    fetchEvents('online');
  }, [fetchEvents]);

  const handleCreateEvent = async () => {
    if (!eventSummary || !eventStart || !eventEnd) {
      alert('Please fill in Summary, Start, and End fields.');
      return;
    }

    const eventData = {
      summary: eventSummary,
      description: eventDescription,
      start: eventStart, // ISO string
      end: eventEnd,     // ISO string
      location: eventLocation,
    };

    if (isOnline) {
      try {
        const response = await fetch('/api/calendar/events', {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify(eventData),
        });
        if (!response.ok) {
          throw new Error(`Create event failed with status: ${response.status}`);
        }
        alert('Event created successfully!');
        setShowCreateForm(false);
        setEventSummary('');
        setEventDescription('');
        setEventStart('');
        setEventEnd('');
        setEventLocation('');
        fetchEvents('online'); // Refresh list
      } catch (err: any) {
        console.error('Online event creation failed:', err);
        alert(`Online event creation failed. Saving for offline sync. Error: ${err.message}`);
        await addToPendingSync('calendar_create', eventData);
      }
    } else {
      alert('Offline. Event queued for creation when online.');
      await addToPendingSync('calendar_create', eventData);
      setShowCreateForm(false); // Close form
      setEventSummary('');
      setEventDescription('');
      setEventStart('');
      setEventEnd('');
      setEventLocation('');
    }
  };

  return (
    <section>
      <h2>Google Calendar Events</h2>
      <button onClick={() => fetchEvents('online')} disabled={!isOnline || loading}>
        {loading && isOnline ? 'Refreshing...' : 'Refresh Online Events'}
      </button>
      <button onClick={() => fetchEvents('offline')} disabled={loading}>
        {loading && !isOnline ? 'Loading Offline...' : 'View Offline Events'}
      </button>
      <button onClick={() => setShowCreateForm(true)} disabled={showCreateForm}>Create Event</button>

      {showCreateForm && (
        <div style={{ marginTop: '10px', padding: '10px', border: '1px solid #eee' }}>
          <h3>Create New Event</h3>
          <input
            type="text"
            placeholder="Summary"
            value={eventSummary}
            onChange={(e) => setEventSummary(e.target.value)}
          />
          <input
            type="text"
            placeholder="Description (optional)"
            value={eventDescription}
            onChange={(e) => setEventDescription(e.target.value)}
          />
          <label>Start Time:</label>
          <input
            type="datetime-local"
            value={eventStart}
            onChange={(e) => setEventStart(e.target.value)}
          />
          <label>End Time:</label>
          <input
            type="datetime-local"
            value={eventEnd}
            onChange={(e) => setEventEnd(e.target.value)}
          />
          <input
            type="text"
            placeholder="Location (optional)"
            value={eventLocation}
            onChange={(e) => setEventLocation(e.target.value)}
          />
          <button onClick={handleCreateEvent}>
            {isOnline ? 'Create Event' : 'Queue Create Offline'}
          </button>
          <button onClick={() => setShowCreateForm(false)}>Cancel</button>
        </div>
      )}

      {loading && <p>Loading events...</p>}
      {error && <p className="error">{error}</p>}
      <ul>
        {events.length === 0 && !loading && !error && <p>No events found.</p>}
        {events.map((event) => (
          <li key={event.id}>
            <strong>{event.summary}</strong><br/>
            {event.description && <p><em>{event.description}</em></p>}
            Starts: {new Date(event.start_time).toLocaleString()}<br/>
            Ends: {new Date(event.end_time).toLocaleString()}<br/>
            {event.location && `Location: ${event.location}`}
          </li>
        ))}
      </ul>
    </section>
  );
};

export default CalendarSection;



body {
  margin: 0;
  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Roboto', 'Oxygen',
    'Ubuntu', 'Cantarell', 'Fira Sans', 'Droid Sans', 'Helvetica Neue',
    sans-serif;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  background-color: #f4f7f6;
  color: #333;
}

code {
  font-family: source-code-pro, Menlo, Monaco, Consolas, 'Courier New',
    monospace;
}



.App {
  text-align: center;
  max-width: 1000px;
  margin: 0 auto;
  padding: 20px;
}

.App-header {
  background-color: #ffffff;
  padding: 20px;
  border-bottom: 1px solid #e0e0e0;
  box-shadow: 0 2px 5px rgba(0, 0, 0, 0.05);
  display: flex;
  justify-content: space-between;
  align-items: center;
  margin-bottom: 30px;
  border-radius: 8px;
}

.App-header h1 {
  margin: 0;
  color: #2196f3;
}

.auth-status {
  display: flex;
  align-items: center;
}

.online-status {
  font-weight: bold;
  margin-right: 15px;
  padding: 5px 10px;
  border-radius: 4px;
}

.online-status.online {
  color: #4caf50; /* Green */
  background-color: #e8f5e9;
}

.online-status.offline {
  color: #f44336; /* Red */
  background-color: #ffebee;
}

button {
  background-color: #2196f3;
  color: white;
  padding: 10px 18px;
  border: none;
  border-radius: 5px;
  cursor: pointer;
  font-size: 1rem;
  transition: background-color 0.3s ease;
  margin-left: 10px;
}

button:hover {
  background-color: #1976d2;
}

button:disabled {
  background-color: #90caf9;
  cursor: not-allowed;
}

main {
  text-align: left;
}

section {
  background-color: #ffffff;
  padding: 25px;
  margin-bottom: 25px;
  border-radius: 8px;
  box-shadow: 0 2px 5px rgba(0, 0, 0, 0.05);
}

section h2 {
  color: #3f51b5;
  margin-top: 0;
  margin-bottom: 20px;
}

section h3 {
  color: #607d8b;
  margin-top: 20px;
  margin-bottom: 15px;
}

ul {
  list-style: none;
  padding: 0;
}

li {
  background-color: #f9f9f9;
  border: 1px solid #e0e0e0;
  padding: 15px;
  margin-bottom: 10px;
  border-radius: 5px;
  display: flex;
  flex-direction: column;
  gap: 5px;
}

input[type="text"],
input[type="datetime-local"],
textarea,
input[type="file"] {
  width: calc(100% - 20px);
  padding: 10px;
  margin-bottom: 15px;
  border: 1px solid #ccc;
  border-radius: 4px;
  box-sizing: border-box;
}

label {
    display: block;
    margin-bottom: 5px;
    font-weight: bold;
    color: #555;
}

textarea {
  min-height: 80px;
  resize: vertical;
}

.error {
    color: #d32f2f;
    background-color: #ffebee;
    border: 1px solid #d32f2f;
    padding: 10px;
    border-radius: 4px;
    margin-top: 15px;
}



npm run dev



// --- Forward Declarations & Includes (Simplified) ---
#include <iostream>
#include <string>
#include <vector>
#include <map>
#include <fstream>
#include <chrono> // For timestamps
#include <thread> // For background sync (basic)
#include <mutex>  // For thread safety
#include <condition_variable> // For signaling sync
#include <algorithm> // For std::find_if

// Assume external libraries are integrated for:
// #include <curl/curl.h> // For HTTP
// #include <nlohmann/json.hpp> // For JSON
// #include <sqlite3.h> // For SQLite

// Mock Headers for external libs
namespace nlohmann {
    class json {
    public:
        // Mock members for basic JSON operations
        std::string dump() const { return "{}"; }
        static json parse(const std::string& s) { return json{}; }
        template<typename T> T get() const { return T{}; }
        // Add more mock methods as needed for demonstration
        bool contains(const std::string& key) const { return true; } // Mock
        json operator[](const std::string& key) { return *this; }
        json operator[](int index) { return *this; }
        bool is_array() const { return false; }
        bool is_string() const { return false; }
        // For array iteration mock
        class iterator {
        public:
            json& operator*() { return *new json(); } // Return a dummy json object
            iterator& operator++() { return *this; }
            bool operator!=(const iterator& other) const { return false; } // Always false for single element
        };
        iterator begin() { return iterator(); }
        iterator end() { return iterator(); }
        // Allow assignment from strings for simplicity
        json& operator=(const std::string& s) { return *this; }
        json& operator=(const char* s) { return *this; }
        json& operator=(int i) { return *this; }
        json& operator=(bool b) { return *this; }
        operator std::string() const { return ""; }
    };
} // namespace nlohmann

// Mock CURL (for demonstration, real CURL interaction is more complex)
struct CURL_MOCK_HANDLE {};
extern "C" {
    CURL_MOCK_HANDLE* curl_easy_init() { return new CURL_MOCK_HANDLE(); }
    void curl_easy_setopt(CURL_MOCK_HANDLE*, int, const char*) {}
    void curl_easy_setopt(CURL_MOCK_HANDLE*, int, long) {}
    void curl_easy_setopt(CURL_MOCK_HANDLE*, int, void*) {} // For write callback
    int curl_easy_perform(CURL_MOCK_HANDLE*) { return 0; } // Success
    void curl_easy_cleanup(CURL_MOCK_HANDLE*) {}
    enum CURLoption { CURLOPT_URL, CURLOPT_HTTPHEADER, CURLOPT_POST, CURLOPT_POSTFIELDS, CURLOPT_WRITEFUNCTION, CURLOPT_WRITEDATA }; // Mock
    enum CURLcode { CURLE_OK, CURLE_LAST }; // Mock
    struct curl_slist {}; // Mock
    curl_slist* curl_slist_append(curl_slist*, const char*) { return new curl_slist(); }
    void curl_slist_free_all(curl_slist*) {}
}

// Mock SQLite (for demonstration)
struct sqlite3_mock {};
struct sqlite3_stmt_mock {};
extern "C" {
    int sqlite3_open(const char*, sqlite3_mock**) { return 0; } // Success
    int sqlite3_close(sqlite3_mock*) { return 0; }
    int sqlite3_exec(sqlite3_mock*, const char*, void*, void*, char**) { return 0; }
    int sqlite3_prepare_v2(sqlite3_mock*, const char*, int, sqlite3_stmt_mock**, const char**) { return 0; }
    int sqlite3_bind_text(sqlite3_stmt_mock*, int, const char*, int, void*) { return 0; }
    int sqlite3_bind_int(sqlite3_stmt_mock*, int, int) { return 0; }
    int sqlite3_step(sqlite3_stmt_mock*) { return 0; } // SQLITE_ROW or SQLITE_DONE
    int sqlite3_column_count(sqlite3_stmt_mock*) { return 0; }
    const unsigned char* sqlite3_column_text(sqlite3_stmt_mock*, int) { return (const unsigned char*)""; }
    int sqlite3_column_int(sqlite3_stmt_mock*, int) { return 0; }
    int sqlite3_finalize(sqlite3_stmt_mock*) { return 0; }
    enum { SQLITE_OK, SQLITE_ROW, SQLITE_DONE }; // Mock return codes
}


// --- Data Models (Simplified) ---
struct GoogleCredentials {
    std::string accessToken;
    std::string refreshToken;
    std::chrono::time_point<std::chrono::system_clock> expiryTime;

    bool isValid() const {
        return !accessToken.empty() && std::chrono::system_clock::now() < expiryTime;
    }
    bool needsRefresh() const {
        return !refreshToken.empty() && std::chrono::system_clock::now() >= expiryTime;
    }
};

struct DriveFile {
    std::string id;
    std::string name;
    std::string mimeType;
    std::string modifiedTime; // ISO 8601 string
    std::string localContentPath; // Path to downloaded file
    bool isLocallyModified = false; // Flag for offline changes
    std::string etag; // For conflict detection and conditional requests
};

struct GmailMessage {
    std::string id;
    std::string threadId;
    std::string snippet;
    std::string subject;
    std::string sender;
    std::string receivedTime; // ISO 8601 string
    std::string body;
    bool isRead = false;
};

struct CalendarEvent {
    std::string id;
    std::string summary;
    std::string description;
    std::string startTime; // ISO 8601 string
    std::string endTime;   // ISO 8601 string
    std::string location;
    std::string status;
    bool isLocallyModified = false;
};

// --- Local Database Manager ---
class LocalDB {
private:
    sqlite3_mock* db; // Mock SQLite connection
    std::string dbPath;
    std::mutex dbMutex; // Protect database access

public:
    LocalDB(const std::string& path) : dbPath(path), db(nullptr) {}

    bool open() {
        if (sqlite3_open(dbPath.c_str(), &db) != SQLITE_OK) {
            std::cerr << "Cannot open database: " << dbPath << std::endl;
            return false;
        }
        std::cout << "Database opened successfully: " << dbPath << std::endl;
        return initSchema();
    }

    void close() {
        if (db) {
            sqlite3_close(db);
            db = nullptr;
            std::cout << "Database closed." << std::endl;
        }
    }

    bool initSchema() {
        std::string schema = R"(
            CREATE TABLE IF NOT EXISTS drive_files (
                id TEXT PRIMARY KEY,
                name TEXT,
                mime_type TEXT,
                modified_time TEXT,
                local_content_path TEXT,
                is_locally_modified INTEGER DEFAULT 0,
                etag TEXT
            );
            CREATE TABLE IF NOT EXISTS gmail_messages (
                id TEXT PRIMARY KEY,
                thread_id TEXT,
                snippet TEXT,
                subject TEXT,
                sender TEXT,
                received_time TEXT,
                body TEXT,
                is_read INTEGER DEFAULT 0
            );
            CREATE TABLE IF NOT EXISTS calendar_events (
                id TEXT PRIMARY KEY,
                summary TEXT,
                description TEXT,
                start_time TEXT,
                end_time TEXT,
                location TEXT,
                status TEXT,
                is_locally_modified INTEGER DEFAULT 0
            );
            CREATE TABLE IF NOT EXISTS pending_sync_queue (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                operation_type TEXT NOT NULL, -- e.g., 'file_upload', 'email_send', 'calendar_create', 'file_delete'
                data_json TEXT NOT NULL,     -- JSON string of relevant data
                timestamp TEXT NOT NULL
            );
            CREATE TABLE IF NOT EXISTS sync_tokens (
                key TEXT PRIMARY KEY,
                token TEXT
            );
        )";
        char* errMsg = nullptr;
        if (sqlite3_exec(db, schema.c_str(), nullptr, nullptr, &errMsg) != SQLITE_OK) {
            std::cerr << "SQL error during schema init: " << errMsg << std::endl;
            sqlite3_free(errMsg);
            return false;
        }
        return true;
    }

    // --- Drive Operations ---
    void saveDriveFile(const DriveFile& file) {
        std::lock_guard<std::mutex> lock(dbMutex);
        std::string sql = "INSERT OR REPLACE INTO drive_files (id, name, mime_type, modified_time, local_content_path, is_locally_modified, etag) VALUES (?, ?, ?, ?, ?, ?, ?)";
        sqlite3_stmt_mock* stmt;
        sqlite3_prepare_v2(db, sql.c_str(), -1, &stmt, nullptr);
        sqlite3_bind_text(stmt, 1, file.id.c_str(), -1, SQLITE_TRANSIENT);
        sqlite3_bind_text(stmt, 2, file.name.c_str(), -1, SQLITE_TRANSIENT);
        sqlite3_bind_text(stmt, 3, file.mimeType.c_str(), -1, SQLITE_TRANSIENT);
        sqlite3_bind_text(stmt, 4, file.modifiedTime.c_str(), -1, SQLITE_TRANSIENT);
        sqlite3_bind_text(stmt, 5, file.localContentPath.c_str(), -1, SQLITE_TRANSIENT);
        sqlite3_bind_int(stmt, 6, file.isLocallyModified);
        sqlite3_bind_text(stmt, 7, file.etag.c_str(), -1, SQLITE_TRANSIENT);
        sqlite3_step(stmt);
        sqlite3_finalize(stmt);
    }

    std::vector<DriveFile> getDriveFiles() {
        std::lock_guard<std::mutex> lock(dbMutex);
        std::vector<DriveFile> files;
        std::string sql = "SELECT id, name, mime_type, modified_time, local_content_path, is_locally_modified, etag FROM drive_files";
        sqlite3_stmt_mock* stmt;
        sqlite3_prepare_v2(db, sql.c_str(), -1, &stmt, nullptr);
        while (sqlite3_step(stmt) == SQLITE_ROW) {
            files.push_back({
                reinterpret_cast<const char*>(sqlite3_column_text(stmt, 0)),
                reinterpret_cast<const char*>(sqlite3_column_text(stmt, 1)),
                reinterpret_cast<const char*>(sqlite3_column_text(stmt, 2)),
                reinterpret_cast<const char*>(sqlite3_column_text(stmt, 3)),
                reinterpret_cast<const char*>(sqlite3_column_text(stmt, 4)),
                static_cast<bool>(sqlite3_column_int(stmt, 5)),
                reinterpret_cast<const char*>(sqlite3_column_text(stmt, 6))
            });
        }
        sqlite3_finalize(stmt);
        return files;
    }

    // --- Gmail Operations ---
    void saveGmailMessage(const GmailMessage& msg) {
        std::lock_guard<std::mutex> lock(dbMutex);
        std::string sql = "INSERT OR REPLACE INTO gmail_messages (id, thread_id, snippet, subject, sender, received_time, body, is_read) VALUES (?, ?, ?, ?, ?, ?, ?, ?)";
        sqlite3_stmt_mock* stmt;
        sqlite3_prepare_v2(db, sql.c_str(), -1, &stmt, nullptr);
        sqlite3_bind_text(stmt, 1, msg.id.c_str(), -1, SQLITE_TRANSIENT);
        sqlite3_bind_text(stmt, 2, msg.threadId.c_str(), -1, SQLITE_TRANSIENT);
        sqlite3_bind_text(stmt, 3, msg.snippet.c_str(), -1, SQLITE_TRANSIENT);
        sqlite3_bind_text(stmt, 4, msg.subject.c_str(), -1, SQLITE_TRANSIENT);
        sqlite3_bind_text(stmt, 5, msg.sender.c_str(), -1, SQLITE_TRANSIENT);
        sqlite3_bind_text(stmt, 6, msg.receivedTime.c_str(), -1, SQLITE_TRANSIENT);
        sqlite3_bind_text(stmt, 7, msg.body.c_str(), -1, SQLITE_TRANSIENT);
        sqlite3_bind_int(stmt, 8, msg.isRead);
        sqlite3_step(stmt);
        sqlite3_finalize(stmt);
    }

    std::vector<GmailMessage> getGmailMessages() {
        std::lock_guard<std::mutex> lock(dbMutex);
        std::vector<GmailMessage> messages;
        std::string sql = "SELECT id, thread_id, snippet, subject, sender, received_time, body, is_read FROM gmail_messages ORDER BY received_time DESC";
        sqlite3_stmt_mock* stmt;
        sqlite3_prepare_v2(db, sql.c_str(), -1, &stmt, nullptr);
        while (sqlite3_step(stmt) == SQLITE_ROW) {
            messages.push_back({
                reinterpret_cast<const char*>(sqlite3_column_text(stmt, 0)),
                reinterpret_cast<const char*>(sqlite3_column_text(stmt, 1)),
                reinterpret_cast<const char*>(sqlite3_column_text(stmt, 2)),
                reinterpret_cast<const char*>(sqlite3_column_text(stmt, 3)),
                reinterpret_cast<const char*>(sqlite3_column_text(stmt, 4)),
                reinterpret_cast<const char*>(sqlite3_column_text(stmt, 5)),
                reinterpret_cast<const char*>(sqlite3_column_text(stmt, 6)),
                static_cast<bool>(sqlite3_column_int(stmt, 7))
            });
        }
        sqlite3_finalize(stmt);
        return messages;
    }

    // --- Calendar Operations ---
    void saveCalendarEvent(const CalendarEvent& event) {
        std::lock_guard<std::mutex> lock(dbMutex);
        std::string sql = "INSERT OR REPLACE INTO calendar_events (id, summary, description, start_time, end_time, location, status, is_locally_modified) VALUES (?, ?, ?, ?, ?, ?, ?, ?)";
        sqlite3_stmt_mock* stmt;
        sqlite3_prepare_v2(db, sql.c_str(), -1, &stmt, nullptr);
        sqlite3_bind_text(stmt, 1, event.id.c_str(), -1, SQLITE_TRANSIENT);
        sqlite3_bind_text(stmt, 2, event.summary.c_str(), -1, SQLITE_TRANSIENT);
        sqlite3_bind_text(stmt, 3, event.description.c_str(), -1, SQLITE_TRANSIENT);
        sqlite3_bind_text(stmt, 4, event.startTime.c_str(), -1, SQLITE_TRANSIENT);
        sqlite3_bind_text(stmt, 5, event.endTime.c_str(), -1, SQLITE_TRANSIENT);
        sqlite3_bind_text(stmt, 6, event.location.c_str(), -1, SQLITE_TRANSIENT);
        sqlite3_bind_text(stmt, 7, event.status.c_str(), -1, SQLITE_TRANSIENT);
        sqlite3_bind_int(stmt, 8, event.isLocallyModified);
        sqlite3_step(stmt);
        sqlite3_finalize(stmt);
    }

    std::vector<CalendarEvent> getCalendarEvents() {
        std::lock_guard<std::mutex> lock(dbMutex);
        std::vector<CalendarEvent> events;
        std::string sql = "SELECT id, summary, description, start_time, end_time, location, status, is_locally_modified FROM calendar_events ORDER BY start_time";
        sqlite3_stmt_mock* stmt;
        sqlite3_prepare_v2(db, sql.c_str(), -1, &stmt, nullptr);
        while (sqlite3_step(stmt) == SQLITE_ROW) {
            events.push_back({
                reinterpret_cast<const char*>(sqlite3_column_text(stmt, 0)),
                reinterpret_cast<const char*>(sqlite3_column_text(stmt, 1)),
                reinterpret_cast<const char*>(sqlite3_column_text(stmt, 2)),
                reinterpret_cast<const char*>(sqlite3_column_text(stmt, 3)),
                reinterpret_cast<const char*>(sqlite3_column_text(stmt, 4)),
                reinterpret_cast<const char*>(sqlite3_column_text(stmt, 5)),
                reinterpret_cast<const char*>(sqlite3_column_text(stmt, 6)),
                static_cast<bool>(sqlite3_column_int(stmt, 7))
            });
        }
        sqlite3_finalize(stmt);
        return events;
    }

    // --- Pending Sync Queue Operations ---
    void queuePendingOperation(const std::string& opType, const nlohmann::json& data) {
        std::lock_guard<std::mutex> lock(dbMutex);
        std::string sql = "INSERT INTO pending_sync_queue (operation_type, data_json, timestamp) VALUES (?, ?, ?)";
        sqlite3_stmt_mock* stmt;
        sqlite3_prepare_v2(db, sql.c_str(), -1, &stmt, nullptr);
        sqlite3_bind_text(stmt, 1, opType.c_str(), -1, SQLITE_TRANSIENT);
        sqlite3_bind_text(stmt, 2, data.dump().c_str(), -1, SQLITE_TRANSIENT);
        sqlite3_bind_text(stmt, 3, std::to_string(std::chrono::system_clock::now().time_since_epoch().count()).c_str(), -1, SQLITE_TRANSIENT);
        sqlite3_step(stmt);
        sqlite3_finalize(stmt);
    }

    std::vector<std::pair<int, std::pair<std::string, nlohmann::json>>> getPendingOperations() {
        std::lock_guard<std::mutex> lock(dbMutex);
        std::vector<std::pair<int, std::pair<std::string, nlohmann::json>>> operations;
        std::string sql = "SELECT id, operation_type, data_json FROM pending_sync_queue ORDER BY timestamp ASC";
        sqlite3_stmt_mock* stmt;
        sqlite3_prepare_v2(db, sql.c_str(), -1, &stmt, nullptr);
        while (sqlite3_step(stmt) == SQLITE_ROW) {
            int id = sqlite3_column_int(stmt, 0);
            std::string opType = reinterpret_cast<const char*>(sqlite3_column_text(stmt, 1));
            std::string dataJson = reinterpret_cast<const char*>(sqlite3_column_text(stmt, 2));
            operations.push_back({id, {opType, nlohmann::json::parse(dataJson)}});
        }
        sqlite3_finalize(stmt);
        return operations;
    }

    void removePendingOperation(int id) {
        std::lock_guard<std::mutex> lock(dbMutex);
        std::string sql = "DELETE FROM pending_sync_queue WHERE id = ?";
        sqlite3_stmt_mock* stmt;
        sqlite3_prepare_v2(db, sql.c_str(), -1, &stmt, nullptr);
        sqlite3_bind_int(stmt, 1, id);
        sqlite3_step(stmt);
        sqlite3_finalize(stmt);
    }

    // --- Sync Token Storage ---
    void saveSyncToken(const std::string& key, const std::string& token) {
        std::lock_guard<std::mutex> lock(dbMutex);
        std::string sql = "INSERT OR REPLACE INTO sync_tokens (key, token) VALUES (?, ?)";
        sqlite3_stmt_mock* stmt;
        sqlite3_prepare_v2(db, sql.c_str(), -1, &stmt, nullptr);
        sqlite3_bind_text(stmt, 1, key.c_str(), -1, SQLITE_TRANSIENT);
        sqlite3_bind_text(stmt, 2, token.c_str(), -1, SQLITE_TRANSIENT);
        sqlite3_step(stmt);
        sqlite3_finalize(stmt);
    }

    std::string getSyncToken(const std::string& key) {
        std::lock_guard<std::mutex> lock(dbMutex);
        std::string token;
        std::string sql = "SELECT token FROM sync_tokens WHERE key = ?";
        sqlite3_stmt_mock* stmt;
        sqlite3_prepare_v2(db, sql.c_str(), -1, &stmt, nullptr);
        sqlite3_bind_text(stmt, 1, key.c_str(), -1, SQLITE_TRANSIENT);
        if (sqlite3_step(stmt) == SQLITE_ROW) {
            token = reinterpret_cast<const char*>(sqlite3_column_text(stmt, 0));
        }
        sqlite3_finalize(stmt);
        return token;
    }
};

// --- Google API Client (Simplified HTTP & JSON Interactions) ---
class GoogleApiClient {
private:
    GoogleCredentials& creds;
    CURL_MOCK_HANDLE* curl; // Mock CURL handle

    // Mock write callback for CURL
    static size_t WriteCallback(void* contents, size_t size, size_t nmemb, void* userp) {
        ((std::string*)userp)->append((char*)contents, size * nmemb);
        return size * nmemb;
    }

    std::string makeApiRequest(const std::string& url, const std::string& method = "GET", const nlohmann::json* body = nullptr, bool download = false) {
        std::string response_data;
        if (!curl) {
            std::cerr << "CURL not initialized." << std::endl;
            return "";
        }

        curl_easy_setopt(curl, CURLOPT_URL, url.c_str());
        std::string auth_header = "Authorization: Bearer " + creds.accessToken;
        curl_slist* headers = nullptr;
        headers = curl_slist_append(headers, auth_header.c_str());
        curl_easy_setopt(curl, CURLOPT_HTTPHEADER, headers);

        if (method == "POST" || method == "PUT") {
            curl_easy_setopt(curl, CURLOPT_POST, 1L);
            if (body) {
                std::string body_str = body->dump();
                curl_easy_setopt(curl, CURLOPT_POSTFIELDS, body_str.c_str());
                // Add Content-Type header for JSON
                headers = curl_slist_append(headers, "Content-Type: application/json");
            }
        } else if (method == "GET" && download) {
             // For downloads, response will be raw binary, not JSON
             // No specific JSON headers needed.
        }

        curl_easy_setopt(curl, CURLOPT_WRITEFUNCTION, WriteCallback);
        curl_easy_setopt(curl, CURLOPT_WRITEDATA, &response_data);

        CURLcode res = curl_easy_perform(curl);
        curl_slist_free_all(headers);

        if (res != CURLE_OK) {
            std::cerr << "CURL request failed (mock): " << res << std::endl;
            return "";
        }
        return response_data;
    }

public:
    GoogleApiClient(GoogleCredentials& credentials) : creds(credentials) {
        curl = curl_easy_init();
        if (!curl) {
            std::cerr << "Failed to initialize CURL (mock)." << std::endl;
        }
    }

    ~GoogleApiClient() {
        if (curl) {
            curl_easy_cleanup(curl);
        }
    }

    // --- OAuth Operations ---
    // In a real app, this would involve a local web server or device flow.
    // Here, we just mock token setting.
    bool performOAuthFlow() {
        std::cout << "Initiating mock OAuth flow..." << std::endl;
        // Simulate obtaining tokens
        creds.accessToken = "mock_access_token_123";
        creds.refreshToken = "mock_refresh_token_456";
        creds.expiryTime = std::chrono::system_clock::now() + std::chrono::hours(1); // Expires in 1 hour
        std::cout << "Mock OAuth successful." << std::endl;
        return true;
    }

    bool refreshAccessToken() {
        if (creds.refreshToken.empty()) {
            std::cerr << "No refresh token available." << std::endl;
            return false;
        }
        std::cout << "Refreshing access token (mock)..." << std::endl;
        // Simulate API call to Google's token endpoint
        // Example: POST to https://oauth2.googleapis.com/token
        // body: grant_type=refresh_token&client_id=...&client_secret=...&refresh_token=...
        // For mock, just update tokens
        creds.accessToken = "mock_refreshed_access_token_" + std::to_string(std::chrono::system_clock::now().time_since_epoch().count());
        creds.expiryTime = std::chrono::system_clock::now() + std::chrono::hours(1);
        std::cout << "Access token refreshed (mock)." << std::endl;
        return true;
    }

    // --- Drive API ---
    std::vector<DriveFile> listDriveFiles() {
        std::vector<DriveFile> files;
        std::string url = "https://www.googleapis.com/drive/v3/files?pageSize=10&fields=nextPageToken,files(id,name,mimeType,modifiedTime,etag)";
        std::string response = makeApiRequest(url);
        if (response.empty()) return files;

        nlohmann::json json_response = nlohmann::json::parse(response);
        if (json_response.contains("files") && json_response["files"].is_array()) {
            // Mock data for demonstration
            files.push_back({"file1", "Document.docx", "application/vnd.openxmlformats-officedocument.wordprocessingml.document", "2025-07-10T10:00:00Z", "", false, "etag1"});
            files.push_back({"file2", "Spreadsheet.xlsx", "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet", "2025-07-11T11:30:00Z", "", false, "etag2"});
            files.push_back({"file3", "Presentation.pptx", "application/vnd.openxmlformats-officedocument.presentationml.presentation", "2025-07-12T14:00:00Z", "", false, "etag3"});
        }
        return files;
    }

    bool downloadDriveFile(const std::string& fileId, const std::string& outputPath) {
        std::cout << "Downloading file (mock): " << fileId << " to " << outputPath << std::endl;
        std::string url = "https://www.googleapis.com/drive/v3/files/" + fileId + "?alt=media";
        std::string file_content = makeApiRequest(url, "GET", nullptr, true); // Actual download
        if (file_content.empty()) return false;

        std::ofstream outfile(outputPath, std::ios::binary);
        if (!outfile) {
            std::cerr << "Failed to open output file: " << outputPath << std::endl;
            return false;
        }
        outfile.write(file_content.c_str(), file_content.length());
        outfile.close();
        return true;
    }

    std::string uploadDriveFile(const std::string& filePath, const std::string& fileName, const std::string& mimeType) {
        std::cout << "Uploading file (mock): " << fileName << std::endl;
        // In real CURL, you'd handle multi-part form data for file upload
        // For mock, just return a dummy ID
        return "new_file_id_" + std::to_string(std::chrono::system_clock::now().time_since_epoch().count());
    }


    // --- Gmail API ---
    std::vector<GmailMessage> listGmailMessages() {
        std::vector<GmailMessage> messages;
        std::string url = "https://www.googleapis.com/gmail/v1/users/me/messages?maxResults=10";
        std::string response = makeApiRequest(url);
        if (response.empty()) return messages;

        nlohmann::json json_response = nlohmann::json::parse(response);
        if (json_response.contains("messages") && json_response["messages"].is_array()) {
            // Mock data for demonstration
            messages.push_back({"msg1", "thread1", "Snippet of email 1", "Meeting Reminder", "sender1@example.com", "2025-07-10T09:00:00Z", "This is the body of email 1."});
            messages.push_back({"msg2", "thread2", "Snippet of email 2", "Project Update", "sender2@example.com", "2025-07-11T12:00:00Z", "This is the body of email 2."});
        }
        return messages;
    }

    std::string sendGmailMessage(const std::string& to, const std::string& subject, const std::string& body) {
        std::cout << "Sending email (mock) to: " << to << " Subject: " << subject << std::endl;
        // In real API, construct RFC 2822 email and base64url encode it
        // For mock, return dummy ID
        return "sent_msg_id_" + std::to_string(std::chrono::system_clock::now().time_since_epoch().count());
    }

    // --- Calendar API ---
    std::vector<CalendarEvent> listCalendarEvents() {
        std::vector<CalendarEvent> events;
        std::string url = "https://www.googleapis.com/calendar/v3/calendars/primary/events?timeMin=" +
                          std::to_string(std::chrono::system_clock::now().time_since_epoch().count()) + "Z"; // Mock current time
        std::string response = makeApiRequest(url);
        if (response.empty()) return events;

        nlohmann::json json_response = nlohmann::json::parse(response);
        if (json_response.contains("items") && json_response["items"].is_array()) {
            // Mock data for demonstration
            events.push_back({"event1", "Team Sync", "Discuss project progress", "2025-07-15T10:00:00+08:00", "2025-07-15T11:00:00+08:00", "Conference Room A", "confirmed"});
            events.push_back({"event2", "Client Meeting", "Discuss new features", "2025-07-16T14:00:00+08:00", "2025-07-16T15:30:00+08:00", "Client Office", "confirmed"});
        }
        return events;
    }

    std::string createCalendarEvent(const std::string& summary, const std::string& description, const std::string& startTime, const std::string& endTime, const std::string& location) {
        std::cout << "Creating calendar event (mock): " << summary << std::endl;
        nlohmann::json event_body = {
            {"summary", summary},
            {"description", description},
            {"start", {{"dateTime", startTime}, {"timeZone", "Asia/Manila"}}},
            {"end", {{"dateTime", endTime}, {"timeZone", "Asia/Manila"}}},
            {"location", location}
        };
        std::string response = makeApiRequest("https://www.googleapis.com/calendar/v3/calendars/primary/events", "POST", &event_body);
        if (response.empty()) return "";
        // For mock, return dummy ID
        return "new_event_id_" + std::to_string(std::chrono::system_clock::now().time_since_epoch().count());
    }
};

// --- Sync Manager ---
class SyncManager {
private:
    GoogleApiClient& api;
    LocalDB& db;
    std::thread syncThread;
    std::atomic<bool> running;
    std::mutex mtx;
    std::condition_variable cv;

public:
    SyncManager(GoogleApiClient& apiClient, LocalDB& localDb) :
        api(apiClient), db(localDb), running(false) {}

    void startSyncLoop() {
        running = true;
        syncThread = std::thread(&SyncManager::syncLoop, this);
    }

    void stopSyncLoop() {
        running = false;
        cv.notify_all(); // Wake up the thread if it's waiting
        if (syncThread.joinable()) {
            syncThread.join();
        }
        std::cout << "Sync loop stopped." << std::endl;
    }

    void requestImmediateSync() {
        cv.notify_one(); // Signal the sync thread to wake up
    }

private:
    void syncLoop() {
        while (running) {
            std::unique_lock<std::mutex> lock(mtx);
            // Wait for a signal or timeout (e.g., every 5 minutes)
            cv.wait_for(lock, std::chrono::minutes(5), [this]{ return !running; });

            if (!running) break;

            std::cout << "\n--- Sync cycle started ---" << std::endl;
            if (api.creds.isValid()) { // Check if we are authenticated and online (conceptual)
                if (api.creds.needsRefresh()) {
                    if (!api.refreshAccessToken()) {
                        std::cerr << "Failed to refresh token. Cannot sync online." << std::endl;
                        continue; // Skip online sync for now
                    }
                }
                processOutgoingChanges();
                fetchIncomingChanges();
            } else {
                std::cout << "Not authenticated or offline. Skipping online sync." << std::endl;
            }
            std::cout << "--- Sync cycle finished ---" << std::endl;
        }
    }

    void processOutgoingChanges() {
        std::cout << "Processing outgoing (local) changes..." << std::endl;
        auto pendingOps = db.getPendingOperations();
        if (pendingOps.empty()) {
            std::cout << "No pending outgoing changes." << std::endl;
            return;
        }

        for (const auto& op : pendingOps) {
            int id = op.first;
            const std::string& type = op.second.first;
            const nlohmann::json& data = op.second.second;

            bool success = false;
            try {
                if (type == "file_upload") {
                    std::string filePath = data["filePath"];
                    std::string fileName = data["fileName"];
                    std::string mimeType = data["mimeType"];
                    if (api.uploadDriveFile(filePath, fileName, mimeType) != "") {
                        success = true;
                    }
                } else if (type == "email_send") {
                    std::string to = data["to"];
                    std::string subject = data["subject"];
                    std::string body = data["body"];
                    if (api.sendGmailMessage(to, subject, body) != "") {
                        success = true;
                    }
                } else if (type == "calendar_create") {
                    std::string summary = data["summary"];
                    std::string description = data["description"];
                    std::string startTime = data["startTime"];
                    std::string endTime = data["endTime"];
                    std::string location = data["location"];
                    if (api.createCalendarEvent(summary, description, startTime, endTime, location) != "") {
                        success = true;
                    }
                }
                // Add more types: file_delete, file_update, email_reply, calendar_update, etc.

                if (success) {
                    db.removePendingOperation(id);
                    std::cout << "Successfully synced outgoing " << type << " operation (ID: " << id << ")" << std::endl;
                } else {
                    std::cerr << "Failed to sync outgoing " << type << " operation (ID: " << id << "). Will retry." << std::endl;
                }
            } catch (const std::exception& e) {
                std::cerr << "Exception during outgoing sync of " << type << ": " << e.what() << std::endl;
            }
        }
    }

    void fetchIncomingChanges() {
        std::cout << "Fetching incoming (remote) changes..." << std::endl;

        // Drive Sync
        std::string driveSyncToken = db.getSyncToken("drive");
        // In a real app, use Drive API's changes.list() with the sync token
        // For mock: just re-fetch all files (inefficient but simple)
        std::vector<DriveFile> remoteFiles = api.listDriveFiles();
        if (!remoteFiles.empty()) {
            std::cout << "Received " << remoteFiles.size() << " remote Drive files." << std::endl;
            for (const auto& rFile : remoteFiles) {
                db.saveDriveFile(rFile); // Simple upsert
                // In a real app: check for conflicts, download new content, etc.
            }
            // Update sync token (mock)
            db.saveSyncToken("drive", "mock_new_drive_sync_token_" + std::to_string(std::chrono::system_clock::now().time_since_epoch().count()));
        }

        // Gmail Sync
        std::string gmailHistoryId = db.getSyncToken("gmail");
        // In a real app, use Gmail API's users.history.list()
        std::vector<GmailMessage> remoteMessages = api.listGmailMessages();
        if (!remoteMessages.empty()) {
            std::cout << "Received " << remoteMessages.size() << " remote Gmail messages." << std::endl;
            for (const auto& rMsg : remoteMessages) {
                db.saveGmailMessage(rMsg);
            }
            // Update sync token (mock)
            db.saveSyncToken("gmail", "mock_new_gmail_history_id_" + std::to_string(std::chrono::system_clock::now().time_since_epoch().count()));
        }

        // Calendar Sync
        std::string calendarSyncToken = db.getSyncToken("calendar");
        // In a real app, use Calendar API's events.list() with syncToken
        std::vector<CalendarEvent> remoteEvents = api.listCalendarEvents();
        if (!remoteEvents.empty()) {
            std::cout << "Received " << remoteEvents.size() << " remote Calendar events." << std::endl;
            for (const auto& rEvent : remoteEvents) {
                db.saveCalendarEvent(rEvent);
            }
            // Update sync token (mock)
            db.saveSyncToken("calendar", "mock_new_calendar_sync_token_" + std::to_string(std::chrono::system_clock::now().time_since_epoch().count()));
        }
    }
};

// --- Main Application Class (Conceptual) ---
class GoogleWorkspaceApp {
private:
    GoogleCredentials creds;
    GoogleApiClient apiClient;
    LocalDB localDb;
    SyncManager syncManager;

public:
    GoogleWorkspaceApp() :
        apiClient(creds),
        localDb("workspace.db"),
        syncManager(apiClient, localDb)
    {}

    bool initialize() {
        if (!localDb.open()) {
            std::cerr << "Failed to initialize local database." << std::endl;
            return false;
        }

        // Try to load saved credentials (not implemented in mock, would be from secure storage)
        // For demo, force OAuth
        if (!creds.isValid()) {
            if (!apiClient.performOAuthFlow()) { // This would involve user interaction
                std::cerr << "Authentication failed." << std::endl;
                return false;
            }
        }
        return true;
    }

    void run() {
        syncManager.startSyncLoop(); // Start background sync

        // Main application loop (e.g., UI event loop in Qt/GTK)
        // For console app, a simple menu loop
        std::cout << "\n--- Google Workspace Desktop App (C++ Mock) ---" << std::endl;
        std::cout << "Type 'help' for options, 'exit' to quit." << std::endl;

        std::string command;
        while (std::getline(std::cin, command) && command != "exit") {
            if (command == "help") {
                std::cout << "Commands:\n"
                          << "  sync         - Request immediate sync\n"
                          << "  ls_drive     - List local Drive files\n"
                          << "  upload_dummy - Upload a dummy file (queues if offline)\n"
                          << "  ls_gmail     - List local Gmail messages\n"
                          << "  send_dummy_email - Send a dummy email (queues if offline)\n"
                          << "  ls_calendar  - List local Calendar events\n"
                          << "  create_dummy_event - Create a dummy calendar event (queues if offline)\n"
                          << "  exit         - Exit the application\n";
            } else if (command == "sync") {
                syncManager.requestImmediateSync();
            } else if (command == "ls_drive") {
                auto files = localDb.getDriveFiles();
                std::cout << "\n--- Local Drive Files (" << files.size() << ") ---\n";
                if (files.empty()) {
                    std::cout << "No local files. Sync first.\n";
                }
                for (const auto& file : files) {
                    std::cout << "  ID: " << file.id << ", Name: " << file.name
                              << ", Modified: " << file.modifiedTime << ", Local Path: " << file.localContentPath
                              << (file.isLocallyModified ? " (MODIFIED OFFLINE)" : "") << "\n";
                }
            } else if (command == "upload_dummy") {
                // Simulate an offline file upload
                std::string dummyFileName = "my_offline_doc.txt";
                std::string dummyFilePath = "dummy_data/" + dummyFileName;
                // Create dummy file content (in a real app, this would be user's actual file)
                std::filesystem::create_directories("dummy_data"); // Requires C++17
                std::ofstream dummyFile(dummyFilePath);
                dummyFile << "This content was written offline at " << std::chrono::system_clock::now().time_since_epoch().count() << "\n";
                dummyFile.close();

                nlohmann::json uploadData = {
                    {"filePath", dummyFilePath},
                    {"fileName", dummyFileName},
                    {"mimeType", "text/plain"}
                };
                localDb.queuePendingOperation("file_upload", uploadData);
                std::cout << "Dummy file '" << dummyFileName << "' queued for upload.\n";
            } else if (command == "ls_gmail") {
                auto messages = localDb.getGmailMessages();
                std::cout << "\n--- Local Gmail Messages (" << messages.size() << ") ---\n";
                 if (messages.empty()) {
                    std::cout << "No local messages. Sync first.\n";
                }
                for (const auto& msg : messages) {
                    std::cout << "  From: " << msg.sender << ", Subject: " << msg.subject << ", Snippet: " << msg.snippet.substr(0, 50) << "...\n";
                }
            } else if (command == "send_dummy_email") {
                nlohmann::json emailData = {
                    {"to", "test@example.com"},
                    {"subject", "Offline Test Email from C++ App"},
                    {"body", "This email was composed offline using the C++ Google Workspace app and queued for sending."}
                };
                localDb.queuePendingOperation("email_send", emailData);
                std::cout << "Dummy email queued for sending.\n";
            } else if (command == "ls_calendar") {
                auto events = localDb.getCalendarEvents();
                std::cout << "\n--- Local Calendar Events (" << events.size() << ") ---\n";
                 if (events.empty()) {
                    std::cout << "No local events. Sync first.\n";
                }
                for (const auto& event : events) {
                    std::cout << "  Summary: " << event.summary << ", Start: " << event.startTime << ", End: " << event.endTime << "\n";
                }
            } else if (command == "create_dummy_event") {
                std::string now_str = "2025-07-15T10:00:00"; // Mock future time
                std::string end_str = "2025-07-15T11:00:00";
                nlohmann::json eventData = {
                    {"summary", "Offline C++ Test Event"},
                    {"description", "Created offline, should sync when online."},
                    {"start", now_str},
                    {"end", end_str},
                    {"location", "Virtual Meeting"}
                };
                localDb.queuePendingOperation("calendar_create", eventData);
                std::cout << "Dummy calendar event queued for creation.\n";
            }
            else {
                std::cout << "Unknown command. Type 'help' for options.\n";
            }
            std::cout << "> ";
        }
        syncManager.stopSyncLoop(); // Stop background sync before exit
        localDb.close();
    }
};

// --- Main function ---
int main() {
    // For demonstration purposes, mock required file system operations for dummy data.
    // In a real application, you'd use <filesystem> from C++17 or platform-specific APIs.
    // std::filesystem::create_directories("dummy_data");

    // Initialize CURL (global init, usually once per app)
    // curl_global_init(CURL_GLOBAL_DEFAULT); // Not used by mock.

    GoogleWorkspaceApp app;
    if (app.initialize()) {
        app.run();
    } else {
        std::cerr << "Application initialization failed." << std::endl;
    }

    // Cleanup CURL (global cleanup)
    // curl_global_cleanup(); // Not used by mock.
    return 0;
}



cmake_minimum_required(VERSION 3.10)
project(GoogleWorkspaceApp CXX)

set(CMAKE_CXX_STANDARD 17) # Or 20, depending on features used

# Find and link against external libraries
find_package(CURL REQUIRED)
find_package(SQLite3 REQUIRED) # Often SQLite is just a source file included
# If using nlohmann/json, it's often header-only or can be added as a submodule
# If using Qt, it requires find_package(Qt6 COMPONENTS Core Network Sql Gui Widgets ...)

# Example for nlohmann/json (assuming it's in a 'json' subdirectory or system-installed)
# target_include_directories(${PROJECT_NAME} PRIVATE "${CMAKE_SOURCE_DIR}/json/include")

add_executable(${PROJECT_NAME} main.cpp client.cpp db.cpp sync.cpp) # Assuming separation into more files

target_link_libraries(${PROJECT_NAME} PRIVATE CURL::CURL Sqlite3::Sqlite3)
# If using Qt: target_link_libraries(${PROJECT_NAME} PRIVATE Qt::Core Qt::Network Qt::Sql Qt::Gui Qt::Widgets)

